<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Uncertainty Quantification &mdash; dakota  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/dakota_theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/sandiaheaderlite.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../_static/copybutton.js?v=f281be69"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Optimization" href="optimization.html" />
    <link rel="prev" title="Design of Experiments" href="designofexperiments.html" /> 
  
  <meta name="sandia.approval_type" content="formal"/>
  <meta property="sandia.approved" content="SAND2025-05563O"/>
  <meta name="description" content="The Dakota project delivers both state-of-the-art research and robust, usable software for optimization and UQ."/>
  <meta name="keywords" content="Dakota, optimization, UQ, uncertainty quantification, parametric analysis, design exploration, model calibration, risk analysis"/>
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> dakota
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../setupdakota.html">Getting Started</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../usingdakota.html">Using Dakota</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../introduction/aboutdakota.html">About Dakota</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introduction/helloworld.html">Dakota Beginner’s Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introduction/couplingtosimulations.html">Coupling Dakota to a Simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../inputfile.html">Dakota Input File</a></li>
<li class="toctree-l2"><a class="reference internal" href="../running.html">Running Dakota</a></li>
<li class="toctree-l2"><a class="reference internal" href="../output.html">Dakota Output</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../studytypes.html">Study Types</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="parameterstudies.html">Parameter Studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="designofexperiments.html">Design of Experiments</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Uncertainty Quantification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#overview">Overview</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#summary-of-dakota-uq-methods">Summary of Dakota UQ Methods</a></li>
<li class="toctree-l5"><a class="reference internal" href="#variables-and-responses-for-uq">Variables and Responses for UQ</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#sampling-methods">Sampling Methods</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#uncertainty-quantification-example-using-sampling-methods">Uncertainty Quantification Example using Sampling Methods</a></li>
<li class="toctree-l5"><a class="reference internal" href="#incremental-sampling">Incremental Sampling</a></li>
<li class="toctree-l5"><a class="reference internal" href="#principal-component-analysis">Principal Component Analysis</a></li>
<li class="toctree-l5"><a class="reference internal" href="#wilks-based-sample-sizes">Wilks-based Sample Sizes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#double-sided-tolerance-interval-equivalent-normal-distribution">Double Sided Tolerance Interval Equivalent Normal Distribution</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#reliability-methods">Reliability Methods</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#local-reliability-methods">Local Reliability Methods</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#method-mapping">Method mapping</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#global-reliability-methods">Global Reliability Methods</a></li>
<li class="toctree-l5"><a class="reference internal" href="#uncertainty-quantification-examples-using-reliability-analysis">Uncertainty Quantification Examples using Reliability Analysis</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#mean-value-reliability-with-textbook">Mean-value Reliability with Textbook</a></li>
<li class="toctree-l6"><a class="reference internal" href="#form-reliability-with-lognormal-ratio">FORM Reliability with Lognormal Ratio</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#stochastic-expansion-methods">Stochastic Expansion Methods</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#uncertainty-quantification-examples-using-stochastic-expansions">Uncertainty Quantification Examples using Stochastic Expansions</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#polynomial-chaos-expansion-for-rosenbrock">Polynomial Chaos Expansion for Rosenbrock</a></li>
<li class="toctree-l6"><a class="reference internal" href="#uncertainty-quantification-example-using-stochastic-collocation">Uncertainty Quantification Example using Stochastic Collocation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#importance-sampling-methods">Importance Sampling Methods</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#importance-sampling-method-based-on-reliability-approach">Importance Sampling Method based on Reliability Approach</a></li>
<li class="toctree-l5"><a class="reference internal" href="#gaussian-process-adaptive-importance-sampling-method">Gaussian Process Adaptive Importance Sampling Method</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#adaptive-sampling-methods">Adaptive Sampling Methods</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#adaptive-sampling-based-on-surrogates">Adaptive sampling based on surrogates</a></li>
<li class="toctree-l5"><a class="reference internal" href="#adaptive-sampling-based-on-dart-throwing">Adaptive sampling based on dart throwing</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#epistemic-nondeterministic-methods">Epistemic Nondeterministic Methods</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#interval-methods-for-epistemic-analysis">Interval Methods for Epistemic Analysis</a></li>
<li class="toctree-l5"><a class="reference internal" href="#dempster-shafer-theory-of-evidence">Dempster-Shafer Theory of Evidence</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#bayesian-calibration-methods">Bayesian Calibration Methods</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#queso">QUESO</a></li>
<li class="toctree-l5"><a class="reference internal" href="#dream">DREAM</a></li>
<li class="toctree-l5"><a class="reference internal" href="#gpmsa">GPMSA</a></li>
<li class="toctree-l5"><a class="reference internal" href="#muq">MUQ</a></li>
<li class="toctree-l5"><a class="reference internal" href="#wasabi">WASABI</a></li>
<li class="toctree-l5"><a class="reference internal" href="#feature-comparison">Feature Comparison</a></li>
<li class="toctree-l5"><a class="reference internal" href="#bayesian-calibration-example">Bayesian Calibration Example</a></li>
<li class="toctree-l5"><a class="reference internal" href="#chain-diagnostics">Chain Diagnostics</a></li>
<li class="toctree-l5"><a class="reference internal" href="#calibrating-the-observation-error-model">Calibrating the Observation Error Model</a></li>
<li class="toctree-l5"><a class="reference internal" href="#scaling-and-weighting-of-residuals">Scaling and Weighting of Residuals</a></li>
<li class="toctree-l5"><a class="reference internal" href="#model-evidence">Model Evidence</a></li>
<li class="toctree-l5"><a class="reference internal" href="#model-discrepancy">Model Discrepancy</a></li>
<li class="toctree-l5"><a class="reference internal" href="#bayesian-experimental-design">Bayesian Experimental Design</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#one-at-a-time-implementation">One-at-a-time Implementation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#uncertainty-quantification-usage-guidelines">Uncertainty Quantification Usage Guidelines</a></li>
<li class="toctree-l4"><a class="reference internal" href="#video-resources">Video Resources</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="optimization.html">Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="nonlinearleastsquares.html">Nonlinear Least Squares</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../topics.html">Topics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced.html">Advanced Topics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../theory.html">Dakota Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../reference.html">Keyword Reference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../usingdakotagui/usingdakotagui.html">Using Dakota GUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../externaltools/externaltools.html">Using External Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compiling/compiling.html">Compiling Dakota</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developingdakota/developingdakota.html">Developing Dakota</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../misc/misc.html">Miscellaneous</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">dakota</a>
      </nav>

	  <!-- SNL Lite header -->
	  <div class="snlheader-subsite--wrapper-default">
		<snlheader class="snlheader-subsite" role="snlbanner">
		  <div class="wrapper">
			<a href="https://www.sandia.gov/index.html">
			  <div class="logo-transparent"><p class="logo">Sandia National Laboratories</p></div>
			</a>
			<div class="nav-top">
			  <a class="visuallyhidden" name="mainnav"></a>
			  <div aria-label="main navigation" class="core-nav-transparent core-nav-transparent--visible" role="navigation">
				<ul role="navigation" class="secondary-links">
				  <li id="search-text-link">
					<a aria-label="Search" href="https://www.sandia.gov/search/">Search Sandia.gov</a>
				  </li>
				  <li id="directory-text-link">
					<a href="https://www.sandia.gov/directory.html" aria-expanded="false" aria-label="Site Directory">All Sandia Websites</a>
				  </li>
				</ul>
			  </div>
			</div>
		  </div> 
		</snlheader>
	  </div>	  

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../usingdakota.html">Using Dakota</a></li>
          <li class="breadcrumb-item"><a href="../studytypes.html">Study Types</a></li>
      <li class="breadcrumb-item active">Uncertainty Quantification</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/usingdakota/studytypes/uq.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="uncertainty-quantification">
<span id="uq"></span><h1>Uncertainty Quantification<a class="headerlink" href="#uncertainty-quantification" title="Link to this heading"></a></h1>
<section id="overview">
<span id="uq-overview"></span><h2>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h2>
<p>At a high level, uncertainty quantification (UQ) or nondeterministic
analysis is the process of (1) characterizing input uncertainties, (2)
forward propagating these uncertainties through a computational model,
and (3) performing statistical or interval assessments on the resulting
responses. This process determines the effect of uncertainties and
assumptions on model outputs or results. In Dakota, uncertainty
quantification methods primarily focus on the forward propagation and
analysis parts of the process (2 and 3), where probabilistic or interval
information on parametric inputs are mapped through the computational
model to assess statistics or intervals on outputs. For an overview of
these approaches for engineering applications,
consult <span id="id1">[<a class="reference internal" href="../../misc/bibliography.html#id139" title="A. Haldar and S. Mahadevan. Probability, Reliability, and Statistical Methods in Engineering Design. Wiley, New York, 2000.">HM00</a>]</span>. Dakota also has emerging methods for
inference or inverse UQ, such as Bayesian calibration. These methods
help with (1) by inferring a statistical characterization of input
parameters that is consistent with available observational data.</p>
<p>UQ is related to sensitivity analysis in that the common goal is to gain
an understanding of how variations in the parameters affect the response
functions of the engineering design problem. However, for UQ, some or
all of the components of the parameter vector are considered to be
uncertain as specified by particular probability distributions (e.g.,
normal, exponential, extreme value) or other uncertainty specifications.
By assigning specific distributional structure to the inputs,
distributional structure for the outputs (i.e, response statistics) can
be inferred. This migrates from an analysis that is more <em>qualitative</em>
in nature, in the case of sensitivity analysis, to an analysis that is
more rigorously <em>quantitative</em>.</p>
<p>UQ methods can be distinguished by their ability to propagate aleatory
or epistemic input uncertainty characterizations, where aleatory
uncertainties are irreducible variabilities inherent in nature and
epistemic uncertainties are reducible uncertainties resulting from a
lack of knowledge.</p>
<p>For aleatory uncertainties, probabilistic methods are
commonly used for computing response distribution statistics based on
input probability distribution specifications. Conversely, for epistemic
uncertainties, use of probability distributions is based on subjective
prior knowledge rather than objective data, and we may alternatively
explore nonprobabilistic methods based on interval specifications.</p>
<section id="summary-of-dakota-uq-methods">
<span id="uq-overview-methods"></span><h3>Summary of Dakota UQ Methods<a class="headerlink" href="#summary-of-dakota-uq-methods" title="Link to this heading"></a></h3>
<p>Dakota contains capabilities for performing nondeterministic analysis
with both types of input uncertainty. These UQ methods have been
developed by Sandia Labs, in conjunction with collaborators in
academia <span id="id2">[<a class="reference internal" href="../../misc/bibliography.html#id84" title="M. S. Eldred, H. Agarwal, V. M. Perez, S. F. Wojtkiewicz, Jr., and J. E. Renaud. Investigation of reliability method formulations in DAKOTA/UQ. Structure &amp; Infrastructure Engineering: Maintenance, Management, Life-Cycle Design &amp; Performance, 3(3):199–213, 2007.">EAP+07</a>, <a class="reference internal" href="../../misc/bibliography.html#id109" title="R. Ghanem and J. R. Red-Horse. Propagation of probabilistic uncertainty in complex physical systems using a stochastic finite element technique. Physica D, 133:137-144, 1999.">GRH99</a>, <a class="reference internal" href="../../misc/bibliography.html#id108" title="R. G. Ghanem and P. D. Spanos. Stochastic Finite Elements: A Spectral Approach. Springer-Verlag, New York, 1991.">GS91</a>, <a class="reference internal" href="../../misc/bibliography.html#id278" title="G. Tang, L. P. Swiler, and M. S Eldred. Using stochastic expansion methods in evidence theory for mixed aleatory-epistemic uncertainty quantification. In Proceedings of the 51st AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference (12th AIAA Non-Deterministic Approaches conference). Orlando, FL, April 12-15, 2010. AIAA Paper 2010-XXXX.">TSE10</a>]</span>.</p>
<p>The aleatory UQ methods in Dakota include various sampling-based
approaches (e.g., Monte Carlo and Latin Hypercube sampling), local and
global reliability methods, and stochastic expansion (polynomial chaos
expansions, stochastic collocation, and functional tensor train)
approaches. The epistemic UQ methods include local and global interval
analysis and Dempster-Shafer evidence theory. These are summarized below
and then described in more depth in subsequent sections of this chapter.
Dakota additionally supports mixed aleatory/epistemic UQ via
interval-valued probability, second-order probability, and
Dempster-Shafer theory of evidence. These involve advanced model
recursions and are described in
<a class="reference internal" href="../advanced/advancedmodelrecursions.html#adv-models-mixed-uq"><span class="std std-ref">Mixed Aleatory-Epistemic UQ</span></a>.</p>
<p><strong>LHS (Latin Hypercube Sampling)</strong>: This package provides both Monte
Carlo (random) sampling and Latin Hypercube sampling methods, which can
be used with probabilistic variables in Dakota that have the following
distributions: normal, lognormal, uniform, loguniform, triangular,
exponential, beta, gamma, gumbel, frechet, weibull, poisson, binomial,
negative binomial, geometric, hypergeometric, and user-supplied
histograms. In addition, LHS accounts for correlations among the
variables <span id="id3">[<a class="reference internal" href="../../misc/bibliography.html#id160" title="R. L. Iman and M. J Shortencarier. A Fortran 77 program and user's guide for the generation of latin hypercube samples for use with computer models. Technical Report NUREG/CR-3624, SAND83-2365, Sandia National Laboratories, Albuquerque, NM, 1984.">IS84</a>]</span>, which can be used to accommodate a
user-supplied correlation matrix or to minimize correlation when a
correlation matrix is not supplied. In addition to a standard sampling
study, we support the capability to perform “incremental” LHS, where a
user can specify an initial LHS study of N samples, and then re-run an
additional incremental study which will double the number of samples (to
2N, with the first N being carried from the initial study). The full
incremental sample of size 2N is also a Latin Hypercube, with proper
stratification and correlation. Statistics for each increment are
reported separately at the end of the study.</p>
<p><strong>Reliability Methods</strong>: This suite of methods includes both local and
global reliability methods. Local methods include first- and
second-order versions of the Mean Value method (MVFOSM and MVSOSM) and a
variety of most probable point (MPP) search methods, including the
Advanced Mean Value method (AMV and AMV<span class="math notranslate nohighlight">\(^2\)</span>), the iterated
Advanced Mean Value method (AMV+ and AMV<span class="math notranslate nohighlight">\(^2\)</span>+), the Two-point
Adaptive Nonlinearity Approximation method (TANA-3), and the traditional
First Order and Second Order Reliability Methods (FORM and
SORM) <span id="id4">[<a class="reference internal" href="../../misc/bibliography.html#id139" title="A. Haldar and S. Mahadevan. Probability, Reliability, and Statistical Methods in Engineering Design. Wiley, New York, 2000.">HM00</a>]</span>. The MPP search methods may be used in
forward (Reliability Index Approach (RIA)) or inverse (Performance
Measure Approach (PMA)) modes, as dictated by the type of level
mappings. Each of the MPP search techniques solve local optimization
problems in order to locate the MPP, which is then used as the point
about which approximate probabilities are integrated (using first- or
second-order integrations in combination with refinements based on
importance sampling). Global reliability methods are designed to handle
nonsmooth and multimodal failure surfaces, by creating global
approximations based on Gaussian process models. They accurately resolve
a particular contour of a response function and then estimate
probabilities using multimodal adaptive importance sampling.</p>
<p><strong>Stochastic Expansion Methods</strong>: Theoretical development of these
techniques mirrors that of deterministic finite element analysis
utilizing the notions of projection, orthogonality, and weak
convergence <span id="id5">[<a class="reference internal" href="../../misc/bibliography.html#id109" title="R. Ghanem and J. R. Red-Horse. Propagation of probabilistic uncertainty in complex physical systems using a stochastic finite element technique. Physica D, 133:137-144, 1999.">GRH99</a>, <a class="reference internal" href="../../misc/bibliography.html#id108" title="R. G. Ghanem and P. D. Spanos. Stochastic Finite Elements: A Spectral Approach. Springer-Verlag, New York, 1991.">GS91</a>]</span>.</p>
<p>Rather than focusing on estimating specific statistics (e.g., failure
probability), they form an approximation to the functional relationship
between response functions and their random inputs, which provides a
more complete uncertainty representation for use in more advanced
contexts, such as coupled multi-code simulations. Expansion methods
include polynomial chaos expansions (PCE), which expand in a basis of
multivariate orthogonal polynomials (e.g., Hermite, Legendre) that are
tailored to representing particular input probability distributions
(e.g., normal, uniform); stochastic collocation (SC), which expand in a
basis of multivariate interpolation polynomials (e.g., Lagrange); and
functional tensor train (FTT), which leverages concepts from data
compression to expand using low rank products of polynomial cores. For
PCE, expansion coefficients may be evaluated using a spectral projection
approach (based on sampling, tensor-product quadrature, Smolyak sparse
grid, or cubature methods for numerical integration) or a regression
approach (least squares or compressive sensing). For SC, interpolants
are formed over tensor-product or sparse grids and may be local or
global, value-based or gradient-enhanced, and nodal or hierarchical. In
global value-based cases (Lagrange polynomials), the barycentric
formulation is used <span id="id6">[<a class="reference internal" href="../../misc/bibliography.html#id22" title="J.-P. Berrut and L. N. Trefethen. Barycentric lagrange interpolation. SIAM Review, 46(3):501–517, 2004.">BT04</a>, <a class="reference internal" href="../../misc/bibliography.html#id152" title="N. J. Higham. The numerical stability of barycentric lagrange interpolation. IMA Journal of Numerical Analysis, 24(4):547–556, 2004.">Hig04</a>, <a class="reference internal" href="../../misc/bibliography.html#id170" title="W. A. Klimke. Uncertainty Modeling using Fuzzy Arithmetic and Sparse Grids. PhD thesis, Universität Stuttgart, Stuttgart, Germany, 2005.">Kli05</a>]</span> to
improve numerical efficiency and stability. For FTT, regression via
regularized nonlinear least squares is employed for recovering low rank
coefficients, and cross-validation schemes are available to determine
the best rank and polynomial basis order settings. Each of these methods
provide analytic response moments and variance-based metrics; however,
PDFs and CDF/CCDF mappings are computed numerically by sampling on the
expansion.</p>
<p><strong>Importance Sampling</strong>: Importance sampling is a method that allows one
to estimate statistical quantities such as failure probabilities in a
way that is more efficient than Monte Carlo sampling. The core idea in
importance sampling is that one generates samples that are
preferentially placed in important regions of the space (e.g. in or near
the failure region or user-defined region of interest), then
appropriately weights the samples to obtain an unbiased estimate of the
failure probability.</p>
<p><strong>Adaptive Sampling</strong>: The goal in performing adaptive sampling is to
construct a surrogate model that can be used as an accurate predictor of
an expensive simulation. The aim is to build a surrogate that minimizes
the error over the entire domain of interest using as little data as
possible from the expensive simulation. The adaptive sampling methods
start with an initial LHS sample, and then adaptively choose samples
that optimize a particular criteria. For example, if a set of additional
possible sample points are generated, one criteria is to pick the next
sample point as the point which maximizes the minimum distance to the
existing points (maximin). Another criteria is to pick the sample point
where the surrogate indicates the most uncertainty in its prediction.</p>
<p>Recently, Dakota added a new method to assess failure probabilities
based on ideas from computational geometry. Part of the idea
underpinning this method is the idea of throwing “darts” which are
higher dimensional objects than sample points (e.g. lines, planes, etc.)
The POF (Probability-of-Failure) darts method uses these objects to
estimate failure probabilities.</p>
<p><strong>Interval Analysis</strong>: Interval analysis is often used to model
epistemic uncertainty. In interval analysis, one assumes that nothing is
known about an epistemic uncertain variable except that its value lies
somewhere within an interval. In this situation, it is NOT assumed that
the value has a uniform probability of occurring within the interval.
Instead, the interpretation is that any value within the interval is a
possible value or a potential realization of that variable. In interval
analysis, the uncertainty quantification problem is one of determining
the resulting bounds on the output (defining the output interval) given
interval bounds on the inputs. Again, any output response that falls
within the output interval is a possible output with no frequency
information assigned to it.</p>
<p>We have the capability to perform interval analysis using either global
or local methods. In the global approach, one uses either a global
optimization method (based on a Gaussian process surrogate model) or a
sampling method to assess the bounds. The local method uses gradient
information in a derivative-based optimization approach, using either
SQP (sequential quadratic programming) or a NIP (nonlinear interior
point) method to obtain bounds.</p>
<p><strong>Dempster-Shafer Theory of Evidence</strong>: The objective of evidence theory
is to model the effects of epistemic uncertainties. Epistemic
uncertainty refers to the situation where one does not know enough to
specify a probability distribution on a variable. Sometimes epistemic
uncertainty is referred to as subjective, reducible, or lack of
knowledge uncertainty. In contrast, aleatory uncertainty refers to the
situation where one does have enough information to specify a
probability distribution. In Dempster-Shafer theory of evidence, the
uncertain input variables are modeled as sets of intervals. The user
assigns a basic probability assignment (BPA) to each interval,
indicating how likely it is that the uncertain input falls within the
interval. The intervals may be overlapping, contiguous, or have gaps.
The intervals and their associated BPAs are then propagated through the
simulation to obtain cumulative distribution functions on belief and
plausibility. Belief is the lower bound on a probability estimate that
is consistent with the evidence, and plausibility is the upper bound on
a probability estimate that is consistent with the evidence. In addition
to the full evidence theory structure, we have a simplified capability
for users wanting to perform pure interval analysis (e.g. what is the
interval on the output given intervals on the input) using either global
or local optimization methods. Interval analysis is often used to model
epistemic variables in nested analyses, where probability theory is used
to model aleatory variables.</p>
<p><strong>Bayesian Calibration</strong>: In Bayesian calibration, uncertain input
parameters are initially characterized by a “prior” distribution. A
Bayesian calibration approach uses experimental data together with a
likelihood function, which describes how well a realization of the
parameters is supported by the data, to update this prior knowledge. The
process yields a posterior distribution of the parameters most
consistent with the data, such that running the model at samples from
the posterior yields results consistent with the observational data.</p>
</section>
<section id="variables-and-responses-for-uq">
<span id="uq-overview-varsresp"></span><h3>Variables and Responses for UQ<a class="headerlink" href="#variables-and-responses-for-uq" title="Link to this heading"></a></h3>
<p>UQ methods that perform a forward uncertainty propagation map
probability or interval information for input parameters into
probability or interval information for output response functions. The
<span class="math notranslate nohighlight">\(m\)</span> functions in the Dakota response data set are interpreted as
<span class="math notranslate nohighlight">\(m\)</span> general response functions by the Dakota methods (with no
specific interpretation of the functions as for optimization and least
squares).</p>
<p>Within the variables specification, uncertain variable descriptions are
employed to define the random variable distributions (refer to
<a class="reference internal" href="../inputfile/variables.html#variables-uncertain"><span class="std std-ref">Uncertain Variables</span></a>). For Bayesian
inference methods, these uncertain variable properties characterize the
prior distribution to be updated and constrained by the observational
data. As enumerated in
<a class="reference internal" href="../inputfile/variables.html#variables-uncertain"><span class="std std-ref">Uncertain Variables</span></a>, uncertain
variables types are categorized as either aleatory or epistemic and as
either continuous or discrete, where discrete types include integer
ranges, integer sets, string sets, and real sets. The continuous
aleatory distribution types include: normal (Gaussian), lognormal,
uniform, loguniform, triangular, exponential, beta, gamma, gumbel,
frechet, weibull, and histogram bin. The discrete aleatory distribution
types include: poisson, binomial, negative binomial, geometric,
hypergeometric, and discrete histograms for integers, strings, and
reals. The epistemic distribution types include continuous intervals,
discrete integer ranges, and discrete sets for integers, strings, and
reals. While many of the epistemic types appear similar to aleatory
counterparts, a key difference is that the latter requires probabilities
for each value within a range or set, whereas the former will use, at
most, a subjective belief specification.</p>
<p>When gradient and/or Hessian information is used in an uncertainty
assessment, derivative components are normally computed with respect to
the active continuous variables, which could be aleatory uncertain,
epistemic uncertain, aleatory and epistemic uncertain, or all continuous
variables, depending on the active view (see
<a class="reference internal" href="../inputfile/variables.html#variables-mixed"><span class="std std-ref">Management of Mixed Variables by Method</span></a>).</p>
</section>
</section>
<section id="sampling-methods">
<span id="uq-sampling"></span><h2>Sampling Methods<a class="headerlink" href="#sampling-methods" title="Link to this heading"></a></h2>
<p>Sampling techniques are selected using the <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-sampling.html"><span class="pre">sampling</span></a></code> method
selection. This method generates sets of samples according to the
probability distributions of the uncertain variables and maps them into
corresponding sets of response functions, where the number of samples is
specified by the <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-sampling-samples.html"><span class="pre">samples</span></a></code> integer specification. Means, standard
deviations, coefficients of variation (COVs), and 95% confidence
intervals are computed for the response functions. Probabilities and
reliabilities may be computed for <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-sampling-response_levels.html"><span class="pre">response_levels</span></a></code> specifications,
and response levels may be computed for either <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-sampling-probability_levels.html"><span class="pre">probability_levels</span></a></code> or
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-sampling-reliability_levels.html"><span class="pre">reliability_levels</span></a></code> specifications.</p>
<p>Currently, traditional Monte Carlo (MC), Latin hypercube sampling (LHS), and
low-discrepancy sampling (LD)/quasi-Monte Carlo sampling (QMC) are supported by
Dakota and are chosen by specifying <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-sampling-sample_type.html"><span class="pre">sample_type</span></a></code> as
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-sampling-sample_type-random.html"><span class="pre">random</span></a></code>,
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-sampling-sample_type-lhs.html"><span class="pre">lhs</span></a></code>, or
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-sampling-sample_type-low_discrepancy.html"><span class="pre">low_discrepancy</span></a></code>. In Monte Carlo sampling,
the samples are selected randomly according to the user-specified probability
distributions. Latin hypercube sampling is a stratified sampling technique for
which the range of each uncertain variable is divided into <span class="math notranslate nohighlight">\(N_{s}\)</span>
segments of equal probability, where <span class="math notranslate nohighlight">\(N_{s}\)</span> is the number of samples
requested. The relative lengths of the segments are determined by the nature of
the specified probability distribution (e.g., uniform has segments of equal
width, normal has small segments near the mean and larger segments in the
tails). For each of the uncertain variables, a sample is selected randomly from
each of these equal probability segments. These <span class="math notranslate nohighlight">\(N_{s}\)</span> values for each of
the individual parameters are then combined in a shuffling operation to create a
set of <span class="math notranslate nohighlight">\(N_{s}\)</span> parameter vectors with a specified correlation structure. A
feature of the resulting sample set is that <em>every row and column in the
hypercube of partitions has exactly one sample</em>. Since the total number of
samples is exactly equal to the number of partitions used for each uncertain
variable, an arbitrary number of desired samples is easily accommodated (as
compared to less flexible approaches in which the total number of samples is a
product or exponential function of the number of intervals for each variable,
i.e., many classical design of experiments methods).</p>
<p>Low-discrepancy or <em>quasi-Monte Carlo</em> sampling comes in two major flavors:
lattice rules and digital nets. The well-known Sobol sequence <span id="id7">[<a class="reference internal" href="../../misc/bibliography.html#id271" title="Il'ya Meerovich Sobol'. On the distribution of points in a cube and the approximate evaluation of integrals. Zhurnal Vychislitel'noi Matematiki i Matematicheskoi Fiziki, 7(4):784–802, 1967.">Sobol67</a>]</span>
is an example of a digital net. Just as Latin hypercube samples, the points are
carefully chosen such that they cover the parameter space more uniformly, in the
sense that the samples exhibit <em>low discrepancy</em>. This discrepancy is important,
because it directly appears in the bound for the integration error. In
particular, if one uses <span class="math notranslate nohighlight">\(N\)</span> points <span class="math notranslate nohighlight">\(\boldsymbol{t}_0,
\boldsymbol{t}_1, \ldots, \boldsymbol{t}_{N-1}\)</span> to approximate an integral
<span class="math notranslate nohighlight">\(I(f)\)</span> as <span class="math notranslate nohighlight">\(I_{N}(f)\)</span>, the Koksma-Hlawka inequality says that</p>
<div class="math notranslate nohighlight">
\[|I(f) - I_N(f)| \leq D(\boldsymbol{t}_0, \boldsymbol{t}_1, \ldots, \boldsymbol{t}_{N-1}) V(f)\]</div>
<p>where <span class="math notranslate nohighlight">\(D\)</span> is the <em>discrepancy</em> of the point set, and where <span class="math notranslate nohighlight">\(V(f)\)</span> is
the <em>variation</em> of the function <span class="math notranslate nohighlight">\(f\)</span>. For a given function, it is thus
advantageous to use points for which the discrepancy is as small as possible.
Currently, Dakota supports
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-sampling-sample_type-low_discrepancy-rank_1_lattice.html"><span class="pre">rank_1_lattice</span></a></code> rules and
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-sampling-sample_type-low_discrepancy-digital_net.html"><span class="pre">digital_net</span></a></code>s.
Low-discrepancy points, and, in particular digital nets, can, under certain
assumptions, outperform LHS, in the sense that they yield faster convergence
when the points are used to approximate the mean of a model response. A good
introduction to quasi-Monte Carlo can be found in <span id="id8">[<a class="reference internal" href="../../misc/bibliography.html#id57" title="Josef Dick, Frances Y Kuo, and Ian H Sloan. High-dimensional integration: the quasi-Monte Carlo way. Acta Numerica, 22:133–288, 2013.">DKS13</a>]</span>.</p>
<p>Advantages of sampling-based methods include their relatively simple
implementation and their independence from the scientific disciplines
involved in the analysis. The main drawback of these techniques is the
large number of function evaluations needed to generate converged
statistics, which can render such an analysis computationally very
expensive, if not intractable, for real-world engineering applications.
LHS techniques, in general, require fewer samples than traditional Monte
Carlo for the same accuracy in statistics, but they still can be
prohibitively expensive. For further information on the method and its
relationship to other sampling techniques, one is referred to the works
by McKay, et al. <span id="id9">[<a class="reference internal" href="../../misc/bibliography.html#id198" title="M. D. McKay, R. J. Beckman, and W. J. Conover. A comparison of three methods for selecting values of input variables in the analysis of output from a computer code. Technometrics, 21(2):239–245, 1979.">MBC79</a>]</span>, Iman and
Shortencarier <span id="id10">[<a class="reference internal" href="../../misc/bibliography.html#id160" title="R. L. Iman and M. J Shortencarier. A Fortran 77 program and user's guide for the generation of latin hypercube samples for use with computer models. Technical Report NUREG/CR-3624, SAND83-2365, Sandia National Laboratories, Albuquerque, NM, 1984.">IS84</a>]</span>, and Helton and
Davis <span id="id11">[<a class="reference internal" href="../../misc/bibliography.html#id148" title="J. C. Helton and F. J. Davis. Sampling-based methods for uncertainty and sensitivity analysis. Technical Report SAND99-2240, Sandia National Laboratories, Albuquerque, NM, 2000.">HD00</a>]</span>. Note that under certain separability
conditions associated with the function to be sampled, Latin hypercube
sampling provides a more accurate estimate of the mean value than does
random sampling. That is, given an equal number of samples, the LHS
estimate of the mean will have less variance than the mean value
obtained through random sampling.
Low-discrepancy samples, and, in particular digital nets, can provide
even more accurate estimates of the mean value, provided the function
one tries to integrate is sufficiently smooth. Some digital net point
sets may even exhibit higher-order convergence of the mean estimate.</p>
<p><a class="reference internal" href="#dace-figure01"><span class="std std-numref">Fig. 39</span></a> demonstrates Latin hypercube sampling on
a two-variable parameter space. Here, the range of both parameters,
<span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span>, is <span class="math notranslate nohighlight">\([0,1]\)</span>. Also, for this example
both <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span> have uniform statistical distributions.
For Latin hypercube sampling, the range of each parameter is divided
into <span class="math notranslate nohighlight">\(p\)</span> “bins” of equal probability. For parameters with uniform
distributions, this corresponds to partitions of equal size. For
<span class="math notranslate nohighlight">\(n\)</span> design parameters, this partitioning yields a total of
<span class="math notranslate nohighlight">\(p^{n}\)</span> bins in the parameter space. Next, <span class="math notranslate nohighlight">\(p\)</span> samples are
randomly selected in the parameter space, with the following
restrictions: (a) each sample is randomly placed inside a bin, and (b)
for all one-dimensional projections of the <span class="math notranslate nohighlight">\(p\)</span> samples and bins,
there will be one and only one sample in each bin. In a two-dimensional
example such as that shown in <a class="reference internal" href="#dace-figure01"><span class="std std-numref">Fig. 39</span></a>, these LHS
rules guarantee that only one bin can be selected in each row and
column. For <span class="math notranslate nohighlight">\(p=4\)</span>, there are four partitions in both <span class="math notranslate nohighlight">\(x_1\)</span>
and <span class="math notranslate nohighlight">\(x_2\)</span>. This gives a total of 16 bins, of which four will be
chosen according to the criteria described above. Note that there is
more than one possible arrangement of bins that meet the LHS criteria.
The dots in <a class="reference internal" href="#dace-figure01"><span class="std std-numref">Fig. 39</span></a> represent the four sample
sites in this example, where each sample is randomly located in its bin.
There is no restriction on the number of bins in the range of each
parameter, however, all parameters must have the same number of bins.</p>
<figure class="align-center" id="dace-figure01">
<img alt="An example of Latin hypercube sampling with four bins in design parameters :math:`x_1` and :math:`x_2`. The dots are the sample sites." src="../../_images/lhs_graphic.png" />
<figcaption>
<p><span class="caption-number">Fig. 39 </span><span class="caption-text">An example of Latin hypercube sampling with four bins in design
parameters <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span>. The dots are the sample
sites.</span><a class="headerlink" href="#dace-figure01" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>The actual algorithm for generating Latin hypercube samples is more complex than
indicated by the description given above. For example, the Latin hypercube
sampling method implemented in the LHS code <span id="id12">[<a class="reference internal" href="../../misc/bibliography.html#id275" title="L. P. Swiler and G. D. Wyss. A user's guide to Sandia's latin hypercube sampling software: LHS UNIX library and standalone version. Technical Report SAND04-2439, Sandia National Laboratories, Albuquerque, NM, July 2004.">SW04</a>]</span> takes into account a
user-specified correlation structure when selecting the sample sites. For more
details on the implementation of the LHS algorithm, see
Reference <span id="id13">[<a class="reference internal" href="../../misc/bibliography.html#id275" title="L. P. Swiler and G. D. Wyss. A user's guide to Sandia's latin hypercube sampling software: LHS UNIX library and standalone version. Technical Report SAND04-2439, Sandia National Laboratories, Albuquerque, NM, July 2004.">SW04</a>]</span>.</p>
<p>In addition to Monte Carlo, LHS and quasi-Monte Carlo design choices, Dakota
sampling methods support options for incrementally-refined designs, generation
of approximately determinant-optimal (D-optimal) designs, and selection of
sample sizes to satisfy Wilks’ criteria.</p>
<section id="uncertainty-quantification-example-using-sampling-methods">
<span id="uq-uncertainty1"></span><h3>Uncertainty Quantification Example using Sampling Methods<a class="headerlink" href="#uncertainty-quantification-example-using-sampling-methods" title="Link to this heading"></a></h3>
<p>The input file in <a class="reference internal" href="#uq-figure01"><span class="std std-numref">Listing 34</span></a> demonstrates
the use of Latin hypercube Monte Carlo sampling for assessing
probability of failure as measured by specified response levels. The
two-variable Textbook example problem (see
<a class="reference internal" href="../examples/additionalexamples.html#additional-textbook"><span class="std std-ref">Textbook</span></a>) will be
used to demonstrate the application of sampling methods for uncertainty
quantification where it is assumed that <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span> are
uniform uncertain variables on the interval <span class="math notranslate nohighlight">\([0,1]\)</span>.</p>
<p>The number of samples to perform is controlled with the <code class="docutils literal notranslate"><span class="pre">samples</span></code>
specification, the type of sampling algorithm to use is controlled with
the <code class="docutils literal notranslate"><span class="pre">sample_type</span></code> specification, the levels used for computing
statistics on the response functions is specified with the
<code class="docutils literal notranslate"><span class="pre">response_levels</span></code> input, and the <code class="docutils literal notranslate"><span class="pre">seed</span></code> specification controls the
sequence of the pseudo-random numbers generated by the sampling
algorithms. The input samples generated are shown in
<a class="reference internal" href="#uq-figure02"><span class="std std-numref">Table 7</span></a> for the case where <code class="docutils literal notranslate"><span class="pre">samples</span></code> =
5 and <code class="docutils literal notranslate"><span class="pre">samples</span></code> = 10 for both <code class="docutils literal notranslate"><span class="pre">random</span></code> (<span class="math notranslate nohighlight">\(\triangle\)</span>) and <code class="docutils literal notranslate"><span class="pre">lhs</span></code>
(<span class="math notranslate nohighlight">\(+\)</span>) sample types.</p>
<div class="literal-block-wrapper docutils container" id="uq-figure01">
<div class="code-block-caption"><span class="caption-number">Listing 34 </span><span class="caption-text">Dakota input file for UQ example using LHS –
see <code class="docutils literal notranslate"><span class="pre">dakota/share/dakota/examples/users/textbook_uq_sampling.in</span></code></span><a class="headerlink" href="#uq-figure01" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span><span class="c"># Dakota Input File: textbook_uq_sampling.in</span>
<span class="k">environment</span>
  tabular_data
    tabular_data_file = &#39;textbook_uq_sampling.dat&#39;
  top_method_pointer = &#39;UQ&#39;

<span class="k">method</span>
  id_method = &#39;UQ&#39;
  sampling
    sample_type lhs
    samples = 10
    seed = 98765
    response_levels = 0.1 0.2 0.6
                      0.1 0.2 0.6
                      0.1 0.2 0.6
    distribution cumulative

<span class="k">variables</span>
  uniform_uncertain = 2
    lower_bounds =  0.   0.
    upper_bounds =  1.   1.
    descriptors  = &#39;x1&#39; &#39;x2&#39;

<span class="k">interface</span>
  id_interface = &#39;I1&#39;
  analysis_drivers = &#39;text_book&#39;
    fork
  asynchronous evaluation_concurrency = 5

<span class="k">responses</span>
  response_functions = 3
  no_gradients
  no_hessians
</pre></div>
</div>
</div>
<table class="docutils align-default" id="uq-figure02">
<caption><span class="caption-number">Table 7 </span><span class="caption-text">Distribution of input sample points for random
        (<span class="math notranslate nohighlight">\(\triangle\)</span>) and lhs (<span class="math notranslate nohighlight">\(+\)</span>) sampling for (a)
        samples=5 and (b) samples=10.</span><a class="headerlink" href="#uq-figure02" title="Link to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><img alt="../../_images/input_samples5.png" src="../../_images/input_samples5.png" />
<ol class="loweralpha simple">
<li></li>
</ol>
</td>
<td><img alt="../../_images/input_samples10.png" src="../../_images/input_samples10.png" />
<ol class="loweralpha simple" start="2">
<li></li>
</ol>
</td>
</tr>
</tbody>
</table>
<p>Latin hypercube sampling ensures full coverage of the range of the input
variables, which is often a problem with Monte Carlo sampling when the
number of samples is small. In the case of <code class="docutils literal notranslate"><span class="pre">samples</span> <span class="pre">=</span> <span class="pre">5</span></code>, poor
stratification is evident in <span class="math notranslate nohighlight">\(x_1\)</span> as four out of the five Monte
Carlo samples are clustered in the range <span class="math notranslate nohighlight">\(0.35 &lt; x_1 &lt; 0.55\)</span>, and
the regions <span class="math notranslate nohighlight">\(x_1 &lt; 0.3\)</span> and <span class="math notranslate nohighlight">\(0.6 &lt; x_1 &lt; 0.9\)</span> are completely
missed. For the case where <code class="docutils literal notranslate"><span class="pre">samples</span> <span class="pre">=</span> <span class="pre">10</span></code>, some clustering in the
Monte Carlo samples is again evident with <code class="docutils literal notranslate"><span class="pre">4</span></code> samples in the range
<span class="math notranslate nohighlight">\(0.5 &lt; x_1 &lt; 0.55\)</span>. In both cases, the stratification with LHS is
superior.</p>
<p>The response function statistics returned by Dakota are shown in
<a class="reference internal" href="#uq-figure03"><span class="std std-numref">Listing 35</span></a>. The first block of output
specifies the response sample means, sample standard deviations, and
skewness and kurtosis. The second block of output displays confidence
intervals on the means and standard deviations of the responses. The
third block defines Probability Density Function (PDF) histograms of the
samples: the histogram bins are defined by the lower and upper values of
the bin and the corresponding density for that bin. Note that these bin
endpoints correspond to the <code class="docutils literal notranslate"><span class="pre">response_levels</span></code> and/or
<code class="docutils literal notranslate"><span class="pre">probability_levels</span></code> defined by the user in the Dakota input file. If
there are just a few levels, these histograms may be coarse. Dakota does
not do anything to optimize the bin size or spacing. Finally, the last
section of the output defines the Cumulative Distribution Function (CDF)
pairs. In this case, <code class="docutils literal notranslate"><span class="pre">distribution</span> <span class="pre">cumulative</span></code> was specified for the
response functions, and Dakota presents the probability levels
corresponding to the specified response levels (<code class="docutils literal notranslate"><span class="pre">response_levels</span></code>)
that were set. The default <code class="docutils literal notranslate"><span class="pre">compute</span> <span class="pre">probabilities</span></code> was used.
Alternatively, Dakota could have provided CCDF pairings, reliability
levels corresponding to prescribed response levels, or response levels
corresponding to prescribed probability or reliability levels.</p>
<div class="literal-block-wrapper docutils container" id="uq-figure03">
<div class="code-block-caption"><span class="caption-number">Listing 35 </span><span class="caption-text">Dakota response function statistics from UQ sampling example.</span><a class="headerlink" href="#uq-figure03" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span>Statistics based on 10 samples:

Sample moment statistics for each response function:
                            Mean           Std Dev          Skewness          Kurtosis
 response_fn_1  3.8383990322e-01  4.0281539886e-01  1.2404952971e+00  6.5529797327e-01
 response_fn_2  7.4798705803e-02  3.4686110941e-01  4.5716015887e-01 -5.8418924529e-01
 response_fn_3  7.0946176558e-02  3.4153246532e-01  5.2851897926e-01 -8.2527332042e-01

95% confidence intervals for each response function:
                    LowerCI_Mean      UpperCI_Mean    LowerCI_StdDev    UpperCI_StdDev
 response_fn_1  9.5683125821e-02  6.7199668063e-01  2.7707061315e-01  7.3538389383e-01
 response_fn_2 -1.7333078422e-01  3.2292819583e-01  2.3858328290e-01  6.3323317325e-01
 response_fn_3 -1.7337143113e-01  3.1526378424e-01  2.3491805390e-01  6.2350514636e-01

Probability Density Function (PDF) histograms for each response function:
PDF for response_fn_1:
          Bin Lower          Bin Upper      Density Value
          ---------          ---------      -------------
   2.3066424677e-02   1.0000000000e-01   3.8994678038e+00
   1.0000000000e-01   2.0000000000e-01   2.0000000000e+00
   2.0000000000e-01   6.0000000000e-01   5.0000000000e-01
   6.0000000000e-01   1.2250968624e+00   4.7992562123e-01
PDF for response_fn_2:
          Bin Lower          Bin Upper      Density Value
          ---------          ---------      -------------
  -3.5261164651e-01   1.0000000000e-01   1.1046998102e+00
   1.0000000000e-01   2.0000000000e-01   2.0000000000e+00
   2.0000000000e-01   6.0000000000e-01   5.0000000000e-01
   6.0000000000e-01   6.9844576220e-01   1.0157877573e+00
PDF for response_fn_3:
          Bin Lower          Bin Upper      Density Value
          ---------          ---------      -------------
  -3.8118095128e-01   1.0000000000e-01   1.2469321539e+00
   1.0000000000e-01   2.0000000000e-01   0.0000000000e+00
   2.0000000000e-01   6.0000000000e-01   7.5000000000e-01
   6.0000000000e-01   6.4526450977e-01   2.2092363423e+00

Level mappings for each response function:
Cumulative Distribution Function (CDF) for response_fn_1:
     Response Level  Probability Level  Reliability Index  General Rel Index
     --------------  -----------------  -----------------  -----------------
   1.0000000000e-01   3.0000000000e-01
   2.0000000000e-01   5.0000000000e-01
   6.0000000000e-01   7.0000000000e-01
Cumulative Distribution Function (CDF) for response_fn_2:
     Response Level  Probability Level  Reliability Index  General Rel Index
     --------------  -----------------  -----------------  -----------------
   1.0000000000e-01   5.0000000000e-01
   2.0000000000e-01   7.0000000000e-01
   6.0000000000e-01   9.0000000000e-01
Cumulative Distribution Function (CDF) for response_fn_3:
     Response Level  Probability Level  Reliability Index  General Rel Index
     --------------  -----------------  -----------------  -----------------
   1.0000000000e-01   6.0000000000e-01
   2.0000000000e-01   6.0000000000e-01
   6.0000000000e-01   9.0000000000e-01
</pre></div>
</div>
</div>
<p>In addition to obtaining statistical summary information of the type
shown in <a class="reference internal" href="#uq-figure03"><span class="std std-numref">Listing 35</span></a>, the results of LHS
sampling also include correlations.</p>
<p id="uq-correlationtypes">Four types of correlations are returned in the output: simple and partial “raw” correlations, and
simple and partial “rank” correlations. The raw correlations refer to
correlations performed on the actual input and output data. Rank
correlations refer to correlations performed on the ranks of the data.
Ranks are obtained by replacing the actual data by the ranked values,
which are obtained by ordering the data in ascending order. For example,
the smallest value in a set of input samples would be given a rank 1,
the next smallest value a rank 2, etc. Rank correlations are useful when
some of the inputs and outputs differ greatly in magnitude: then it is
easier to compare if the smallest ranked input sample is correlated with
the smallest ranked output, for example.</p>
<p>Correlations are always calculated between two sets of sample data. One
can calculate correlation coefficients between two input variables,
between an input and an output variable (probably the most useful), or
between two output variables. The simple correlation coefficients
presented in the output tables are Pearson’s correlation coefficient,
which is defined for two variables <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> as:
<span class="math notranslate nohighlight">\(\mathtt{Corr}(x,y) = \frac{\sum_{i}(x_{i}-\bar{x})(y_{i}-\bar{y})}
{\sqrt{\sum_{i}(x_{i}-\bar{x})^2\sum_{i}(y_{i}-\bar{y})^2}}\)</span>. Partial
correlation coefficients are similar to simple correlations, but a
partial correlation coefficient between two variables measures their
correlation while adjusting for the effects of the other variables. For
example, say one has a problem with two inputs and one output; and the
two inputs are highly correlated. Then the correlation of the second
input and the output may be very low after accounting for the effect of
the first input. The rank correlations in Dakota are obtained using
Spearman’s rank correlation. Spearman’s rank is the same as the Pearson
correlation coefficient except that it is calculated on the rank data.</p>
<p><a class="reference internal" href="#uq-figure04"><span class="std std-numref">Listing 36</span></a> shows an example of the
correlation output provided by Dakota for the input file in
<a class="reference internal" href="#uq-figure01"><span class="std std-numref">Listing 34</span></a>. Note that these correlations
are presently only available when one specifies <code class="docutils literal notranslate"><span class="pre">lhs</span></code> as the sampling
method under <code class="docutils literal notranslate"><span class="pre">sampling</span></code>. Also note that the simple and partial
correlations should be similar in most cases (in terms of values of
correlation coefficients). This is because we use a default “restricted
pairing” method in the LHS routine which forces near-zero correlation
amongst uncorrelated inputs.</p>
<div class="literal-block-wrapper docutils container" id="uq-figure04">
<div class="code-block-caption"><span class="caption-number">Listing 36 </span><span class="caption-text">Correlation results using LHS Sampling.</span><a class="headerlink" href="#uq-figure04" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span>Simple Correlation Matrix between input and output:
                       x1           x2 response_fn_1 response_fn_2 response_fn_3
          x1  1.00000e+00
          x2 -7.22482e-02  1.00000e+00
response_fn_1 -7.04965e-01 -6.27351e-01  1.00000e+00
response_fn_2  8.61628e-01 -5.31298e-01 -2.60486e-01  1.00000e+00
response_fn_3 -5.83075e-01  8.33989e-01 -1.23374e-01 -8.92771e-01  1.00000e+00

Partial Correlation Matrix between input and output:
             response_fn_1 response_fn_2 response_fn_3
          x1 -9.65994e-01  9.74285e-01 -9.49997e-01
          x2 -9.58854e-01 -9.26578e-01  9.77252e-01

Simple Rank Correlation Matrix between input and output:
                       x1           x2 response_fn_1 response_fn_2 response_fn_3
          x1  1.00000e+00
          x2 -6.66667e-02  1.00000e+00
response_fn_1 -6.60606e-01 -5.27273e-01  1.00000e+00
response_fn_2  8.18182e-01 -6.00000e-01 -2.36364e-01  1.00000e+00
response_fn_3 -6.24242e-01  7.93939e-01 -5.45455e-02 -9.27273e-01  1.00000e+00

Partial Rank Correlation Matrix between input and output:
             response_fn_1 response_fn_2 response_fn_3
          x1 -8.20657e-01  9.74896e-01 -9.41760e-01
          x2 -7.62704e-01 -9.50799e-01  9.65145e-01
</pre></div>
</div>
</div>
<p>Finally, note that the LHS package can be used for design of experiments
over design and state variables by including an active view override in
the variables specification section of the Dakota input file (see
<a class="reference internal" href="../inputfile/variables.html#variables-mixedview"><span class="std std-ref">Active Variables View</span></a>). Then, instead
of iterating on only the uncertain variables, the LHS package will
sample over all of the active variables. In the <code class="docutils literal notranslate"><span class="pre">active</span> <span class="pre">all</span></code> view,
continuous design and continuous state variables are treated as having
uniform probability distributions within their upper and lower bounds,
discrete design and state variables are sampled uniformly from within
their sets or ranges, and any uncertain variables are sampled within
their specified probability distributions.</p>
</section>
<section id="incremental-sampling">
<span id="uq-incremental"></span><h3>Incremental Sampling<a class="headerlink" href="#incremental-sampling" title="Link to this heading"></a></h3>
<p>In many situations, one may run an initial sample set and then need to
perform further sampling to get better estimates of the mean, variance,
and percentiles, and to obtain more comprehensive sample coverage. We
call this capability incremental sampling. Typically, a Dakota restart
file (<code class="docutils literal notranslate"><span class="pre">dakota.rst</span></code>) would be available from the original sample,
so only the newly
generated samples would need to be evaluated. Incremental sampling
supports continuous uncertain variables and discrete uncertain variables
such as discrete distributions (e.g. binomial, Poisson, etc.) as well as
histogram variables and uncertain set types.</p>
<p>There are two cases, incremental random and incremental Latin hypercube
sampling, with incremental LHS being the most common. One major
advantage of LHS incremental sampling is that it maintains the
stratification and correlation structure of the original LHS sample.
That is, if one generated two independent LHS samples and simply merged
them, the calculation of the accuracy of statistical measures such as
the mean and the variance would be slightly incorrect. However, in the
incremental case, the full sample (double the original size) is a Latin
Hypercube sample itself and statistical measures and their accuracy can
be properly calculated. The incremental sampling capability is most
useful when one is starting off with very small samples. Once the sample
size is more than a few hundred, the benefit of incremental sampling
diminishes.</p>
<ol class="arabic">
<li><p>Incremental random sampling: With incremental random sampling, the
original sample set with <span class="math notranslate nohighlight">\(N1\)</span> samples must be generated using
<code class="docutils literal notranslate"><span class="pre">sample_type</span> <span class="pre">=</span> <span class="pre">random</span></code> and <code class="docutils literal notranslate"><span class="pre">samples</span> <span class="pre">=</span> <span class="pre">N1</span></code>. Then, the user can
duplicate the Dakota input file and add <code class="docutils literal notranslate"><span class="pre">refinement_samples</span> <span class="pre">=</span> <span class="pre">N2</span></code>
with the number of new samples <span class="math notranslate nohighlight">\(N2\)</span> to be added. Random
incremental sampling does not require a doubling of samples each
time. Thus, the user can specify any number of <code class="docutils literal notranslate"><span class="pre">refinement_samples</span></code>
(from an additional one sample to a large integer).</p>
<p>For example, if the first sample has 50 samples, and 10 more samples
are desired, the second Dakota run should specify <code class="docutils literal notranslate"><span class="pre">samples</span> <span class="pre">=</span> <span class="pre">50</span></code>,
<code class="docutils literal notranslate"><span class="pre">refinement_samples</span> <span class="pre">=</span> <span class="pre">10</span></code>. In this situation, only 10 new samples
will be generated, and the final statistics will be reported at the
end of the study both for the initial 50 samples and for the full
sample of 60. The command line syntax for running the second sample
is <code class="docutils literal notranslate"><span class="pre">dakota</span> <span class="pre">-i</span> <span class="pre">input60.in</span> <span class="pre">-r</span> <span class="pre">dakota.50.rst</span></code> where <code class="docutils literal notranslate"><span class="pre">input60.in</span></code> is
the input file with the refinement samples specification and
<code class="docutils literal notranslate"><span class="pre">dakota.50.rst</span></code> is the
restart file containing the initial 50 samples. Note that if the
restart file has a different name, that is fine; the correct restart
file name should be used.</p>
<p>This process can be repeated if desired,arbitrarily extending the
total sample size each time, e.g, <code class="docutils literal notranslate"><span class="pre">samples</span> <span class="pre">=</span> <span class="pre">50</span></code>,
<code class="docutils literal notranslate"><span class="pre">refinement_samples</span> <span class="pre">=</span> <span class="pre">10</span> <span class="pre">3</span> <span class="pre">73</span> <span class="pre">102</span></code>.</p>
</li>
<li><p>Incremental Latin hypercube sampling: With incremental LHS sampling,
the original sample set with <span class="math notranslate nohighlight">\(N1\)</span> samples must be generated
using <code class="docutils literal notranslate"><span class="pre">sample_type</span> <span class="pre">=</span> <span class="pre">lhs</span></code> and <code class="docutils literal notranslate"><span class="pre">samples</span> <span class="pre">=</span> <span class="pre">N1</span></code>. Then, the user can
duplicate the Dakota input file and add <code class="docutils literal notranslate"><span class="pre">refinement_samples</span> <span class="pre">=</span> <span class="pre">N1</span></code>.
The sample size must double each time, so the first set of refinement
samples must be the same size as the initial set. That is, if one
starts with a very small sample size of 10, then one can use the
incremental sampling capability to generate sample sizes of 20, 40,
80, etc.</p>
<p>For example, if the first sample has 50 samples, in the second Dakota
run, the number of refinement samples should be set to 50 for a total
of 100. In this situation, only 50 new samples will be generated, and
at the end of the study final statistics will be reported both for
the initial 50 samples and for the full sample of 100. The command
line syntax for running the second sample is
<code class="docutils literal notranslate"><span class="pre">dakota</span> <span class="pre">-i</span> <span class="pre">input100.in</span> <span class="pre">-r</span> <span class="pre">dakota.50.rst</span></code>, where <code class="docutils literal notranslate"><span class="pre">input100.in</span></code>
is the input file with the incremental sampling specification and
<code class="docutils literal notranslate"><span class="pre">dakota.50.rst</span></code> is the restart file
containing the initial 50 samples. Note that if the restart file has
a different name, that is fine; the correct restart file name should
be used.</p>
<p>This process can be repeated if desired, doubling the total sample
size each time, e.g, <code class="docutils literal notranslate"><span class="pre">samples</span> <span class="pre">=</span> <span class="pre">50</span></code>,
<code class="docutils literal notranslate"><span class="pre">refinement_samples</span> <span class="pre">=</span> <span class="pre">50</span> <span class="pre">100</span> <span class="pre">200</span> <span class="pre">400</span></code>.</p>
</li>
</ol>
</section>
<section id="principal-component-analysis">
<h3>Principal Component Analysis<a class="headerlink" href="#principal-component-analysis" title="Link to this heading"></a></h3>
<p>As of Dakota 6.3, we added a capability to perform Principal Component
Analysis on field response data when using LHS sampling. Principal
components analysis (PCA) is a data reduction method and allows one to
express an ensemble of field data with a set of principal components
responsible for the spread of that data.</p>
<p>Dakota can calculate the principal components of the response matrix of
N samples * L responses (the field response of length L) using the
keyword <code class="docutils literal notranslate"><span class="pre">principal_components</span></code>. The Dakota implementation is under
active development: the PCA capability may ultimately be specified
elsewhere or used in different ways. For now, it is performed as a
post-processing analysis based on a set of Latin Hypercube samples.</p>
<p>If the user specifies LHS sampling with field data responses and also
specifies <code class="docutils literal notranslate"><span class="pre">principal_components</span></code>, Dakota will calculate the principal
components by calculating the eigenvalues and eigenvectors of a centered
data matrix. Further, if the user specifies
<code class="docutils literal notranslate"><span class="pre">percent_variance_explained</span></code> = 0.99, the number of components that
accounts for at least 99 percent of the variance in the responses will
be retained. The default for this percentage is 0.95. In many
applications, only a few principal components explain the majority of
the variance, resulting in significant data reduction. The principal
components are written to a file <code class="docutils literal notranslate"><span class="pre">princ_comp.txt</span></code>.
Dakota also uses the principal
components to create a surrogate model by representing the overall
response as weighted sum of M principal components, where the weights
will be determined by Gaussian processes which are a function of the
input uncertain variables. This reduced form then can be used for
sensitivity analysis, calibration, etc.</p>
</section>
<section id="wilks-based-sample-sizes">
<span id="uq-wilks"></span><h3>Wilks-based Sample Sizes<a class="headerlink" href="#wilks-based-sample-sizes" title="Link to this heading"></a></h3>
<p>Most of the sampling methods require the user to specify the number of
samples in advance. However, if one specifies <code class="docutils literal notranslate"><span class="pre">random</span></code> sampling, one
can use an approach developed by Wilks <span id="id14">[<a class="reference internal" href="../../misc/bibliography.html#id302" title="S. S. Wilks. Determination of sample sizes for setting tolerance limits. Ann. Math. Stat., 12(1):91–96, 1941.">Wil41</a>]</span> to
determine the number of samples that ensures a particular confidence
level in a percentile of interest. The Wilks method of computing the
number of samples to execute for a random sampling study is based on
order statistics, eg considering the outputs ordered from smallest to
largest <span id="id15">[<a class="reference internal" href="../../misc/bibliography.html#id221" title="W.T. Nutt and G.B. Wallis. Evaluation of nuclear safety from the outputs of computer codes in the presence of uncertainties. Reliability Engineering and System Safety, 83:57–77, 2004.">NW04</a>, <a class="reference internal" href="../../misc/bibliography.html#id302" title="S. S. Wilks. Determination of sample sizes for setting tolerance limits. Ann. Math. Stat., 12(1):91–96, 1941.">Wil41</a>]</span>. Given a <code class="docutils literal notranslate"><span class="pre">probability_level</span></code>,
<span class="math notranslate nohighlight">\(\alpha\)</span>, and <code class="docutils literal notranslate"><span class="pre">confidence_level</span></code>, <span class="math notranslate nohighlight">\(\beta\)</span>, the Wilks
calculation determines the minimum number of samples required such that
there is <span class="math notranslate nohighlight">\((\beta*100)\)</span>% confidence that the
<span class="math notranslate nohighlight">\((\alpha*100)\)</span>%-ile of the uncertain distribution on model
output will fall below the actual <span class="math notranslate nohighlight">\((\alpha*100)\)</span>%-ile given by
the sample. To be more specific, if we wish to calculate the
<span class="math notranslate nohighlight">\(95\%\)</span> confidence limit on the <span class="math notranslate nohighlight">\(95^{th}\)</span> percentile, Wilks
indicates that 59 samples are needed. If we order the responses and take
the largest one, that value defines a tolerance limit on the 95th
percentile: we have a situation where <span class="math notranslate nohighlight">\(95\%\)</span> of the time, the
<span class="math notranslate nohighlight">\(95^{th}\)</span> percentile will fall at or below that sampled value.
This represents a <code class="docutils literal notranslate"><span class="pre">one_sided_upper</span></code> treatment applicable to the
largest output value. This treatment can be reversed to apply to the
lowest output value by using the <code class="docutils literal notranslate"><span class="pre">one_sided_lower</span></code> option, and further
expansion to include an interval containing both the smallest and the
largest output values in the statistical statement can be specified via
the <code class="docutils literal notranslate"><span class="pre">two_sided</span></code> option. Additional generalization to higher order
statistics, eg a statement applied to the N largest outputs
(<code class="docutils literal notranslate"><span class="pre">one_sided_upper</span></code>) or the N smallest and N largest outputs
(<code class="docutils literal notranslate"><span class="pre">two_sided</span></code>), can be specified using the <code class="docutils literal notranslate"><span class="pre">order</span></code> option along with
value N.</p>
</section>
<section id="double-sided-tolerance-interval-equivalent-normal-distribution">
<span id="uq-tolerance-intervals"></span><h3>Double Sided Tolerance Interval Equivalent Normal Distribution<a class="headerlink" href="#double-sided-tolerance-interval-equivalent-normal-distribution" title="Link to this heading"></a></h3>
<p>Tolerance Intervals (TIs) are a simple way to approximately account for
the epistemic sampling uncertainty introduced from finite samples of a
random variable. TIs are parameterized by two user-prescribed levels:
one for the desired “coverage” proportion of a distribution and one for
the desired degree of statistical “confidence” in covering or bounding
at least that proportion.
For instance, a <span class="math notranslate nohighlight">\(95\%\)</span> coverage / <span class="math notranslate nohighlight">\(90\%\)</span> confidence TI
(<span class="math notranslate nohighlight">\(95\%\)</span>/<span class="math notranslate nohighlight">\(90\%\)</span> TI, <span class="math notranslate nohighlight">\(95\)</span>/<span class="math notranslate nohighlight">\(90\)</span> TI,
or <span class="math notranslate nohighlight">\(0.95\)</span>/<span class="math notranslate nohighlight">\(0.90\)</span> TI)
prescribes lower and upper values of a range said to have at least
<span class="math notranslate nohighlight">\(90\%\)</span> odds that it covers or spans <span class="math notranslate nohighlight">\(95\%\)</span> of the “true”
probability distribution from which the random samples were drawn,
if they were drawn from a Normal distribution  <span id="id16">[<a class="reference internal" href="../../misc/bibliography.html#id162" title="Charles F. Jekel and Vicente J. Romero. Conservative estimation of tail probabilities from limited sample data. Technical Report SAND2020-2828, Sandia National Laboratories, Albuquerque, NM, March 2020.">JR20</a>]</span>.</p>
</section>
</section>
<section id="reliability-methods">
<span id="uq-reliability"></span><h2>Reliability Methods<a class="headerlink" href="#reliability-methods" title="Link to this heading"></a></h2>
<p>Reliability methods provide an alternative approach to uncertainty
quantification which can be less computationally demanding than sampling
techniques. Reliability methods for uncertainty quantification are based
on probabilistic approaches that compute approximate response function
distribution statistics based on specified uncertain variable
distributions. These response statistics include response mean, response
standard deviation, and cumulative or complementary cumulative
distribution functions (CDF/CCDF). These methods are often more
efficient at computing statistics in the tails of the response
distributions (events with low probability) than sampling based
approaches since the number of samples required to resolve a low
probability can be prohibitive.</p>
<p>The methods all answer the fundamental question: “Given a set of
uncertain input variables, <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>, and a scalar response
function, <span class="math notranslate nohighlight">\(g\)</span>, what is the probability that the response function
is below or above a certain level, <span class="math notranslate nohighlight">\(\bar{z}\)</span>?” The former can be
written as
<span class="math notranslate nohighlight">\(P[g(\mathbf{X}) \le \bar{z}] = \mathit{F}_{g}(\bar{z})\)</span> where
<span class="math notranslate nohighlight">\(\mathit{F}_{g}(\bar{z})\)</span> is the cumulative distribution function
(CDF) of the uncertain response <span class="math notranslate nohighlight">\(g(\mathbf{X})\)</span> over a set of
response levels. The latter can be written as
<span class="math notranslate nohighlight">\(P[g(\mathbf{X}) &gt; \bar{z}]\)</span> and defines the complementary
cumulative distribution function (CCDF).</p>
<p>This probability calculation involves a multi-dimensional integral over
an irregularly shaped domain of interest, <span class="math notranslate nohighlight">\(\mathbf{D}\)</span>, where
<span class="math notranslate nohighlight">\(g(\mathbf{X}) &lt; z\)</span> as displayed in <a class="reference internal" href="#uq-figure05"><span class="std std-numref">Fig. 40</span></a>
for the case of two variables. The reliability methods all involve the
transformation of the user-specified uncertain variables,
<span class="math notranslate nohighlight">\(\mathbf{X}\)</span>, with probability density function,
<span class="math notranslate nohighlight">\(p(x_1,x_2)\)</span>, which can be non-normal and correlated, to a space
of independent Gaussian random variables, <span class="math notranslate nohighlight">\(\mathbf{u}\)</span>, possessing
a mean value of zero and unit variance (i.e., standard normal
variables). The region of interest, <span class="math notranslate nohighlight">\(\mathbf{D}\)</span>, is also mapped
to the transformed space to yield, <span class="math notranslate nohighlight">\(\mathbf{D_{u}}\)</span> , where
<span class="math notranslate nohighlight">\(g(\mathbf{U}) &lt; z\)</span> as shown in <a class="reference internal" href="#uq-figure06"><span class="std std-numref">Fig. 41</span></a>. The
Nataf transformation <span id="id17">[<a class="reference internal" href="../../misc/bibliography.html#id54" title="A. Der Kiureghian and P. L. Liu. Structural reliability under incomplete information. J. Eng. Mech., ASCE, 112(EM-1):85–104, 1986.">DKL86</a>]</span>, which is identical to
the Rosenblatt transformation <span id="id18">[<a class="reference internal" href="../../misc/bibliography.html#id254" title="M. Rosenblatt. Remarks on a multivariate transformation. Annals of Mathematical Statistics, 23(3):470–472, 1952.">Ros52</a>]</span> in the case of
independent random variables, is used in Dakota to accomplish this
mapping. This transformation is performed to make the probability
calculation more tractable. In the transformed space, probability
contours are circular in nature as shown in
<a class="reference internal" href="#uq-figure06"><span class="std std-numref">Fig. 41</span></a> unlike in the original uncertain variable
space, <a class="reference internal" href="#uq-figure05"><span class="std std-numref">Fig. 40</span></a>. Also, the multi-dimensional
integrals can be approximated by simple functions of a single parameter,
<span class="math notranslate nohighlight">\(\beta\)</span>, called the reliability index. <span class="math notranslate nohighlight">\(\beta\)</span> is the
minimum Euclidean distance from the origin in the transformed space to
the response surface. This point is also known as the most probable
point (MPP) of failure. Note, however, the methodology is equally
applicable for generic functions, not simply those corresponding to
failure criteria; this nomenclature is due to the origin of these
methods within the disciplines of structural safety and reliability.
Note that there are local and global reliability methods. The majority
of the methods available are local, meaning that a local optimization
formulation is used to locate one MPP. In contrast, global methods can
find multiple MPPs if they exist.</p>
<figure class="align-center" id="uq-figure05">
<img alt="Graphical depiction of calculation of cumulative distribution function in the original uncertain variable space." src="../../_images/cdf_orig_graphic.png" />
<figcaption>
<p><span class="caption-number">Fig. 40 </span><span class="caption-text">Graphical depiction of calculation of cumulative distribution
function in the original uncertain variable space.</span><a class="headerlink" href="#uq-figure05" title="Link to this image"></a></p>
</figcaption>
</figure>
<figure class="align-center" id="uq-figure06">
<img alt="Graphical depiction of integration for the calculation of cumulative distribution function in the transformed uncertain variable space." src="../../_images/cdf_tran_graphic.png" />
<figcaption>
<p><span class="caption-number">Fig. 41 </span><span class="caption-text">Graphical depiction of integration for the calculation of cumulative
distribution function in the transformed uncertain variable space.</span><a class="headerlink" href="#uq-figure06" title="Link to this image"></a></p>
</figcaption>
</figure>
<section id="local-reliability-methods">
<span id="uq-reliability-local"></span><h3>Local Reliability Methods<a class="headerlink" href="#local-reliability-methods" title="Link to this heading"></a></h3>
<p><a class="reference internal" href="../theory/reliability.html#theory-uq-reliability-local"><span class="std std-ref">The main section on Local Reliability Methods</span></a>
provides the algorithmic details for the local reliability methods, including the Mean Value method
and the family of most probable point (MPP) search methods.</p>
<section id="method-mapping">
<span id="uq-reliability-local-map"></span><h4>Method mapping<a class="headerlink" href="#method-mapping" title="Link to this heading"></a></h4>
<p>Given settings for limit state approximation, approximation order,
integration approach, and other details presented to this point, it is
evident that the number of algorithmic combinations is high.
<a class="reference internal" href="#tab-rel-meth-map"><span class="std std-numref">Table 8</span></a> provides a succinct mapping for some
of these combinations to common method names from the reliability
literature, where bold font indicates the most well-known combinations and
regular font indicates other supported combinations.</p>
<table class="tr-nth-child-3 color red docutils align-center" id="tab-rel-meth-map">
<caption><span class="caption-number">Table 8 </span><span class="caption-text">Mapping from Dakota options to standard reliability
methods.</span><a class="headerlink" href="#tab-rel-meth-map" title="Link to this table"></a></caption>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>Order of approximation
and integration</p></th>
<th class="head"></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MPP search</p></td>
<td><p>First order</p></td>
<td><p>Second order</p></td>
</tr>
<tr class="row-odd"><td><p>none</p></td>
<td><p><strong>MVFOSM</strong></p></td>
<td><p>MVSOSM</p></td>
</tr>
<tr class="row-even"><td><p>x_taylor_mean</p></td>
<td><p><strong>AMV</strong></p></td>
<td><p>AMV<span class="math notranslate nohighlight">\(^2\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>u_taylor_mean</p></td>
<td><p>u-space AMV</p></td>
<td><p>u-space AMV<span class="math notranslate nohighlight">\(^2\)</span></p></td>
</tr>
<tr class="row-even"><td><p>x_taylor_mpp</p></td>
<td><p><strong>AMV+</strong></p></td>
<td><p>AMV<span class="math notranslate nohighlight">\(^2\)</span>+</p></td>
</tr>
<tr class="row-odd"><td><p>u_taylor_mpp</p></td>
<td><p>u-space AMV+</p></td>
<td><p>u-space
AMV<span class="math notranslate nohighlight">\(^2\)</span>+</p></td>
</tr>
<tr class="row-even"><td><p>x_two_point</p></td>
<td><p><strong>TANA</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>u_two_point</p></td>
<td><p>u-space TANA</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>no_approx</p></td>
<td><p><strong>FORM</strong></p></td>
<td><p><strong>SORM</strong></p></td>
</tr>
</tbody>
</table>
<p>Within the Dakota specification (refer to <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-local_reliability.html"><span class="pre">local_reliability</span></a></code>),
the MPP search and integration order
selections are explicit in the method specification, but the order of
the approximation is inferred from the associated response specification
(as is done with local taylor series approximations described in
<a class="reference internal" href="../inputfile/model.html#models-surf-taylor"><span class="std std-ref">Taylor Series</span></a>). Thus,
reliability methods do not have to be synchronized in approximation and
integration order as shown in the table; however, it is often desirable
to do so.</p>
</section>
</section>
<section id="global-reliability-methods">
<span id="uq-reliability-global"></span><h3>Global Reliability Methods<a class="headerlink" href="#global-reliability-methods" title="Link to this heading"></a></h3>
<p>Global reliability methods are designed to handle nonsmooth and
multimodal failure surfaces, by creating global approximations based on
Gaussian process models. They accurately resolve a particular contour of
a response function and then estimate probabilities using multimodal
adaptive importance sampling.</p>
<p>The global reliability method in Dakota is called Efficient Global
Reliability Analysis (EGRA)  <span id="id19">[<a class="reference internal" href="../../misc/bibliography.html#id24" title="B. J. Bichon, M. S. Eldred, L. P. Swiler, S. Mahadevan, and J. M. McFarland. Efficient global reliability analysis for nonlinear implicit performance functions. AIAA Journal, 46(10):2459–2468, 2008.">BES+08</a>]</span>. The name is
due to its roots in efficient global optimization (EGO)
 <span id="id20">[<a class="reference internal" href="../../misc/bibliography.html#id158" title="D. Huang, T. T. Allen, W. I. Notz, and N. Zeng. Global optimization of stochastic black-box systems via sequential kriging meta-models. Journal of Global Optimization, 34:441–466, 2006.">HANZ06</a>, <a class="reference internal" href="../../misc/bibliography.html#id165" title="D. Jones, M. Schonlau, and W. Welch. Efficient global optimization of expensive black-box functions. Journal of Global Optimization, 13:455–492, 1998.">JSW98</a>]</span>. The main idea in EGO-type optimization
methods is that a global approximation is made of the underlying
function. This approximation, which is a Gaussian process model, is used
to guide the search by finding points which maximize the expected
improvement function (EIF). The EIF is used to select the location at
which a new training point should be added to the Gaussian process model
by maximizing the amount of improvement in the objective function that
can be expected by adding that point. A point could be expected to
produce an improvement in the objective function if its predicted value
is better than the current best solution, or if the uncertainty in its
prediction is such that the probability of it producing a better
solution is high. Because the uncertainty is higher in regions of the
design space with fewer observations, this provides a balance between
exploiting areas of the design space that predict good solutions, and
exploring areas where more information is needed.</p>
<p>The general procedure of these EGO-type methods is:</p>
<ol class="arabic simple">
<li><p>Build an initial Gaussian process model of the objective function.</p></li>
<li><p>Find the point that maximizes the EIF. If the EIF value at this point
is sufficiently small, stop.</p></li>
<li><p>Evaluate the objective function at the point where the EIF is
maximized. Update the Gaussian process model using this new point. Go
to Step 2.</p></li>
</ol>
<p>Gaussian process (GP) models are used because they provide not just a
predicted value at an unsampled point, but also an estimate of the
prediction variance. This variance gives an indication of the
uncertainty in the GP model, which results from the construction of the
covariance function. This function is based on the idea that when input
points are near one another, the correlation between their corresponding
outputs will be high. As a result, the uncertainty associated with the
model’s predictions will be small for input points which are near the
points used to train the model, and will increase as one moves further
from the training points.</p>
<p>The expected improvement function is used in EGO algorithms to select
the location at which a new training point should be added. The EIF is
defined as the expectation that any point in the search space will
provide a better solution than the current best solution based on the
expected values and variances predicted by the GP model. It is important
to understand how the use of this EIF leads to optimal solutions. The
EIF indicates how much the objective function value at a new potential
location is expected to be less than the predicted value at the current
best solution. Because the GP model provides a Gaussian distribution at
each predicted point, expectations can be calculated. Points with good
expected values and even a small variance will have a significant
expectation of producing a better solution (exploitation), but so will
points that have relatively poor expected values and greater variance
(exploration).</p>
<p>The application of EGO to reliability analysis, however, is made more
complicated due to the inclusion of equality constraints. In forward
reliability analysis, the response function appears as a constraint
rather than the objective. That is, we want to satisfy the constraint
that the response equals a threshold value and is on the limit state:
<span class="math notranslate nohighlight">\(G({\bf u})\!=\!\bar{z}\)</span>. Therefore, the EIF function was modified
to focus on feasibility, and instead of using an expected improvement
function, we use an expected feasibility function (EFF)
 <span id="id21">[<a class="reference internal" href="../../misc/bibliography.html#id24" title="B. J. Bichon, M. S. Eldred, L. P. Swiler, S. Mahadevan, and J. M. McFarland. Efficient global reliability analysis for nonlinear implicit performance functions. AIAA Journal, 46(10):2459–2468, 2008.">BES+08</a>]</span>. The EFF provides an indication of how
well the response is expected to satisfy the equality constraint. Points
where the expected value is close to the threshold
(<span class="math notranslate nohighlight">\(\mu_G\!\approx\!\bar{z}\)</span>) and points with a large uncertainty in
the prediction will have large expected feasibility values.</p>
<p>The general outline of the EGRA algorithm is as follows: LHS sampling is
used to generate a small number of samples from the true response
function. Then, an initial Gaussian process model is constructed. Based
on the EFF, the point with maximum EFF is found using the global
optimizer DIRECT. The true response function is then evaluated at this
new point, and this point is added to the sample set and the process of
building a new GP model and maximizing the EFF is repeated until the
maximum EFF is small. At this stage, the GP model is accurate in the
vicinity of the limit state. The GP model is then used to calculate the
probability of failure using multimodal importance sampling, which is
explained below.</p>
<p>One method to calculate the probability of failure is to directly
perform the probability integration numerically by sampling the response
function. Sampling methods can be prohibitively expensive because they
generally require a large number of response function evaluations.
Importance sampling methods reduce this expense by focusing the samples
in the important regions of the uncertain space. They do this by
centering the sampling density function at the MPP rather than at the
mean. This ensures the samples will lie the region of interest, thus
increasing the efficiency of the sampling method. Adaptive importance
sampling (AIS) further improves the efficiency by adaptively updating
the sampling density function. Multimodal adaptive importance
sampling <span id="id22">[<a class="reference internal" href="../../misc/bibliography.html#id55" title="A. Dey and S. Mahadevan. Ductile structural system reliability analysis using adaptive importance sampling. Structural Safety, 20:137–154, 1998.">DM98</a>]</span> is a variation of AIS that allows for
the use of multiple sampling densities making it better suited for cases
where multiple sections of the limit state are highly probable.</p>
<p>Note that importance sampling methods require that the location of at
least one MPP be known because it is used to center the initial sampling
density. However, current gradient-based, local search methods used in
MPP search may fail to converge or may converge to poor solutions for
highly nonlinear problems, possibly making these methods inapplicable.
The EGRA algorithm described above does not depend on the availability
of accurate gradient information, making convergence more reliable for
nonsmooth response functions. Moreover, EGRA has the ability to locate
multiple failure points, which can provide multiple starting points and
thus a good multimodal sampling density for the initial steps of
multimodal AIS. The probability assessment using multimodal AIS thus
incorporates probability of failure at multiple points.</p>
</section>
<section id="uncertainty-quantification-examples-using-reliability-analysis">
<span id="uq-reliability-ex"></span><h3>Uncertainty Quantification Examples using Reliability Analysis<a class="headerlink" href="#uncertainty-quantification-examples-using-reliability-analysis" title="Link to this heading"></a></h3>
<p>In summary, the user can choose to perform either forward (RIA) or
inverse (PMA) mappings when performing a reliability analysis. With
either approach, there are a variety of methods from which to choose in
terms of limit state approximations (MVFOSM, MVSOSM, x-/u-space AMV,
x-/u-space AMV<span class="math notranslate nohighlight">\(^2\)</span>, x-/u-space AMV+, x-/u-space
AMV<span class="math notranslate nohighlight">\(^2\)</span>+, x-/u-space TANA, and FORM/SORM), probability
integrations (first-order or second-order), limit state Hessian
selection (analytic, finite difference, BFGS, or SR1), and MPP
optimization algorithm (SQP or NIP) selections.</p>
<p>All reliability methods output approximate values of the CDF/CCDF
response-probability-reliability levels for prescribed response levels
(RIA) or prescribed probability or reliability levels (PMA). In
addition, mean value methods output estimates of the response means and
standard deviations as well as importance factors that attribute
variance among the set of uncertain variables (provided a nonzero
response variance estimate).</p>
<section id="mean-value-reliability-with-textbook">
<span id="uq-examples-mv"></span><h4>Mean-value Reliability with Textbook<a class="headerlink" href="#mean-value-reliability-with-textbook" title="Link to this heading"></a></h4>
<p><a class="reference internal" href="#uq-examples-mv-input"><span class="std std-numref">Listing 37</span></a> shows the
Dakota input file for an example problem that demonstrates the simplest
reliability method, called the mean value method (also referred to as
the Mean Value First Order Second Moment method). It is specified with
method keyword <code class="docutils literal notranslate"><span class="pre">local_reliability</span></code>. This method calculates the mean
and variance of the response function based on information about the
mean and variance of the inputs and gradient information at the mean of
the inputs. The mean value method is extremely cheap computationally
(only five runs were required for the textbook function), but can be
quite inaccurate, especially for nonlinear problems and/or problems with
uncertain inputs that are significantly non-normal. More detail on the
mean value method can be found in the main <a class="reference internal" href="../theory/reliability.html#theory-uq-reliability-local"><span class="std std-ref">Local Reliability Methods section</span></a>,
and more detail on reliability methods in general (including the more advanced methods)
is found in <a class="reference internal" href="#uq-reliability"><span class="std std-ref">Reliability Methods</span></a>.</p>
<p>Example output from the mean value method is displayed in
<a class="reference internal" href="#uq-examples-mv-results"><span class="std std-numref">Listing 38</span></a>. Note that
since the mean of both inputs is 1, the mean value of the output for
response 1 is zero. However, the mean values of the constraints are both
0.5. The mean value results indicate that variable x1 is more important
in constraint 1 while x2 is more important in constraint 2, which is the
case based on <a class="reference internal" href="../examples/additionalexamples.html#additional-textbook"><span class="std std-ref">Textbook</span></a>. The
importance factors are not available for the first response as the
standard deviation is zero.</p>
<div class="literal-block-wrapper docutils container" id="uq-examples-mv-input">
<div class="code-block-caption"><span class="caption-number">Listing 37 </span><span class="caption-text">Mean Value Reliability Method: the Dakota input file – see
<code class="docutils literal notranslate"><span class="pre">dakota/share/dakota/examples/users/textbook_uq_meanvalue.in</span></code></span><a class="headerlink" href="#uq-examples-mv-input" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span><span class="c"># Dakota Input File: textbook_uq_meanvalue.in</span>

<span class="k">environment</span>

<span class="k">method</span>
  local_reliability

<span class="k">interface</span>
  analysis_drivers = &#39;text_book&#39;
    fork asynchronous

<span class="k">variables</span>
  lognormal_uncertain = 2
    means                 =  1.      1.
    std_deviations        =  0.5     0.5
    descriptors           =  &#39;TF1ln&#39; &#39;TF2ln&#39;

<span class="k">responses</span>
  response_functions = 3
  numerical_gradients
    method_source dakota
    interval_type central
    fd_gradient_step_size = 1.e-4
  no_hessians
</pre></div>
</div>
</div>
<div class="literal-block-wrapper docutils container" id="uq-examples-mv-results">
<div class="code-block-caption"><span class="caption-number">Listing 38 </span><span class="caption-text">Results of the Mean Value Method on the Textbook Function</span><a class="headerlink" href="#uq-examples-mv-results" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span>MV Statistics for response_fn_1:
  Approximate Mean Response                  =  0.0000000000e+00
  Approximate Standard Deviation of Response =  0.0000000000e+00
  Importance Factors not available.
MV Statistics for response_fn_2:
  Approximate Mean Response                  =  5.0000000000e-01
  Approximate Standard Deviation of Response =  1.0307764064e+00
  Importance Factor for TF1ln                =  9.4117647059e-01
  Importance Factor for TF2ln                =  5.8823529412e-02
MV Statistics for response_fn_3:
  Approximate Mean Response                  =  5.0000000000e-01
  Approximate Standard Deviation of Response =  1.0307764064e+00
  Importance Factor for TF1ln                =  5.8823529412e-02
  Importance Factor for TF2ln                =  9.4117647059e-01
</pre></div>
</div>
</div>
</section>
<section id="form-reliability-with-lognormal-ratio">
<h4>FORM Reliability with Lognormal Ratio<a class="headerlink" href="#form-reliability-with-lognormal-ratio" title="Link to this heading"></a></h4>
<p>This example quantifies the uncertainty in the “log ratio” response
function:</p>
<div class="math notranslate nohighlight">
\[g(x_1,x_2) = \frac{x_1}{x_2}\]</div>
<p>by computing approximate response statistics using reliability analysis
to determine the response cumulative distribution function:</p>
<div class="math notranslate nohighlight">
\[P[g(x_1,x_2) &lt; \bar{z}]\]</div>
<p>where <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span> are identically distributed lognormal
random variables with means of <code class="docutils literal notranslate"><span class="pre">1</span></code>, standard deviations of <code class="docutils literal notranslate"><span class="pre">0.5</span></code>,
and correlation coefficient of <code class="docutils literal notranslate"><span class="pre">0.3</span></code>.</p>
<p>A Dakota input file showing RIA using FORM (option 7 in limit state
approximations combined with first-order integration) is listed in
<a class="reference internal" href="#uq-rel-input-form"><span class="std std-numref">Listing 39</span></a>. The user first
specifies the <code class="docutils literal notranslate"><span class="pre">local_reliability</span></code> method, followed by the MPP search
approach and integration order. In this example, we specify
<code class="docutils literal notranslate"><span class="pre">mpp_search</span> <span class="pre">no_approx</span></code> and utilize the default first-order integration
to select FORM. Finally, the user specifies response levels or
probability/reliability levels to determine if the problem will be
solved using an RIA approach or a PMA approach. In the example of
<a class="reference internal" href="#uq-rel-input-form"><span class="std std-numref">Listing 39</span></a>, we use RIA by
specifying a range of <code class="docutils literal notranslate"><span class="pre">response_levels</span></code> for the problem. The resulting
output for this input is shown in
<a class="reference internal" href="#uq-rel-output-form"><span class="std std-numref">Listing 40</span></a>, with probability
and reliability levels listed for each response level.
<a class="reference internal" href="#uq-rel-form-compare"><span class="std std-numref">Fig. 42</span></a> shows that FORM compares favorably
to an exact analytic solution for this problem. Also note that FORM does
have some error in the calculation of CDF values for this problem, but
it is a very small error (on the order of e-11), much smaller than the
error obtained when using a Mean Value method, which will be discussed
next.</p>
<div class="literal-block-wrapper docutils container" id="uq-rel-input-form">
<div class="code-block-caption"><span class="caption-number">Listing 39 </span><span class="caption-text">Dakota input file for Reliability UQ example using FORM –
see <code class="docutils literal notranslate"><span class="pre">dakota/share/dakota/examples/users/logratio_uq_reliability.in</span></code></span><a class="headerlink" href="#uq-rel-input-form" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span><span class="c"># Dakota Input File: logratio_uq_reliability.in</span>

<span class="k">environment</span>

<span class="k">method</span>
  local_reliability
    mpp_search no_approx
    response_levels = .4 .5 .55 .6 .65 .7
     .75 .8 .85 .9 1. 1.05 1.15 1.2 1.25 1.3
     1.35 1.4 1.5 1.55 1.6 1.65 1.7 1.75

<span class="k">variables</span>
  lognormal_uncertain = 2
    means             =  1.  1
    std_deviations    =  0.5 0.5
    initial_point     =  0.6 1.4
    descriptors       =  &#39;TF1ln&#39;   &#39;TF2ln&#39;
  uncertain_correlation_matrix =  1   0.3
            0.3 1

<span class="k">interface</span>
  analysis_drivers = &#39;log_ratio&#39;
    direct
<span class="c">#  fork asynch</span>

<span class="k">responses</span>
  response_functions = 1
  numerical_gradients
    method_source dakota
    interval_type central
    fd_step_size = 1.e-4
  no_hessians
</pre></div>
</div>
</div>
<div class="literal-block-wrapper docutils container" id="uq-rel-output-form">
<div class="code-block-caption"><span class="caption-number">Listing 40 </span><span class="caption-text">Output from Reliability UQ example using FORM.</span><a class="headerlink" href="#uq-rel-output-form" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span>Cumulative Distribution Function (CDF) for response_fn_1:
     Response Level  Probability Level  Reliability Index
     --------------  -----------------  -----------------
   4.0000000000e-01   4.7624085962e-02   1.6683404020e+00
   5.0000000000e-01   1.0346525475e-01   1.2620507942e+00
   5.5000000000e-01   1.3818404972e-01   1.0885143628e+00
   6.0000000000e-01   1.7616275822e-01   9.3008801339e-01
   6.5000000000e-01   2.1641741368e-01   7.8434989943e-01
   7.0000000000e-01   2.5803428381e-01   6.4941748143e-01
   7.5000000000e-01   3.0020938124e-01   5.2379840558e-01
   8.0000000000e-01   3.4226491013e-01   4.0628960782e-01
   8.5000000000e-01   3.8365052982e-01   2.9590705956e-01
   9.0000000000e-01   4.2393548232e-01   1.9183562480e-01
   1.0000000000e+00   5.0000000000e-01   6.8682233460e-12
   1.0500000000e+00   5.3539344228e-01  -8.8834907167e-02
   1.1500000000e+00   6.0043460094e-01  -2.5447217462e-01
   1.2000000000e+00   6.3004131827e-01  -3.3196278078e-01
   1.2500000000e+00   6.5773508987e-01  -4.0628960782e-01
   1.3000000000e+00   6.8356844630e-01  -4.7770089473e-01
   1.3500000000e+00   7.0761025532e-01  -5.4641676380e-01
   1.4000000000e+00   7.2994058691e-01  -6.1263331274e-01
   1.5000000000e+00   7.6981945355e-01  -7.3825238860e-01
   1.5500000000e+00   7.8755158269e-01  -7.9795460350e-01
   1.6000000000e+00   8.0393505584e-01  -8.5576118635e-01
   1.6500000000e+00   8.1906005158e-01  -9.1178881995e-01
   1.7000000000e+00   8.3301386860e-01  -9.6614373461e-01
   1.7500000000e+00   8.4588021938e-01  -1.0189229206e+00
</pre></div>
</div>
</div>
<figure class="align-default" id="uq-rel-form-compare">
<img alt="Comparison of the cumulative distribution function (CDF) computed by FORM, the Mean Value method, and the exact CDF for :math:`g(x_1,x_2)=\frac{x_1}{x_2}`" src="../../_images/cdf_form.png" />
<figcaption>
<p><span class="caption-number">Fig. 42 </span><span class="caption-text">Comparison of the cumulative distribution function (CDF) computed by
FORM, the Mean Value method, and the exact CDF for
<span class="math notranslate nohighlight">\(g(x_1,x_2)=\frac{x_1}{x_2}\)</span></span><a class="headerlink" href="#uq-rel-form-compare" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>If the user specifies <code class="docutils literal notranslate"><span class="pre">local_reliability</span></code> as a method with no
additional specification on how to do the MPP search (for example, by
commenting out <code class="docutils literal notranslate"><span class="pre">mpp_search</span> <span class="pre">no_approx</span></code> in
<a class="reference internal" href="#uq-rel-input-form"><span class="std std-numref">Listing 39</span></a>), then no MPP search
is done: the Mean Value method is used. The mean value results are shown
in <a class="reference internal" href="#uq-rel-output-mv"><span class="std std-numref">Listing 41</span></a> and consist of
approximate mean and standard deviation of the response, the importance
factors for each uncertain variable, and approximate
probability/reliability levels for the prescribed response levels that
have been inferred from the approximate mean and standard deviation (see
the <a class="reference internal" href="../theory/reliability.html#theory-uq-reliability-local-mv"><span class="std std-ref">Mean Value section of the main Reliability Methods page</span></a>). It is evident that the statistics
are considerably different from the fully converged FORM results;
however, these rough approximations are also much less expensive to
calculate. The importance factors are a measure of the sensitivity of
the response function(s) to the uncertain input variables. A comparison
of the mean value results with the FORM results is shown in
<a class="reference internal" href="#uq-rel-form-compare"><span class="std std-numref">Fig. 42</span></a>. The mean value results are not
accurate near the tail values of the CDF, and can differ from the exact
solution by as much as 0.11 in CDF estimates. A comprehensive comparison
of various reliability methods applied to the logratio problem is
provided in  <span id="id23">[<a class="reference internal" href="../../misc/bibliography.html#id81" title="M. S. Eldred and B. J. Bichon. Second-order reliability formulations in DAKOTA/UQ. In Proceedings of the 47th AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics and Materials Conference, number AIAA-2006-1828. Newport, RI, May 1–4 2006.">EB06</a>]</span>.</p>
<div class="literal-block-wrapper docutils container" id="uq-rel-output-mv">
<div class="code-block-caption"><span class="caption-number">Listing 41 </span><span class="caption-text">Output from Reliability UQ example using mean value.</span><a class="headerlink" href="#uq-rel-output-mv" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span>MV Statistics for response_fn_1:
  Approximate Mean Response                  =  1.0000000000e+00
  Approximate Standard Deviation of Response =  5.9160798127e-01
  Importance Factor for TF1ln                =  7.1428570714e-01
  Importance Factor for TF2ln                =  7.1428572143e-01
  Importance Factor for TF1ln     TF2ln      = -4.2857142857e-01
Cumulative Distribution Function (CDF) for response_fn_1:
     Response Level  Probability Level  Reliability Index  General Rel Index
     --------------  -----------------  -----------------  -----------------
   4.0000000000e-01   1.5524721837e-01   1.0141851006e+00   1.0141851006e+00
   5.0000000000e-01   1.9901236093e-01   8.4515425050e-01   8.4515425050e-01
   5.5000000000e-01   2.2343641149e-01   7.6063882545e-01   7.6063882545e-01
   6.0000000000e-01   2.4948115037e-01   6.7612340040e-01   6.7612340040e-01
   6.5000000000e-01   2.7705656603e-01   5.9160797535e-01   5.9160797535e-01
   7.0000000000e-01   3.0604494093e-01   5.0709255030e-01   5.0709255030e-01
   7.5000000000e-01   3.3630190949e-01   4.2257712525e-01   4.2257712525e-01
   8.0000000000e-01   3.6765834596e-01   3.3806170020e-01   3.3806170020e-01
   8.5000000000e-01   3.9992305332e-01   2.5354627515e-01   2.5354627515e-01
   9.0000000000e-01   4.3288618783e-01   1.6903085010e-01   1.6903085010e-01
   1.0000000000e+00   5.0000000000e-01   0.0000000000e+00   0.0000000000e+00
   1.0500000000e+00   5.3367668035e-01  -8.4515425050e-02  -8.4515425050e-02
   1.1500000000e+00   6.0007694668e-01  -2.5354627515e-01  -2.5354627515e-01
   1.2000000000e+00   6.3234165404e-01  -3.3806170020e-01  -3.3806170020e-01
   1.2500000000e+00   6.6369809051e-01  -4.2257712525e-01  -4.2257712525e-01
   1.3000000000e+00   6.9395505907e-01  -5.0709255030e-01  -5.0709255030e-01
   1.3500000000e+00   7.2294343397e-01  -5.9160797535e-01  -5.9160797535e-01
   1.4000000000e+00   7.5051884963e-01  -6.7612340040e-01  -6.7612340040e-01
   1.5000000000e+00   8.0098763907e-01  -8.4515425050e-01  -8.4515425050e-01
   1.5500000000e+00   8.2372893005e-01  -9.2966967555e-01  -9.2966967555e-01
   1.6000000000e+00   8.4475278163e-01  -1.0141851006e+00  -1.0141851006e+00
   1.6500000000e+00   8.6405064339e-01  -1.0987005257e+00  -1.0987005257e+00
   1.7000000000e+00   8.8163821351e-01  -1.1832159507e+00  -1.1832159507e+00
   1.7500000000e+00   8.9755305196e-01  -1.2677313758e+00  -1.2677313758e+00
</pre></div>
</div>
</div>
<p>Additional reliability analysis and design results are provided in
Sections <a class="reference internal" href="../examples/additionalexamples.html#additional-logratio"><span class="std std-ref">Log Ratio</span></a> through <a class="reference internal" href="../examples/additionalexamples.html#additional-steel-column"><span class="std std-ref">Steel Column</span></a>.</p>
</section>
</section>
</section>
<section id="stochastic-expansion-methods">
<span id="uq-expansion"></span><h2>Stochastic Expansion Methods<a class="headerlink" href="#stochastic-expansion-methods" title="Link to this heading"></a></h2>
<p>The development of these techniques mirrors that of deterministic finite
element analysis through the utilization of the concepts of projection,
orthogonality, and weak convergence. The polynomial chaos expansion is
based on a multidimensional orthogonal polynomial approximation and the
stochastic collocation approach is based on a multidimensional
interpolation polynomial approximation, both formed in terms of
standardized random variables. A distinguishing feature of these two
methodologies is that the final solution is expressed as a functional
mapping, and not merely as a set of statistics as is the case for many
other methodologies (sampling, reliability, et al.). This makes these
techniques particularly attractive for use in multi-physics applications
which link different analysis packages. The first stochastic expansion
method is the polynomial chaos expansion
(PCE) <span id="id24">[<a class="reference internal" href="../../misc/bibliography.html#id109" title="R. Ghanem and J. R. Red-Horse. Propagation of probabilistic uncertainty in complex physical systems using a stochastic finite element technique. Physica D, 133:137-144, 1999.">GRH99</a>, <a class="reference internal" href="../../misc/bibliography.html#id108" title="R. G. Ghanem and P. D. Spanos. Stochastic Finite Elements: A Spectral Approach. Springer-Verlag, New York, 1991.">GS91</a>]</span>. For smooth functions (i.e.,
analytic, infinitely-differentiable) in <span class="math notranslate nohighlight">\(L^2\)</span> (i.e., possessing
finite variance), exponential convergence rates can be obtained under
order refinement for integrated statistical quantities of interest such
as mean, variance, and probability. Dakota implements the generalized
PCE approach using the Wiener-Askey
scheme <span id="id25">[<a class="reference internal" href="../../misc/bibliography.html#id310" title="D. Xiu and G. M. Karniadakis. The wiener-askey polynomial chaos for stochastic differential equations. SIAM J. Sci. Comput., 24(2):619–644, 2002.">XK02</a>]</span>, in which Hermite, Legendre,
Laguerre, Jacobi, and generalized Laguerre orthogonal polynomials are
used for modeling the effect of continuous random variables described by
normal, uniform, exponential, beta, and gamma probability distributions,
respectively <a class="footnote-reference brackets" href="#id67" id="id26" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>. These orthogonal polynomial selections are optimal
for these distribution types since the inner product weighting function
corresponds <a class="footnote-reference brackets" href="#id68" id="id27" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a> to the probability density functions for these
continuous distributions. Orthogonal polynomials can be computed for any
positive weight function, so these five classical orthogonal polynomials
may be augmented with numerically-generated polynomials for other
probability distributions (e.g., for lognormal, extreme value, and
histogram distributions). When independent standard random variables are
used (or computed through transformation), the variable expansions are
uncoupled, allowing the polynomial orthogonality properties to be
applied on a per-dimension basis. This allows one to mix and match the
polynomial basis used for each variable without interference with the
spectral projection scheme for the response.</p>
<p>In non-intrusive PCE, simulations are used as black boxes and the
calculation of chaos expansion coefficients for response metrics of
interest is based on a set of simulation response evaluations. To
calculate these response PCE coefficients, two classes of approaches are
available: spectral projection and regression. The spectral projection
approach projects the response against each basis function using inner
products and employs the polynomial orthogonality properties to extract
each coefficient. Each inner product involves a multidimensional
integral over the support range of the weighting function, which can be
evaluated numerically using sampling, tensor-product quadrature, Smolyak
sparse grid <span id="id28">[<a class="reference internal" href="../../misc/bibliography.html#id269" title="S.A. Smolyak. Quadrature and interpolation formulas for tensor products of certain classes of functions. Dokl. Akad. Nauk SSSR, 4:240–243, 1963.">Smo63</a>]</span>, or
cubature <span id="id29">[<a class="reference internal" href="../../misc/bibliography.html#id273" title="A. Stroud. Approximate Calculation of Multiple Integrals. Prentice Hall, 1971.">Str71</a>]</span> approaches. The regression approach
finds a set of PCE coefficients which best match a set of response
values obtained from either a design of computer experiments (“point
collocation” <span id="id30">[<a class="reference internal" href="../../misc/bibliography.html#id296" title="R. W. Walters. Towards stochastic fluid mechanics via polynomial chaos. In Proceedings of the 41st AIAA Aerospace Sciences Meeting and Exhibit, number AIAA-2003-0413. Reno, NV, January 6–9, 2003.">Wal03</a>]</span>) or from a randomly selected
subset of tensor Gauss points (“probabilistic
collocation” <span id="id31">[<a class="reference internal" href="../../misc/bibliography.html#id281" title="M.A. Tatang. Direct incorporation of uncertainty in chemical and environmental engineering systems. PhD thesis, MIT, 1995.">Tat95</a>]</span>). Various methods can be used to
solve the resulting linear system, including least squares methods for
over-determined systems and compressed sensing methods for
under-determined systems. Details of these methods are documented in
<a class="reference internal" href="../theory/stochastic.html#theory-uq-expansion-regress"><span class="std std-ref">Linear regression</span></a> and the necessary specifications
needed to activate these techniques are provided in the documentation
for the <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-polynomial_chaos.html"><span class="pre">polynomial_chaos</span></a></code> keyword.</p>
<p>Stochastic collocation (SC) is another stochastic expansion technique
for UQ that is closely related to PCE. As for PCE, exponential
convergence rates can be obtained under order refinement for integrated
statistical quantities of interest, provided that the response functions
are smooth with finite variance. The primary distinction is that,
whereas PCE estimates coefficients for known multivariate orthogonal
polynomial basis functions, SC forms multivariate interpolation
polynomial basis functions for known coefficients. The interpolation
polynomials may be either local or global and either value-based or
gradient-enhanced (four combinations: Lagrange interpolation, Hermite
interpolation, piecewise linear spline, and piecewise cubic spline), and
may be used within nodal or hierarchical interpolation formulations.
Interpolation is performed on structured grids such as tensor-product or
sparse grids. Starting from a tensor-product multidimensional
interpolation polynomial in the value-based case (Lagrange or piecewise
linear spline), we have the feature that the <span class="math notranslate nohighlight">\(i^{th}\)</span>
interpolation polynomial has a value of 1 at collocation point <span class="math notranslate nohighlight">\(i\)</span>
and a value of 0 for all other collocation points, leading to the use of
expansion coefficients that are just the response values at each of the
collocation points. In the gradient-enhanced case (<a class="reference internal" href="../theory/stochastic.html#theory-uq-expansion-interp-hermite"><span class="std std-ref">Hermite</span></a>
or <a class="reference internal" href="../theory/stochastic.html#theory-uq-expansion-interp-linear"><span class="std std-ref">piecewise cubic spline</span></a>),
SC includes both “type 1” and “type 2” interpolation
polynomials, where the former interpolate the values while producing
zero gradients and the latter interpolate the gradients while producing
zero values. Sparse interpolants are weighted sums of these tensor
interpolants;</p>
<p>however, they are only interpolatory for sparse grids
based on fully nested rules and will exhibit some interpolation error at
the collocation points for sparse grids based on non-nested rules. A key
to maximizing performance with SC is performing collocation using the
Gauss points and weights from the same optimal orthogonal polynomials
used in PCE. For use of standard Gauss integration rules (not nested
variants such as Gauss-Patterson or Genz-Keister) within tensor-product
quadrature, tensor PCE expansions and tensor SC interpolants are
equivalent in that identical polynomial approximations are
generated <span id="id32">[<a class="reference internal" href="../../misc/bibliography.html#id41" title="P. G. Constantine, D. F. Gleich, and G. Iaccarino. Spectral methods for parameterized matrix equations. SIAM Journal on Matrix Analysis and Applications, 31(5):2681–2699, 2010.">CGI10</a>]</span>. Moreover, this equivalence can
be extended to sparse grids based on standard Gauss rules, provided that
a sparse PCE is formed based on a weighted sum of tensor
expansions <span id="id33">[<a class="reference internal" href="../../misc/bibliography.html#id42" title="P. G. Constantine, M. S. Eldred, and E. T. Phipps. Sparse pseudospectral approximation method. Computer Methods in Applied Mechanics and Engineering, 229–232:1–12, July 2012.">CEP12</a>]</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="../theory/stochastic.html#theory-uq-expansion"><span class="std std-ref">Stochastic Expansion Methods</span></a> provides full algorithmic details for the PCE and SC methods.</p>
</div>
<p>A recent addition is functional tensor train (FTT) expansions which
leverage concepts from data/image compression using products of
dimensional basis “cores.” When the response admits a “low rank”
representation, this means that the size of the cores required for an
accurate recovery is not large and a compressed format for the expansion
can be achieved based on a tensor train composition. In Dakota, the
basis functions used within the core for each random dimension are
univariate orthogonal polynomials, similar to PCE. Solution for the
expansion coefficients is based on regression and employs a numerical
solution of a regularized nonlinear least squares problem. Both the rank
and polynomial order per dimension are resolution controls for the
method, and cross-validation procedures are provided to automate the
selection of the best settings for a given response data set. Additional
FTT theory will be provided in future releases as this capability is
promoted to a default part of the Dakota software configuration.</p>
<p>Finally, advanced multilevel and multifidelity approaches are provided
for PCE, SC, and FT (refer to
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-multilevel_polynomial_chaos.html"><span class="pre">multilevel_polynomial_chaos</span></a></code>,
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-multifidelity_polynomial_chaos.html"><span class="pre">multifidelity_polynomial_chaos</span></a></code>,
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-multilevel_function_train.html"><span class="pre">multilevel_function_train</span></a></code>,
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-multifidelity_function_train.html"><span class="pre">multifidelity_function_train</span></a></code>
and <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-multifidelity_stoch_collocation.html"><span class="pre">multifidelity_stoch_collocation</span></a></code>). These approaches decompose the
input-output mapping and form multiple expansions in order to reduce
reliance on the most expensive computational models by integrating
information from low cost modeling alternatives.</p>
<section id="uncertainty-quantification-examples-using-stochastic-expansions">
<span id="uq-stoch-exp-ex"></span><h3>Uncertainty Quantification Examples using Stochastic Expansions<a class="headerlink" href="#uncertainty-quantification-examples-using-stochastic-expansions" title="Link to this heading"></a></h3>
<section id="polynomial-chaos-expansion-for-rosenbrock">
<span id="uq-stoch-exp-ex-pce"></span><h4>Polynomial Chaos Expansion for Rosenbrock<a class="headerlink" href="#polynomial-chaos-expansion-for-rosenbrock" title="Link to this heading"></a></h4>
<p>A typical Dakota input file for performing an uncertainty quantification
using PCE is shown in <a class="reference internal" href="#uq-examples-pce-input"><span class="std std-numref">Listing 42</span></a>. In this
example, we compute CDF probabilities for six response levels of
Rosenbrock’s function. Since Rosenbrock is a fourth order polynomial and
we employ a fourth-order expansion using an optimal basis (Legendre for
uniform random variables), we can readily obtain a polynomial expansion
which exactly matches the Rosenbrock function. In this example, we
select Gaussian quadratures using an anisotropic approach (fifth-order
quadrature in <span class="math notranslate nohighlight">\(x_1\)</span> and third-order quadrature in <span class="math notranslate nohighlight">\(x_2\)</span>),
resulting in a total of 15 function evaluations to compute the PCE
coefficients.</p>
<div class="literal-block-wrapper docutils container" id="uq-examples-pce-input">
<div class="code-block-caption"><span class="caption-number">Listing 42 </span><span class="caption-text">Dakota input file for performing UQ using polynomial chaos expansions –
see <code class="docutils literal notranslate"><span class="pre">dakota/share/dakota/examples/users/rosen_uq_pce.in</span></code></span><a class="headerlink" href="#uq-examples-pce-input" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span><span class="c"># Dakota Input File: rosen_uq_pce.in</span>

<span class="k">environment</span>

<span class="k">method</span>
  polynomial_chaos
    quadrature_order = 5
    dimension_preference = 5 3
    samples_on_emulator = 10000
    seed = 12347
    response_levels = .1 1. 50. 100. 500. 1000.
    variance_based_decomp #interaction_order = 1

<span class="k">variables</span>
  uniform_uncertain = 2
    lower_bounds      = -2.  -2.
    upper_bounds      =  2.   2.
    descriptors       = &#39;x1&#39; &#39;x2&#39;

<span class="k">interface</span>
  analysis_drivers = &#39;rosenbrock&#39;
    direct

<span class="k">responses</span>
  response_functions = 1
  no_gradients
  no_hessians
</pre></div>
</div>
</div>
<p>The tensor product quadature points upon which the expansion is
calculated are shown in <a class="reference internal" href="#uq-examples-rosen-pce-points"><span class="std std-numref">Fig. 43</span></a>.
The tensor product generates all combinations of values from each
individual dimension: it is an all-way pairing of points.</p>
<figure class="align-center" id="uq-examples-rosen-pce-points">
<a class="reference internal image-reference" href="../../_images/rosen_pce_pts.png"><img alt="Rosenbrock polynomial chaos example: tensor product quadrature points." src="../../_images/rosen_pce_pts.png" style="height: 2.5in;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 43 </span><span class="caption-text">Rosenbrock polynomial chaos example: tensor product quadrature
points.</span><a class="headerlink" href="#uq-examples-rosen-pce-points" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Once the expansion coefficients have been calculated, some statistics
are available analytically and others must be evaluated numerically. For
the numerical portion, the input file specifies the use of 10000
samples, which will be evaluated on the expansion to compute the CDF
probabilities. In
<a class="reference internal" href="#uq-examples-pce-out"><span class="std std-numref">Listing 43</span></a>, excerpts from
the results summary are presented, where we first see a summary of the
PCE coefficients which exactly reproduce Rosenbrock for a Legendre
polynomial basis. The analytic statistics for mean, standard deviation,
and COV are then presented. For example, the mean is 455.66 and the
standard deviation is 606.56. The moments are followed by global
sensitivity indices (Sobol’ indices).This example shows that variable x1
has the largest main effect (0.497) as compared with variable x2 (0.296)
or the interaction between x1 and x2 (0.206). After the global
sensitivity indices, the local sensitivities are presented, evaluated at
the mean values. Finally, we see the numerical results for the CDF
probabilities based on 10000 samples performed on the expansion. For
example, the probability that the Rosenbrock function is less than 100
over these two uncertain variables is 0.342. Note that this is a very
similar estimate to what was obtained using 200 Monte Carlo samples,
with fewer true function evaluations.</p>
<div class="literal-block-wrapper docutils container" id="uq-examples-pce-out">
<div class="code-block-caption"><span class="caption-number">Listing 43 </span><span class="caption-text">Excerpt of UQ output for polynomial chaos example.</span><a class="headerlink" href="#uq-examples-pce-out" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span>Polynomial Chaos coefficients for response_fn_1:
        coefficient   u1   u2
        ----------- ---- ----
   4.5566666667e+02   P0   P0
  -4.0000000000e+00   P1   P0
   9.1695238095e+02   P2   P0
  -9.9475983006e-14   P3   P0
   3.6571428571e+02   P4   P0
  -5.3333333333e+02   P0   P1
  -3.9968028887e-14   P1   P1
  -1.0666666667e+03   P2   P1
  -3.3573144265e-13   P3   P1
   1.2829737273e-12   P4   P1
   2.6666666667e+02   P0   P2
   2.2648549702e-13   P1   P2
   4.8849813084e-13   P2   P2
   2.8754776338e-13   P3   P2
  -2.8477220582e-13   P4   P2
-------------------------------------------------------------------
Statistics derived analytically from polynomial expansion:

Moment-based statistics for each response function:
                            Mean           Std Dev          Skewness          Kurtosis
response_fn_1
  expansion:    4.5566666667e+02  6.0656024184e+02
  numerical:    4.5566666667e+02  6.0656024184e+02  1.9633285271e+00  3.3633861456e+00

Covariance among response functions:
[[  3.6791532698e+05 ]]

Local sensitivities for each response function evaluated at uncertain variable means:
response_fn_1:
 [ -2.0000000000e+00  2.4055757386e-13 ]

Global sensitivity indices for each response function:
response_fn_1 Sobol indices:
                                  Main             Total
                      4.9746891383e-01  7.0363551328e-01 x1
                      2.9636448672e-01  5.0253108617e-01 x2
                           Interaction
                      2.0616659946e-01 x1 x2

Statistics based on 10000 samples performed on polynomial expansion:

Probability Density Function (PDF) histograms for each response function:
PDF for response_fn_1:
          Bin Lower          Bin Upper      Density Value
          ---------          ---------      -------------
   6.8311107124e-03   1.0000000000e-01   2.0393073423e-02
   1.0000000000e-01   1.0000000000e+00   1.3000000000e-02
   1.0000000000e+00   5.0000000000e+01   4.7000000000e-03
   5.0000000000e+01   1.0000000000e+02   1.9680000000e-03
   1.0000000000e+02   5.0000000000e+02   9.2150000000e-04
   5.0000000000e+02   1.0000000000e+03   2.8300000000e-04
   1.0000000000e+03   3.5755437782e+03   5.7308286215e-05

Level mappings for each response function:
Cumulative Distribution Function (CDF) for response_fn_1:
     Response Level  Probability Level  Reliability Index  General Rel Index
     --------------  -----------------  -----------------  -----------------
   1.0000000000e-01   1.9000000000e-03
   1.0000000000e+00   1.3600000000e-02
   5.0000000000e+01   2.4390000000e-01
   1.0000000000e+02   3.4230000000e-01
   5.0000000000e+02   7.1090000000e-01
   1.0000000000e+03   8.5240000000e-01
-------------------------------------------------------------------
</pre></div>
</div>
</div>
</section>
<section id="uncertainty-quantification-example-using-stochastic-collocation">
<span id="uq-stoch-exp-ex-sc"></span><h4>Uncertainty Quantification Example using Stochastic Collocation<a class="headerlink" href="#uncertainty-quantification-example-using-stochastic-collocation" title="Link to this heading"></a></h4>
<p>Compared to the previous PCE example, this section presents a more
sophisticated example, where we use stochastic collocation built on an
anisotropic sparse grid defined from numerically-generated orthogonal
polynomials. The uncertain variables are lognormal in this example and
the orthogonal polynomials are generated from Gauss-Wigert recursion
coefficients <span id="id34">[<a class="reference internal" href="../../misc/bibliography.html#id264" title="I.C. Simpson. Numerical integration over a semi-infinite interval, using the lognormal distibution. Numerische Mathematik, 31:71–76, 1978.">Sim78</a>]</span> in combination with the
Golub-Welsch procedure <span id="id35">[<a class="reference internal" href="../../misc/bibliography.html#id125" title="G. H.. Golub and J. H. Welsch. Caclulation of gauss quadrature rules. Mathematics of Computation, 23(106):221–230, 1969.">GW69</a>]</span>. The input file
is shown in <a class="reference internal" href="#uq-figure11"><span class="std std-numref">Listing 44</span></a>. Note that the
dimension preference of <span class="math notranslate nohighlight">\((2,1)\)</span> is inverted to define a
<span class="math notranslate nohighlight">\(\gamma\)</span> weighting vector of <span class="math notranslate nohighlight">\((0.5,1)\)</span> (and
<span class="math notranslate nohighlight">\(\underline{\gamma}\)</span> of <span class="math notranslate nohighlight">\(0.5\)</span>) for use in the anisotropic
Smolyak index set constraint (see <a class="reference internal" href="../theory/stochastic.html#theory-uq-expansion-spectral-sparse"><span class="std std-ref">Smolyak sparse grids</span></a>). In this example, we compute CDF
probabilities for six response levels of Rosenbrock’s function. This
example requires 19 function evaluations to calculate the interpolating
polynomials in stochastic collocation and the resulting expansion
exactly reproduces Rosenbrock’s function. The placement of the points
generated by the sparse grid is shown in <a class="reference internal" href="#uq-figure11b"><span class="std std-numref">Fig. 44</span></a>.</p>
<div class="literal-block-wrapper docutils container" id="uq-figure11">
<div class="code-block-caption"><span class="caption-number">Listing 44 </span><span class="caption-text">Dakota input file for performing UQ using stochastic collocation –
see <code class="docutils literal notranslate"><span class="pre">dakota/share/dakota/examples/users/rosen_uq_sc.in</span></code></span><a class="headerlink" href="#uq-figure11" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span><span class="c"># Dakota Input File: rosen_uq_sc.in</span>

<span class="k">environment</span>

<span class="k">method</span>
  stoch_collocation
    sparse_grid_level = 3
    dimension_preference = 2 1
    samples_on_emulator = 10000 seed = 12347
    response_levels = .1 1. 50. 100. 500. 1000.
    variance_based_decomp #interaction_order = 1
  output silent

<span class="k">variables</span>
  lognormal_uncertain = 2
    means             =  1.   1.
    std_deviations    =  0.5  0.5
    descriptors       = &#39;x1&#39; &#39;x2&#39;

<span class="k">interface</span>
  analysis_drivers = &#39;rosenbrock&#39;
    direct

<span class="k">responses</span>
  response_functions = 1
  no_gradients
  no_hessians
</pre></div>
</div>
</div>
<figure class="align-center" id="uq-figure11b">
<a class="reference internal image-reference" href="../../_images/rosen_sc_pts.png"><img alt="Rosenbrock stochastic collocation example: sparse grid points." src="../../_images/rosen_sc_pts.png" style="height: 2.5in;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 44 </span><span class="caption-text">Rosenbrock stochastic collocation example: sparse grid points.</span><a class="headerlink" href="#uq-figure11b" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>Once the expansion coefficients have been calculated, some statistics
are available analytically and others must be evaluated numerically. For
the numerical portion, the input file specifies the use of 10000
samples, which will be evaluated on the expansion to compute the CDF
probabilities. In <a class="reference internal" href="#uq-figure12"><span class="std std-numref">Listing 45</span></a>, excerpts from
the results summary are presented. We first see the moment statistics
for mean, standard deviation, skewness, and kurtosis computed by
numerical integration (see <a class="reference internal" href="../theory/stochastic.html#theory-uq-expansion-moment"><span class="std std-ref">Analytic moments</span></a>), where the numerical row corresponds
to integration using the original response values and the expansion row
corresponds to integration using values from the interpolant. The
response covariance (collapsing to a single variance value for one
response function) and global sensitivity indices (Sobol’ indices) are
presented next. This example shows that variable x1 has the largest main
effect (0.99) as compared with variable x2 (0.0007) or the interaction
between x1 and x2 (0.005).</p>
<p>Finally, we see the numerical results for the
CDF probabilities based on 10000 samples performed on the expansion. For
example, the probability that the Rosenbrock function is less than 100
is 0.7233. Note that these results are significantly different than the
ones presented in <a class="reference internal" href="#uq-stoch-exp-ex-pce"><span class="std std-ref">Polynomial Chaos Expansion for Rosenbrock</span></a> because of
the different assumptions about the inputs: uniform[-2,2] versus
lognormals with means of 1.0 and standard deviations of 0.5.</p>
<div class="literal-block-wrapper docutils container" id="uq-figure12">
<div class="code-block-caption"><span class="caption-number">Listing 45 </span><span class="caption-text">Excerpt of UQ output for stochastic collocation example.</span><a class="headerlink" href="#uq-figure12" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span>Statistics derived analytically from polynomial expansion:

Moment-based statistics for each response function:
                            Mean           Std Dev          Skewness          Kurtosis
response_fn_1
  expansion:    2.5671972656e+02  2.0484189184e+03  2.7419241630e+02  1.9594567379e+06
  numerical:    2.5671972656e+02  2.0484189184e+03  2.7419241630e+02  1.9594567379e+06

Covariance among response functions:
[[  4.1960200651e+06 ]]

Global sensitivity indices for each response function:
response_fn_1 Sobol indices:
                                  Main             Total
                      9.9391978710e-01  9.9928724777e-01 x1
                      7.1275222945e-04  6.0802128961e-03 x2
                           Interaction
                      5.3674606667e-03 x1 x2

Statistics based on 10000 samples performed on polynomial expansion:

Level mappings for each response function:
Cumulative Distribution Function (CDF) for response_fn_1:
     Response Level  Probability Level  Reliability Index  General Rel Index
     --------------  -----------------  -----------------  -----------------
   1.0000000000e-01   1.8100000000e-02
   1.0000000000e+00   8.7800000000e-02
   5.0000000000e+01   5.8410000000e-01
   1.0000000000e+02   7.2330000000e-01
   5.0000000000e+02   9.2010000000e-01
   1.0000000000e+03   9.5660000000e-01
</pre></div>
</div>
</div>
</section>
</section>
</section>
<section id="importance-sampling-methods">
<span id="uq-importance"></span><h2>Importance Sampling Methods<a class="headerlink" href="#importance-sampling-methods" title="Link to this heading"></a></h2>
<p>Importance sampling is a method that allows one to estimate statistical
quantities such as failure probabilities (e.g. the probability that a
response quantity will exceed a threshold or fall below a threshold
value) in a way that is more efficient than Monte Carlo sampling. The
core idea in importance sampling is that one generates samples that
preferentially samples important regions in the space (e.g. in or near
the failure region or user-defined region of interest), and then
appropriately weights the samples to obtain an unbiased estimate of the
failure probability  <span id="id36">[<a class="reference internal" href="../../misc/bibliography.html#id272" title="R. Srinivasan. Importance Sampling. Springer-Verlag, 2002.">Sri02</a>]</span>. In importance
sampling, the samples are generated from a density which is called the
importance density: it is not the original probability density of the
input distributions. The importance density should be centered near the
failure region of interest. For black-box simulations such as those
commonly interfaced with Dakota, it is difficult to specify the
importance density a priori: the user often does not know where the
failure region lies, especially in a high-dimensional
space. <span id="id37">[<a class="reference internal" href="../../misc/bibliography.html#id277" title="L. P. Swiler and N. J. West. Importance sampling: promises and limitations. In Proceedings of the 12th AIAA Non-Deterministic Approaches Conference, number AIAA-2010-2850. 2010.">SW10</a>]</span></p>
<p>More formally, we define the objective of importance sampling as
calculating the probability, <span class="math notranslate nohighlight">\(P\)</span>, that the output will exceed a
threshold level. This is a failure probability, where the failure
probability is defined as some scalar function,
<span class="math notranslate nohighlight">\(y\left(\textbf{X}\right)\)</span>, exceeding a threshold, <span class="math notranslate nohighlight">\(T\)</span>,
where the inputs, <span class="math notranslate nohighlight">\(\textbf{X}\)</span>, are randomly distributed with
density, <span class="math notranslate nohighlight">\(\rho\left(\textbf{X}\right)\)</span>. When evaluating
<span class="math notranslate nohighlight">\(y\left(\textbf{X}\right)\)</span> is sufficiently expensive or <span class="math notranslate nohighlight">\(P\)</span>
is sufficiently small, Monte Carlo (MC) sampling methods to estimate
<span class="math notranslate nohighlight">\(P\)</span> will be infeasible due to the large number of function
evaluations required for a specified accuracy.</p>
<p>The probability of failure can be thought of as the mean rate of
occurrence of failure. The Monte Carlo (MC) estimate of <span class="math notranslate nohighlight">\(P\)</span> is
therefore the sample mean of the indicator function,
<span class="math notranslate nohighlight">\(I\left(\textbf{X}\right)\)</span>,</p>
<div class="math notranslate nohighlight" id="equation-mc-ind">
<span class="eqno">(26)<a class="headerlink" href="#equation-mc-ind" title="Link to this equation"></a></span>\[P_{MC}=\frac{1}{N}\sum_{i=1}^{N}I\left(\mathbf{X_i}\right)\ \ \textbf{X}\sim \rho\left(\textbf{X}\right),\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> samples, <span class="math notranslate nohighlight">\(\mathbf{X_i}\)</span>, are drawn from
<span class="math notranslate nohighlight">\(\rho\left(\textbf{X}\right)\)</span>, and the indicator function
<span class="math notranslate nohighlight">\(I\left(\textbf{X}\right)\)</span> is 1 if failure occurs and zero
otherwise.</p>
<p>Importance sampling draws samples from the importance density
<span class="math notranslate nohighlight">\(\rho'\left(\textbf{X}\right)\)</span> and scales the sample mean by the
importance density:</p>
<div class="math notranslate nohighlight" id="equation-eqn-ispfail">
<span class="eqno">(27)<a class="headerlink" href="#equation-eqn-ispfail" title="Link to this equation"></a></span>\[P_{IS}=\frac{1}{N}\sum_{i=1}^N \left(I\left(\mathbf{X_i}\right)\frac{\rho\left(\mathbf{X_i}\right)}{\rho'\left(\mathbf{X_i}\right)}\right)\ \ \textbf{X}\sim\rho'\left(\textbf{X}\right).\]</div>
<p>This reduces the asymptotic error variance from:</p>
<div class="math notranslate nohighlight">
\[\sigma_{err_{MC}}^2=\frac{{\rm E}\left[\left(I\left(\textbf{X}\right)-P\right)^2\right]}{N}\]</div>
<p>to</p>
<div class="math notranslate nohighlight" id="equation-eq-iserrorvar">
<span class="eqno">(28)<a class="headerlink" href="#equation-eq-iserrorvar" title="Link to this equation"></a></span>\[\sigma_{err_{IS}}^2=\frac{{\rm E}\left[\left(I\left(\textbf{X}\right)\frac{\rho\left(\textbf{X}\right)}{\rho'\left(\textbf{X}\right)}
-P\right)^2\right]}{N}.\]</div>
<p>Inspection of Eq. <a class="reference internal" href="#equation-eq-iserrorvar">(28)</a> reveals
<span class="math notranslate nohighlight">\(\sigma_{err_{IS}}^2=0\)</span> if <span class="math notranslate nohighlight">\(\rho'\left(\textbf{X}\right)\)</span>
equals the ideal importance density
<span class="math notranslate nohighlight">\(\rho^*\left(\textbf{X}\right)\)</span>,</p>
<div class="math notranslate nohighlight">
\[\rho^*\left(\textbf{X}\right)=\frac{I\left(\textbf{X}\right)\rho\left(\textbf{X}\right)}{P}.\]</div>
<p>However, <span class="math notranslate nohighlight">\(\rho^*\left(\textbf{X}\right)\)</span> is unknown a priori
because <span class="math notranslate nohighlight">\(I\left(\textbf{X}\right)\)</span> is only known where it has been
evaluated. Therefore, the required <span class="math notranslate nohighlight">\(P\)</span> in the denominator is also
unknown: this is what we are trying to estimate.</p>
<p>If importance sampling is to be effective, the practitioner must be able
to choose a good <span class="math notranslate nohighlight">\(\rho'\left(\textbf{X}\right)\)</span> without already
knowing <span class="math notranslate nohighlight">\(I\left(\textbf{X}\right)\)</span> everywhere. There is a danger:
a poor choice for <span class="math notranslate nohighlight">\(\rho'\left(\textbf{X}\right)\)</span> can put most of
the samples in unimportant regions and make <span class="math notranslate nohighlight">\(\sigma_{err_{IS}}^2\)</span>
much greater than <span class="math notranslate nohighlight">\(\sigma_{err_{MC}}^2\)</span>. In particular, importance
sampling can be challenging for very low probability events in
high-dimensional spaces where the output <span class="math notranslate nohighlight">\(y\)</span> is calculated by a
simulation. In these cases, usually one does not know anything a priori
about where the failure region exists in input space. We have developed
two importance sampling approaches which do not rely on the user
explicitly specifying an importance density.</p>
<section id="importance-sampling-method-based-on-reliability-approach">
<span id="uq-importance-rel"></span><h3>Importance Sampling Method based on Reliability Approach<a class="headerlink" href="#importance-sampling-method-based-on-reliability-approach" title="Link to this heading"></a></h3>
<p>The first method is based on ideas in reliability modeling
<a class="reference internal" href="#uq-reliability-local"><span class="std std-ref">Local Reliability Methods</span></a>. An initial Latin Hypercube sampling
is performed to generate an initial set of samples. These initial
samples are augmented with samples from an importance density as
follows: The variables are transformed to standard normal space. In the
transformed space, the importance density is a set of normal densities
centered around points which are in the failure region. Note that this
is similar in spirit to the reliability methods, in which importance
sampling is centered around a Most Probable Point (MPP). In the case of
the LHS samples, the importance sampling density will simply by a
mixture of normal distributions centered around points in the failure
region.</p>
<p>This method is specified by the keyword <code class="docutils literal notranslate"><span class="pre">importance_sampling</span></code>. The
options for importance sampling are as follows: <code class="docutils literal notranslate"><span class="pre">import</span></code> centers a
sampling density at one of the initial LHS samples identified in the
failure region. It then generates the importance samples, weights them
by their probability of occurence given the original density, and
calculates the required probability (CDF or CCDF level).
<code class="docutils literal notranslate"><span class="pre">adapt_import</span></code> is the same as <code class="docutils literal notranslate"><span class="pre">import</span></code> but is performed iteratively
until the failure probability estimate converges. <code class="docutils literal notranslate"><span class="pre">mm_adapt_import</span></code>
starts with all of the samples located in the failure region to build a
multimodal sampling density. First, it uses a small number of samples
around each of the initial samples in the failure region. Note that
these samples are allocated to the different points based on their
relative probabilities of occurrence: more probable points get more
samples. This early part of the approach is done to search for
“representative” points. Once these are located, the multimodal sampling
density is set and then the multi-modal adaptive method proceeds
similarly to the adaptive method (sample until convergence).</p>
</section>
<section id="gaussian-process-adaptive-importance-sampling-method">
<span id="uq-gpais"></span><h3>Gaussian Process Adaptive Importance Sampling Method<a class="headerlink" href="#gaussian-process-adaptive-importance-sampling-method" title="Link to this heading"></a></h3>
<p>The second importance sampling method in Dakota is the one we recommend,
at least for problems that have a relatively small number of input
variables (e.g. less than 10). This method, Gaussian Process Adaptive
Importance Sampling, is outlined in the paper
 <span id="id38">[<a class="reference internal" href="../../misc/bibliography.html#id47" title="K. Dalbey and L. P. Swiler. Gaussian Process Adaptive Importance Sampling. International Journal for Uncertainty Quantification, 4(2):133–149, 2014.">DS14</a>]</span>. This method starts with an initial set
of LHS samples and adds samples one at a time, with the goal of
adaptively improving the estimate of the ideal importance density during
the process. The approach uses a mixture of component densities. An
iterative process is used to construct the sequence of improving
component densities. At each iteration, a Gaussian process (GP)
surrogate is used to help identify areas in the space where failure is
likely to occur. The GPs are not used to directly calculate the failure
probability; they are only used to approximate the importance density.
Thus, the Gaussian process adaptive importance sampling algorithm
overcomes limitations involving using a potentially inaccurate surrogate
model directly in importance sampling calculations.</p>
<p>This method is specified with the keyword <code class="docutils literal notranslate"><span class="pre">gpais</span></code>. There are three
main controls which govern the behavior of the algorithm. <code class="docutils literal notranslate"><span class="pre">samples</span></code>
specifies the initial number of Latin Hypercube samples which are used
to create the initial Gaussian process surrogate. <code class="docutils literal notranslate"><span class="pre">emulator_samples</span></code>
specifies the number of samples taken on the latest Gaussian process
model each iteration of the algorithm. These samples are used in the
construction of the next importance sampling density. The default is
10,000 samples. The third control is <code class="docutils literal notranslate"><span class="pre">max_iterations</span></code>, which controls
the number of iterations of the algorithm. Each iteration, one
additional sample of the “true” simulation is taken. Thus, if
<code class="docutils literal notranslate"><span class="pre">samples</span></code> were set at 100 and <code class="docutils literal notranslate"><span class="pre">max_iterations</span></code> were set to 200,
there would be a total of 300 function evaluations of the simulator
model taken.</p>
</section>
</section>
<section id="adaptive-sampling-methods">
<span id="uq-adaptive"></span><h2>Adaptive Sampling Methods<a class="headerlink" href="#adaptive-sampling-methods" title="Link to this heading"></a></h2>
<p>The goal in performing adaptive sampling is to construct a surrogate
model that can be used as an accurate predictor to some expensive
simulation, thus it is to one’s advantage to build a surrogate that
minimizes the error over the entire domain of interest using as little
data as possible from the expensive simulation. The adaptive part
alludes to the fact that the surrogate will be refined by focusing
samples of the expensive simulation on particular areas of interest
rather than rely on random selection or standard space-filling
techniques.</p>
<section id="adaptive-sampling-based-on-surrogates">
<span id="uq-adaptive-surrogate"></span><h3>Adaptive sampling based on surrogates<a class="headerlink" href="#adaptive-sampling-based-on-surrogates" title="Link to this heading"></a></h3>
<p>At a high-level, the adaptive sampling pipeline is a four-step process:</p>
<ol class="arabic simple">
<li><p>Evaluate the expensive simulation (referred to as the true model) at
initial sample points</p></li>
<li><p>Fit/refit a surrogate model</p></li>
<li><p>Create a candidate set and score based on information from surrogate</p></li>
<li><p>Select a candidate point to evaluate the true model and Repeat 2-4</p></li>
</ol>
<p>In terms of the Dakota implementation, the adaptive sampling method
currently uses Latin Hypercube sampling (LHS) to generate the initial
points in Step 1 above. For Step 2, we use a Gaussian process model. The
user can specify the scoring metric used to select the next point (or
points) to evaluate and add to the set. We have investigated several
scoring metrics with which to evaluate candidate points for Step 3.
There are some classical ones such as distance (e.g. add a point which
maximizes the minimum distance to all of the existing points). This
distance metric tends to generate points that are space-filling. We have
investigated several methods that involve interesting topological
features of the space (e.g. points that are near saddle points). These
are an area of active investigation but are not currently included in
Dakota. The fitness metrics for scoring candidate points currently
include:</p>
<dl class="simple">
<dt>Predicted Variance</dt><dd><p>First introduced in <span id="id39">[<a class="reference internal" href="../../misc/bibliography.html#id191" title="David J. C. MacKay. Information-based objective functions for active data selection. Neural Computation, 4:590–604, 1992.">Mac92</a>]</span> and later used in
<span id="id40">[<a class="reference internal" href="../../misc/bibliography.html#id262" title="Sambu Seo, Marko Wallat, Thore Graepel, and Klaus Obermayer. Gaussian process regression: active data selection and test point rejection. In In Proceedings of the International Joint Conference on Neural Networks (IJCNN), 241–246. IEEE, 2000.">SWGO00</a>]</span>, this method uses the predicted variance of
the Gaussian process surrogate as the score of a candidate point.
Thus, the adaptively chosen points will be in areas of highest
uncertainty according to the Gaussian process model.</p>
</dd>
<dt>Distance</dt><dd><p>A candidate’s score is the Euclidean distance in domain space between
the candidate and its nearest neighbor in the set of points already
evaluated on the true model. Therefore, the most undersampled area of
the domain will always be selected. The adaptivity of this method
could be brought to question as it would chose the exact same points
regardless of the surrogate model used. However, it is useful to use
to compare other adaptive metrics to one that relies purely on
space-filling in an equivalent context.</p>
</dd>
</dl>
<dl class="simple">
<dt>Gradient</dt><dd><p>Similar to the above metric, a candidate’s nearest neighbor is
determined as in the distance metric, only now the score is the
absolute value of the difference in range space of the two points.
The range space values used are predicted from the surrogate model.
Though this method is called the gradient metric, it actually does
not take into account how close the candidate and its neighbor are in
domain space. This method attempts to evenly fill the range space of
the surrogate.</p>
</dd>
</dl>
<p>Note that in our approach, a Latin Hypercube sample is generated (a new
one, different from the initial sample) and the surrogate model is
evaluated at this points. These are the “candidate points” that are then
evaluated according to the fitness metric outlined above. The number of
candidates used in practice should be high enough to fill most of the
input domain: we recommend at least hundreds of points for a low-
dimensional problem. All of the candidates (samples on the emulator) are
given a score and then the highest-scoring candidate is selected to be
evaluated on the true model.</p>
<p>The adaptive sampling method also can generate batches of points to add
at a time. With batch or multi-point selection, the true model can be
evaluated in parallel and thus increase throughput before refitting our
surrogate model. This proposes a new challenge as the problem of
choosing a single point and choosing multiple points off a surrogate are
fundamentally different. Selecting the <span class="math notranslate nohighlight">\(n\)</span> best scoring candidates
is more than likely to generate a set of points clustered in one area
which will not be conducive to adapting the surrogate. We have
implemented several strategies for batch selection of points:</p>
<dl>
<dt><strong>Naive Selection</strong></dt><dd><p>This strategy will select the <span class="math notranslate nohighlight">\(n\)</span> highest scoring candidates
regardless of their position. This tends to group an entire round of
points in the same area.</p>
</dd>
<dt><strong>Distance Penalized Re-weighted Scoring</strong></dt><dd><p>In this strategy, the highest scoring candidate is selected and then
all remaining candidates are re-scored with a distance penalization
factor added in to the score. Only points selected within a round are
used for the distance penalization. The factor is the same as used in
the distance penalization scoring metrics from
<span id="id41">[<a class="reference internal" href="../../misc/bibliography.html#id192" title="Daniel P. Maljovec, Bei Wang, Ana Kupresanin, Gardar Johannesson, Valerio Pascucci, and Peer-Timo Bremer. Adaptive sampling with topological scores. International Journal for Uncertainty Quantification, 2012.">MWK+12</a>]</span>. First, compute all of the minimum
distances from each remaining candidate to the selected candidates.
Then, determine the median value of these distances. If the smallest
distance, <span class="math notranslate nohighlight">\(d\)</span>, between a point and the selected set is less
than the computed median distance its score is unaltered, otherwise
the score is multiplied by a value <span class="math notranslate nohighlight">\(\rho\)</span> determined by the
following equation:</p>
<div class="math notranslate nohighlight">
\[\rho = 1.5*d - 0.5*d^3\]</div>
</dd>
<dt><strong>Topological Maxima of Scoring Function</strong></dt><dd><p>In this strategy we look at the topology of the scoring function and
select the <span class="math notranslate nohighlight">\(n\)</span> highest maxima in the topology. To determine
local maxima, we construct the approximate Morse-Smale complex. If
the number of local maxima is less than <span class="math notranslate nohighlight">\(n\)</span>, we revert to the
distance strategy above. As a further extension, one may want to
filter low-persistence maxima, but to keep the framework general, we
chose to omit this feature as defining a threshold for what deems a
critical point as “low persistence” can vary drastically from problem
to problem.</p>
</dd>
<dt><strong>Constant Liar</strong></dt><dd><p>We adapt the constant liar strategy presented in
<span id="id42">[<a class="reference internal" href="../../misc/bibliography.html#id117" title="David Ginsbourger, Rodolphe Riche, and Laurent Carraro. Kriging is well-suited to parallelize optimization. In Yoel Tenne and Chi-Keong Goh, editors, Computational Intelligence in Expensive Optimization Problems, volume 2 of Adaptation, Learning, and Optimization, pages 131-162. Springer Berlin Heidelberg, 2010. URL: http://dx.doi.org/10.1007/978-3-642-10701-6_6, doi:10.1007/978-3-642-10701-6_6.">GRC10</a>]</span> with the scoring metrics. The
strategy first selects the highest scoring candidate, and then refits
the surrogate using a “lie” value at the point selected and repeating
until <span class="math notranslate nohighlight">\(n\)</span> points have been selected whereupon the lie values
are removed from the surrogate and the selected points are evaluated
on the true model and the surrogate is refit with these values.</p>
</dd>
</dl>
<p>The adaptive sampling method is specified by the method keyword
<code class="docutils literal notranslate"><span class="pre">adaptive_sampling</span></code>. There are many controls, including the number of
candidate samples to investigate each iteration (<code class="docutils literal notranslate"><span class="pre">emulator_samples</span></code>),
the fitness metric used in scoring candidates (<code class="docutils literal notranslate"><span class="pre">fitness_metric</span></code>), and
the number of iterations to perform the adaptive sampling
(<code class="docutils literal notranslate"><span class="pre">max_iterations</span></code>). For batch selection of points, one specifies a
<code class="docutils literal notranslate"><span class="pre">batch_selection</span></code> strategy and a <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>. The details of the
specification are provided in the Dakota reference manual.</p>
</section>
<section id="adaptive-sampling-based-on-dart-throwing">
<span id="uq-adaptive-darts"></span><h3>Adaptive sampling based on dart throwing<a class="headerlink" href="#adaptive-sampling-based-on-dart-throwing" title="Link to this heading"></a></h3>
<p><code class="docutils literal notranslate"><span class="pre">pof_darts</span></code> is a novel method for estimating the tail probability
(Probability of Failure) based on random sphere-packing in the uncertain
parameter space. Random points are sequentially sampled from the domain
and consequently surrounded by protecting spheres, with the constraint
that each new sphere center has to be outside all prior
spheres <span id="id43">[<a class="reference internal" href="../../misc/bibliography.html#id64" title="Mohamed S Ebeida, Scott A Mitchell, Laura P Swiler, Vicente J Romero, and Ahmad A Rushdi. Pof-darts: geometric adaptive sampling for probability of failure. Reliability Engineering &amp; System Safety, 155:64–77, 2016.">EMS+16</a>]</span>. The radius of each sphere is
chosen such that the entire sphere lies either in the failure or the
non-failure region. This radius depends of the function evaluation at
the disk center, the failure threshold and an estimate of the function
gradient at the disk center. After exhausting the sampling budget
specified by <code class="docutils literal notranslate"><span class="pre">build_samples</span></code>, which is the number of spheres per
failure threshold, the domain is decomposed into two regions. These
regions correspond to failure and non-failure categories, each
represented by the union of the spheres of each type. The volume of the
union of failure spheres gives a lower bound on the required estimate of
the probability of failure, while the volume of the union of the
non-failure spheres subtracted from the volume of the domain gives an
upper estimate. After all the spheres are constructed, we construct a
surrogate model, specified via a <code class="docutils literal notranslate"><span class="pre">model_pointer</span></code>, and sample the
surrogate model extensively to estimate the probability of failure for
each threshold.</p>
<p><code class="docutils literal notranslate"><span class="pre">pof_darts</span></code> handles multiple response functions and allows each to
have multiple failure thresholds. For each failure threshold
<code class="docutils literal notranslate"><span class="pre">pof_darts</span></code> will insert a number of spheres specified by the
user-input parameter “samples”. However, estimating the probability of
failure for each failure threshold would utilize the total number of
disks sampled for all failure thresholds. For each failure threshold,
the sphere radii changes to generate the right spatial decomposition.
The POF-Darts method is specified by the method keyword <code class="docutils literal notranslate"><span class="pre">pof_darts</span></code>.
The sample budget is specified by <code class="docutils literal notranslate"><span class="pre">build_samples</span></code>. By default, the
method employs a local approach to estimate the Lipschitz constant per
sphere.</p>
<p>The surrogate model used by the <code class="docutils literal notranslate"><span class="pre">pof_darts</span></code> method for extensive
sampling is specified using a <code class="docutils literal notranslate"><span class="pre">model_pointer</span></code>, and its parameters are
therefore defined in that model. It can typically be any global
surrogate in Dakota (e.g., Gaussian process, polynomial chaos expansion,
polynomial regression, etc). POF-Darts can also use piecewise-decomposed
surrogates which build local pieces of the surrogate over different
domain patches. The piecewise decomposition option is a new capability
added to Dakota to help construct surrogates in high-dimensional spaces,
using known function evaluations as well as gradient and Hessian
information, if available. The piecewise decomposition option is
declared using the keyword <code class="docutils literal notranslate"><span class="pre">domain_decomp</span></code> and currently supports
polynomial, Gaussian Process (GP), and Radial Basis Functions (RBF)
surroagte models only. For example: a polynomial regression global
surrogate is specified with <code class="docutils literal notranslate"><span class="pre">model</span> <span class="pre">polynomial</span></code>, its order is selected
using <code class="docutils literal notranslate"><span class="pre">surrogate_order</span></code>, and the piecewise decomposition option is
specified with <code class="docutils literal notranslate"><span class="pre">domain_decomp</span></code>. The <code class="docutils literal notranslate"><span class="pre">domain_decomp</span></code> option is
parametrized by a <code class="docutils literal notranslate"><span class="pre">cell_type</span></code> set by default to Voronoi cells, an
optional number of <code class="docutils literal notranslate"><span class="pre">support_layers</span></code>, and an optional
<code class="docutils literal notranslate"><span class="pre">discontinuity_detection</span></code> capability.
See <a class="reference internal" href="../inputfile/model.html#models-surf-piecewise-decomp"><span class="std std-ref">Piecewise Decomposition Option for Global Surrogate Models</span></a>
for more details.</p>
</section>
</section>
<section id="epistemic-nondeterministic-methods">
<span id="uq-epistemic"></span><h2>Epistemic Nondeterministic Methods<a class="headerlink" href="#epistemic-nondeterministic-methods" title="Link to this heading"></a></h2>
<p>Uncertainty quantification is often used as part of the risk assessment
of performance, reliability, and safety of engineered systems.
Increasingly, uncertainty is separated into two categories for analysis
purposes: aleatory and epistemic
uncertainty <span id="id44">[<a class="reference internal" href="../../misc/bibliography.html#id150" title="J. C. Helton, J. D. Johnson, W. L. Oberkampf, and C. B Storlie. A sampling-based computational strategy for the representation of epistemic uncertainty in model predictions with evidence theory. Comp. Methods in Applied Mechanics and Engineering, 196:3980-3998, 2007.">HJOS07</a>, <a class="reference internal" href="../../misc/bibliography.html#id222" title="W. L. Oberkampf and J. C. Helton. Evidence theory for engineering applications. Technical Report SAND2003-3559P, Sandia National Laboratories, Albuquerque, NM, 2003.">OH03</a>]</span>. Aleatory uncertainty is
also referred to as variability, irreducible or inherent uncertainty, or
uncertainty due to chance. Examples of aleatory uncertainty include the
height of individuals in a population, or the temperature in a
processing environment. Aleatory uncertainty is usually modeled with
probability distributions, and sampling methods such as Latin Hypercube
sampling in Dakota can be used to model aleatory uncertainty. In
contrast, epistemic uncertainty refers to lack of knowledge or lack of
information about a particular aspect of the simulation model, including
the system and environment being modeled. An increase in knowledge or
information relating to epistemic uncertainty will lead to a reduction
in the predicted uncertainty of the system response or performance. For
epistemic uncertain variables, typically one does not know enough to
specify a probability distribution on a variable. Epistemic uncertainty
is referred to as subjective, reducible, or lack of knowledge
uncertainty. Examples of epistemic uncertainty include little or no
experimental data for a fixed but unknown physical parameter, incomplete
understanding of complex physical phenomena, uncertainty about the
correct model form to use, etc.</p>
<p>There are many approaches which have been developed to model epistemic
uncertainty, including fuzzy set theory, possibility theory, and
evidence theory. It is also possible to use simple interval analysis in
an epistemic context. Interval analysis and evidence theory are
described in more detail below.</p>
<section id="interval-methods-for-epistemic-analysis">
<span id="uq-interval"></span><h3>Interval Methods for Epistemic Analysis<a class="headerlink" href="#interval-methods-for-epistemic-analysis" title="Link to this heading"></a></h3>
<p>In interval analysis, one assumes that nothing is known about an
epistemic uncertain variable except that its value lies somewhere within
an interval. In this situation, it is NOT assumed that the value has a
uniform probability of occuring within the interval. Instead, the
interpretation is that any value within the interval is a possible value
or a potential realization of that variable. In interval analysis, the
uncertainty quantification problem is one of determining the resulting
bounds on the output (defining the output interval) given interval
bounds on the inputs. Again, any output response that falls within the
output interval is a possible output with no frequency information
assigned to it.</p>
<p>We have the capability to perform interval analysis using either
<code class="docutils literal notranslate"><span class="pre">global_interval_est</span></code> or <code class="docutils literal notranslate"><span class="pre">local_interval_est</span></code>. In
the global approach, one uses either a global optimization method or a
sampling method to assess the bounds. <code class="docutils literal notranslate"><span class="pre">global_interval_est</span></code> allows the
user to specify either <code class="docutils literal notranslate"><span class="pre">lhs</span></code>, which performs Latin Hypercube Sampling
and takes the minimum and maximum of the samples as the bounds (no
optimization is performed) or <code class="docutils literal notranslate"><span class="pre">ego</span></code>. In the case of <code class="docutils literal notranslate"><span class="pre">ego</span></code>, the
efficient global optimization method is used to calculate bounds. The
ego method is described in
<a class="reference internal" href="optimization.html#opt-methods-gradientfree-global"><span class="std std-ref">Derivative-Free Global Methods</span></a>.
If the problem is amenable to local optimization methods (e.g. can
provide derivatives or use finite difference method to calculate
derivatives), then one can use local methods to calculate these bounds.
<code class="docutils literal notranslate"><span class="pre">local_interval_est</span></code> allows the user to specify either <code class="docutils literal notranslate"><span class="pre">sqp</span></code> which
is sequential quadratic programming, or <code class="docutils literal notranslate"><span class="pre">nip</span></code> which is a nonlinear
interior point method.</p>
<p>Note that when performing interval analysis, it is necessary to define
interval uncertain variables as described in
<a class="reference internal" href="../inputfile/variables.html#variables-uncertain"><span class="std std-ref">Uncertain Variables</span></a>. For interval
analysis, one must define only one interval per input variable, in
contrast with Dempster-Shafer evidence theory, where an input can have
several possible intervals. Interval analysis can be considered a
special case of Dempster-Shafer evidence theory where each input is
defined by one input interval with a basic probability assignment of
one. In Dakota, however, the methods are separate and semantic
differences exist in the output presentation. If you are performing a
pure interval analysis, we recommend using either
<code class="docutils literal notranslate"><span class="pre">global_interval_est</span></code> or <code class="docutils literal notranslate"><span class="pre">local_interval_est</span></code> instead of
<code class="docutils literal notranslate"><span class="pre">global_evidence</span></code> or <code class="docutils literal notranslate"><span class="pre">local_evidence</span></code>, for reasons of simplicity.</p>
<p>These interval methods can also be used as the outer loop within an
interval-valued probability analysis for propagating mixed aleatory and
epistemic uncertainty – refer to
<a class="reference internal" href="../advanced/advancedmodelrecursions.html#adv-models-mixed-uq-ivp"><span class="std std-ref">Interval-valued probability (IVP)</span></a> for
additional details.</p>
<p>An example of interval estimation is shown in
<a class="reference internal" href="#uq-examples-interval-input"><span class="std std-numref">Listing 46</span></a>, with example results in
<a class="reference internal" href="#uq-examples-interval-out"><span class="std std-numref">Listing 47</span></a>. This
example is a demonstration of calculating interval bounds for three
outputs of the cantilever beam problem. The cantilever beam problem is
described in detail in
<a class="reference internal" href="../examples/additionalexamples.html#additional-cantilever"><span class="std std-ref">Cantilever</span></a>. Given
input intervals of [1,10] on beam width and beam thickness, we can see
that the interval estimate of beam weight is approximately [1,100].</p>
<div class="literal-block-wrapper docutils container" id="uq-examples-interval-input">
<div class="code-block-caption"><span class="caption-number">Listing 46 </span><span class="caption-text">Dakota input file for performing UQ using interval analysis –
see <code class="docutils literal notranslate"><span class="pre">dakota/share/dakota/examples/users/cantilever_uq_global_interval.in</span></code></span><a class="headerlink" href="#uq-examples-interval-input" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span><span class="c"># Dakota Input File: cantilever_uq_global_interval.in</span>

<span class="k">environment</span>
  tabular_data
<span class="c">#    tabular_data_file = &#39;cantilever_uq_global_interval.dat&#39;</span>

<span class="k">method</span>
  global_interval_est ego
    seed = 1234567

<span class="k">variables</span>
  continuous_interval_uncertain = 2
    num_intervals   =  1    1
    interval_probabilities  =  1.0  1.0
    lower_bounds    =  1.0  1.0
    upper_bounds    = 10.0 10.0
    descriptors        &#39;w&#39;  &#39;t&#39;
  continuous_state = 4
    initial_state     =  40000. 29.E+6 500. 1000.
    descriptors       =  &#39;R&#39; &#39;E&#39; &#39;X&#39; &#39;Y&#39;

<span class="k">interface</span>
  analysis_drivers = &#39;cantilever&#39;
    direct

<span class="k">responses</span>
  response_functions = 3
  descriptors = &#39;weight&#39; &#39;stress&#39; &#39;displ&#39;
  no_gradients
  no_hessians
</pre></div>
</div>
</div>
<div class="literal-block-wrapper docutils container" id="uq-examples-interval-out">
<div class="code-block-caption"><span class="caption-number">Listing 47 </span><span class="caption-text">Excerpt of UQ output for interval example.</span><a class="headerlink" href="#uq-examples-interval-out" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span>------------------------------------------------------------------
Min and Max estimated values for each response function:
weight:  Min = 1.0000169352e+00  Max = 9.9999491948e+01
stress:  Min = -9.7749994284e-01  Max = 2.1499428450e+01
displ:  Min = -9.9315672724e-01  Max = 6.7429714485e+01
-----------------------------------------------------------------
</pre></div>
</div>
</div>
</section>
<section id="dempster-shafer-theory-of-evidence">
<span id="uq-dempshaf"></span><h3>Dempster-Shafer Theory of Evidence<a class="headerlink" href="#dempster-shafer-theory-of-evidence" title="Link to this heading"></a></h3>
<p>We have chosen to pursue evidence theory at Sandia as a way to model
epistemic uncertainty, in part because evidence theory is a
generalization of probability theory. Evidence theory is also referred
to as Dempster-Shafer theory or the theory of random
sets <span id="id45">[<a class="reference internal" href="../../misc/bibliography.html#id222" title="W. L. Oberkampf and J. C. Helton. Evidence theory for engineering applications. Technical Report SAND2003-3559P, Sandia National Laboratories, Albuquerque, NM, 2003.">OH03</a>]</span>. This section focuses on the use of
Dempster-Shafer evidence theory for propagating epistemic uncertainties.
When aleatory uncertainties are also present, we may choose either to
discretize the aleatory probability distributions into sets of intervals
and treat them as well-characterized epistemic variables, or we may
choose to segregate the aleatory uncertainties and treat them within an
inner loop. A nested Dempster-Shafer approach for propagating mixed
aleatory and epistemic uncertainty is described in
Section <a class="reference internal" href="../advanced/advancedmodelrecursions.html#adv-models-mixed-uq"><span class="std std-ref">Mixed Aleatory-Epistemic UQ</span></a>.</p>
<p>In evidence theory, there are two complementary measures of uncertainty:
belief and plausibility. Together, belief and plausibility can be
thought of as defining lower and upper bounds, respectively, on
probabilities. Belief and plausibility define the lower and upper limits
or intervals on probability values. Typical plots of cumulative and
complementary cumulative belief and plausibility functions are shown in
<a class="reference internal" href="#uq-figure15"><span class="std std-numref">Fig. 45</span></a> <span id="id46">[<a class="reference internal" href="../../misc/bibliography.html#id150" title="J. C. Helton, J. D. Johnson, W. L. Oberkampf, and C. B Storlie. A sampling-based computational strategy for the representation of epistemic uncertainty in model predictions with evidence theory. Comp. Methods in Applied Mechanics and Engineering, 196:3980-3998, 2007.">HJOS07</a>]</span>.</p>
<figure class="align-default" id="uq-figure15">
<img alt="Example cumulative belief and plausibility distribution functions on left; complementary cumulative belief and plausibility distribution functions on right" src="../../_images/belief_plaus.png" />
<figcaption>
<p><span class="caption-number">Fig. 45 </span><span class="caption-text">Example cumulative belief and plausibility distribution functions on
left; complementary cumulative belief and plausibility distribution
functions on right</span><a class="headerlink" href="#uq-figure15" title="Link to this image"></a></p>
</figcaption>
</figure>
<p>In evidence theory, it is not possible to specify one probability value.
Instead, there is a range of values that is consistent with the
evidence. The range of values is defined by belief and plausibility.
Note that no statement or claim is made about one value within an
interval being more or less likely than any other value.</p>
<p>In Dempster-Shafer evidence theory, the uncertain input variables are
modeled as sets of intervals. The user assigns a basic probability
assignment (BPA) to each interval, indicating how likely it is that the
uncertain input falls within the interval. The BPAs for a particular
uncertain input variable must sum to one. The intervals may be
overlapping, contiguous, or have gaps. In Dakota, an interval
uncertain variable is specified as <code class="docutils literal notranslate"><span class="pre">interval_uncertain</span></code>. When one
defines an interval type variable in Dakota, it is also necessary
to specify the number of intervals defined for each variable with
<code class="docutils literal notranslate"><span class="pre">iuv_num_intervals</span></code> as well the basic probability assignments per
interval, <code class="docutils literal notranslate"><span class="pre">iuv_interval_probs</span></code>, and the associated bounds per each
interval, <code class="docutils literal notranslate"><span class="pre">iuv_interval_bounds</span></code>.  <a class="reference internal" href="#uq-figure16"><span class="std std-numref">Listing 48</span></a> shows the input
specification for interval uncertain variables. The example has two
epistemic uncertain interval variables. The first uncertain variable
has three intervals and the second has two. The basic probability
assignments for the first variable are 0.5, 0.1, and 0.4, while the
BPAs for the second variable are 0.7 and 0.3. Note that it is possible
(and often the case) to define an interval uncertain variable with only
ONE interval. This means that you only know that the possible value of
that variable falls within the interval, and the BPA for that interval
would be 1.0. In the case we have shown, the interval bounds on the
first interval for the first variable are 0.6 and 0.9, and the bounds
for the second interval for the first variable are 0.1 to 0.5, etc.</p>
<div class="literal-block-wrapper docutils container" id="uq-figure16">
<div class="code-block-caption"><span class="caption-number">Listing 48 </span><span class="caption-text">Dakota input file for UQ example using Evidence Theory –
see <code class="docutils literal notranslate"><span class="pre">dakota/share/dakota/examples/users/textbook_uq_glob_evidence.in</span></code></span><a class="headerlink" href="#uq-figure16" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span><span class="c"># Dakota Input File: textbook_uq_glob_evidence.in</span>

<span class="k">environment</span>
  tabular_data
    tabular_data_file = &#39;textbook_uq_glob_evidence.dat&#39;

<span class="k">method</span>
  global_evidence lhs
    samples = 1000
    seed = 59334
    response_levels = 0.001 0.03 0.2 0.8 0.001 0.2 0.6 0.8
    probability_levels = 0.25 0.5 0.75 0.25 0.5 0.75
    distribution cumulative
  output verbose

<span class="k">variables</span>
  continuous_interval_uncertain = 2
    num_intervals   = 3 2
    interval_probabilities  = 0.5 0.1 0.4 0.7 0.3
    lower_bounds    = 0.6 0.1 0.5 0.3 0.6
    upper_bounds    = 0.9 0.5 1.0 0.5 0.8

<span class="k">interface</span>
  analysis_drivers = &#39;text_book&#39;
    direct

<span class="k">responses</span>
  response_functions = 2
  no_gradients
  no_hessians
</pre></div>
</div>
</div>
<p>Once the intervals, the BPAs, and the interval bounds are defined, the
user can run an epistemic analysis by specifying the method as either
<code class="docutils literal notranslate"><span class="pre">global_evidence</span></code> or <code class="docutils literal notranslate"><span class="pre">local_evidence</span></code> in the Dakota input file. Both
of these methods perform Dempster-Shafer calculations: the difference is
that the local method uses a local optimization algorithm to calculate
the interval bounds and the global method uses either sampling or a
global optimization approach to calculate an interval bound. These
differences are discussed in more detail below. The intervals and their
associated BPAs are then propagated through the simulation to obtain
cumulative distribution functions on belief and plausibility. As
mentioned above, belief is the lower bound on a probability estimate
that is consistent with the evidence, and plausibility is the upper
bound on a probability estimate that is consistent with the evidence.</p>
<p><a class="reference internal" href="#uq-figure17"><span class="std std-numref">Listing 49</span></a> shows results for the first
response function obtained when running the example in
<a class="reference internal" href="#uq-figure16"><span class="std std-numref">Listing 48</span></a>. In this example, there are 6
output intervals (as a result of the 2 interval input variables with 3
and 2 intervals, respectively). The output intervals are ordered to
obtain cumulative bound functions for both belief and plausibility. The
cumulative distribution function is presented for both belief (CBF) and
plausibility (CPF). The CBF value is the cumulative belief corresponding
to a certain output value. For example, the belief that the output value
is less than or equal to 0.2 for response 1 is 0.27, and the
plausibility that the output is less than or equal to 0.2 is 1 for
response 1. The belief that the output value is less than 0.6217 is
0.75, while the plausbility that the output is less than 0.0806 is 0.75.
The CBF and CPF may be plotted on a graph and interpreted as bounding
the cumulative distribution function (CDF), which is the probability
that the output is less than or equal to a certain value. The interval
bounds on probability values show the value of epistemic uncertainty
analysis: the intervals are usually much larger than expected, giving
one a truer picture of the total output uncertainty caused by lack of
knowledge or information about the epistemic input quantities.</p>
<div class="literal-block-wrapper docutils container" id="uq-figure17">
<div class="code-block-caption"><span class="caption-number">Listing 49 </span><span class="caption-text">Results of an Epistemic Uncertainty Quantification using Evidence Theory.</span><a class="headerlink" href="#uq-figure17" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span>Belief and Plausibility for each response function:
Cumulative Belief/Plausibility Functions (CBF/CPF) for response_fn_1:
     Response Level  Belief Prob Level   Plaus Prob Level
     --------------  -----------------   ----------------
   1.0000000000e-03   0.0000000000e+00   0.0000000000e+00
   3.0000000000e-02   0.0000000000e+00   2.7000000000e-01
   2.0000000000e-01   2.7000000000e-01   1.0000000000e+00
   8.0000000000e-01   9.3000000000e-01   1.0000000000e+00
  Probability Level  Belief Resp Level   Plaus Resp Level
  -----------------  -----------------   ----------------
   2.5000000000e-01   2.6187288772e-01   6.2609206069e-02
   5.0000000000e-01   2.9829775860e-01   6.3736734971e-02
   7.5000000000e-01   6.2173551556e-01   8.0596931719e-02
</pre></div>
</div>
</div>
<p>As in other nondeterministic methods, with <code class="docutils literal notranslate"><span class="pre">local_evidence</span></code> or
<code class="docutils literal notranslate"><span class="pre">global_evidence</span></code>, one can specify probability levels and response
levels. If response levels are specified, the belief and plausibility
function values corresponding to those response levels are calculated
(see Belief Prob Level and Plaus Prob Level in the tables shown in
<a class="reference internal" href="#uq-figure17"><span class="std std-numref">Listing 49</span></a>). Similarly, if probability
levels are specified, these are first interpreted to be belief values,
and the corresponding response levels are calculated (see Belief Resp
Level); then they are interpreted to be plausibility values and the
corresponding response levels are calculated (see Plaus Resp Level in
the table in <a class="reference internal" href="#uq-figure17"><span class="std std-numref">Listing 49</span></a>). We have recently
added the capability to support generalized reliability mappings in the
evidence methods. If the user specifies a generalized reliability level,
it will be first converted to a probability, then interpreted as a
belief and plausibility and the corresponding response levels will be
calculated. Likewise, if response levels are specified, the
corresponding belief and plausibility values will be mapped to bounds on
the generalized reliability levels.</p>
<p>To elaborate on the differences between <code class="docutils literal notranslate"><span class="pre">global_evidence</span></code> and
<code class="docutils literal notranslate"><span class="pre">local_evidence</span></code>: both of these methods take the Dempster-Shafer
structures specified on the inputs and calculate a resulting
Dempster-Shafer structure on the outputs (e.g. a cumulative belief and
plausibility function). To calculate the belief and plausibility
measures, it is necessary to calculate the minimum and maximum of the
response function in each “interval cell combination.” For example, in a
two variable problem, if the first variable had three intervals and
associated BPAs assigned and the second variable had two intervals and
associated BPAs assigned, there would be 6 interval cells in total. In
each of these six cells, one needs to identify a minimum and maximum
value of the response function. This is easy to do if the function is
monotonic in both variables, but in general it is not. We offer the
capability to use local optimization methods to calculate these bounds:
<code class="docutils literal notranslate"><span class="pre">local_evidence</span></code> allows the user to specify either <code class="docutils literal notranslate"><span class="pre">sqp</span></code> which is
sequential quadratic programming, or <code class="docutils literal notranslate"><span class="pre">nip</span></code> which is a nonlinear
interior point method. We also offer the capability to use global
methods to assess these interval cell bounds. <code class="docutils literal notranslate"><span class="pre">global_evidence</span></code> allows
the user to specify either <code class="docutils literal notranslate"><span class="pre">lhs</span></code>, which performs Latin Hypercube
Sampling and takes the minimum and maximum of the samples within each
cell as the bounds (no optimization is performed) or <code class="docutils literal notranslate"><span class="pre">ego</span></code>. In the
case of <code class="docutils literal notranslate"><span class="pre">ego</span></code>, the efficient global optimization method is used to
calculate bounds. The <code class="docutils literal notranslate"><span class="pre">ego</span></code> method is described in
<a class="reference internal" href="optimization.html#opt-methods-gradientfree-global"><span class="std std-ref">Derivative-Free Global Methods</span></a>.
Note that for a situation with many uncertain variables, each with a
fairly complicated Dempster-Shafer structure described by many
intervals, there will be a huge number of interval calls, and the
overall process of performing Dempster-Shafer analysis will be extremely
expensive. Reference <span id="id47">[<a class="reference internal" href="../../misc/bibliography.html#id279" title="G. Tang, G. Iaccarino, and M. S Eldred. Global sensitivity analysis for stochastic collocation expansion. In Proceedings of the 51st AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference (12th AIAA Non-Deterministic Approaches conference). Orlando, FL, April 12-15, 2010. AIAA Paper 2010-XXXX.">TIE10</a>]</span> provides more details
about the implementation of the optimization methods to perform
Dempster-Shafer calculations, as well as comparisons on test problems.</p>
</section>
</section>
<section id="bayesian-calibration-methods">
<span id="uq-bayesian"></span><h2>Bayesian Calibration Methods<a class="headerlink" href="#bayesian-calibration-methods" title="Link to this heading"></a></h2>
<p>In Bayesian calibration a “prior distribution” on a parameter is updated
through a Bayesian framework involving experimental data and a
likelihood function. Bayesian inference theory is best left to other
sources  <span id="id48">[<a class="reference internal" href="../../misc/bibliography.html#id168" title="M. C. Kennedy and A. O'Hagan. Bayesian calibration of computer models. Journal of the Royal Statistical Society, 63:425–464, 2001.">KOHagan01</a>]</span> and only a brief summary is given
here. In Bayesian methods, uncertain parameters are characterized by
probability density functions. These probability density functions
define the permissible parameter values - the support, as well as the
relative plausibility of each permissible parameter value. In the
context of calibration or any inference step, the probability density
function that describes knowledge before the incorporation of data is
called the prior,
<span class="math notranslate nohighlight">\(f_{\boldsymbol{\Theta}}\left( \boldsymbol{\theta}
\right)\)</span>.</p>
<p>Note: In Dakota, the prior distribution is characterized by the
properties of the active uncertain variables. Correlated priors are only
supported for unbounded normal, untruncated lognormal, uniform,
exponential, gumbel, frechet, and weibull distributions and require a
probability transformation by specifying <code class="docutils literal notranslate"><span class="pre">standardized_space</span></code>.</p>
<p>When data are available, the likelihood function describes how well each
parameter value is supported by the data. Bayes
Theorem <span id="id49">[<a class="reference internal" href="../../misc/bibliography.html#id161" title="E. T. Jaynes and G. Larry. Bretthorst. Probability theory : the logic of science. Cambridge University Press, Cambridge, UK; New York, NY, 2003.">JB03</a>]</span>, shown in
<a class="reference internal" href="#equation-eq-bayesthm">(29)</a>, is used for inference: to
derive the plausible parameter values, based on the prior probability
density and the data <span class="math notranslate nohighlight">\(\boldsymbol{d}\)</span>. The result is the posterior
probability density function of the parameters
<span class="math notranslate nohighlight">\(f_{\boldsymbol{{\Theta |D}}}\left( \boldsymbol{{\theta |d}}
\right)\)</span>. It is interpreted the same way as the prior, but includes the
information derived from the data.</p>
<div class="math notranslate nohighlight" id="equation-eq-bayesthm">
<span class="eqno">(29)<a class="headerlink" href="#equation-eq-bayesthm" title="Link to this equation"></a></span>\[{f_{\boldsymbol{\Theta |D}}}\left( \boldsymbol{\theta |d} \right) = \frac{{{f_{\boldsymbol{\Theta}}}\left( \boldsymbol{\theta}  \right)\mathcal{L}\left( \boldsymbol{\theta;d} \right)}}{{{f_{\boldsymbol{D}}}\left( \boldsymbol{d} \right)}}.\]</div>
<p>The likelihood function is used to describe how well a model’s
predictions are supported by the data. The likelihood function can be
written generally as:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}\left(\boldsymbol{{\theta ;d}} \right) =  \mathcal{F}(q(\boldsymbol{\theta)} -\boldsymbol{d}),\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> are the parameters of model quantity
of interest <span class="math notranslate nohighlight">\(q\)</span>. The form of the function <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> can
greatly influence the results. The specific likelihood function used in
Dakota is based on Gaussian probability density functions. This means
that we assume the difference between the model quantity (e.g. quantity
of interest returned from a computer simulation) and the experimental
observations are Gaussian:</p>
<div class="math notranslate nohighlight" id="equation-eq-model">
<span class="eqno">(30)<a class="headerlink" href="#equation-eq-model" title="Link to this equation"></a></span>\[d_i = q_i(\boldsymbol{\theta}) + \epsilon_i,\]</div>
<p>where <span class="math notranslate nohighlight">\(\epsilon_i\)</span> is a random variable that can encompass both
measurement errors on <span class="math notranslate nohighlight">\(d_i\)</span> and modeling errors associated with
the simulation quantity of interest <span class="math notranslate nohighlight">\(q_i\)</span>, for each of <span class="math notranslate nohighlight">\(n\)</span>
observations.</p>
<p>If we assume that all experiments and observations are independent, then
the probabilistic model defined by <a class="reference internal" href="#equation-eq-model">(30)</a>
results in a likelihood function for <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> that is
the product of <span class="math notranslate nohighlight">\(n\)</span> normal probability density functions:</p>
<div class="math notranslate nohighlight" id="equation-eq-likelihood">
<span class="eqno">(31)<a class="headerlink" href="#equation-eq-likelihood" title="Link to this equation"></a></span>\[\mathcal{L}(\boldsymbol{{\theta};d}) = \prod_{i=1}^n
\frac{1}{\sigma_d \sqrt{2\pi}} \exp
\left[ - \frac{\left(d_i-q_i(\boldsymbol{{\theta}})\right)^2}{2{\sigma_d}^2} \right],\]</div>
<p>where <span class="math notranslate nohighlight">\({\sigma_d}^2\)</span> refers to the measurement error of the data,
assumed constant across all data observations in this case.</p>
<p>We also support the more general case of a full covariance matrix,
<span class="math notranslate nohighlight">\(\boldsymbol{\Sigma_d}\)</span>, that specifies the covariance between
each observation <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>. In this case, the likelihood
is commonly written in log form, where the log-likelihood is:</p>
<div class="math notranslate nohighlight">
\[\label{eqn:LogLikelihood}
\log{\mathcal{L}(\boldsymbol{{\theta};d})} \propto % =-0.5 {R}^{T} {\Sigma_d}^{-1} {R}
-\frac{1}{2} \boldsymbol{r}^T \boldsymbol{\Sigma_d}^{-1} \boldsymbol{r},\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{r}\)</span> is the vector of residuals between the data
points and the model quantity of interest,
<span class="math notranslate nohighlight">\(q(\boldsymbol{\theta})-\boldsymbol{d}\)</span>.</p>
<p>Dakota admits four <code class="docutils literal notranslate"><span class="pre">experiment_variance_type</span></code> options to specify the
measurement error covariance: <code class="docutils literal notranslate"><span class="pre">none</span></code> for no measurement error
specified (in this case, the variance is assumed to be one), <code class="docutils literal notranslate"><span class="pre">scalar</span></code>
where a constant value <span class="math notranslate nohighlight">\({\sigma_d}^2\)</span> is given for all
observations, <code class="docutils literal notranslate"><span class="pre">diagonal</span></code> where a value is specified for the diagonal
elements of the covariance matrix <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma_d}\)</span> meaning
that each observation has its own measurement error but there are no
cross terms, and <code class="docutils literal notranslate"><span class="pre">matrix</span></code> where the full covariance matrix
<span class="math notranslate nohighlight">\(\boldsymbol{\Sigma_d}\)</span> is specified. The <code class="docutils literal notranslate"><span class="pre">diagonal</span></code> and
<code class="docutils literal notranslate"><span class="pre">matrix</span></code> terms are only available for field response data. In contrast
to earlier versions of Dakota, all measurement error variance should be
specified with units of variance/covariance, not standard deviation.</p>
<p>Markov Chain Monte Carlo (MCMC) is the prototypical method used to
estimate posterior parameter densities, given the observational data and
the priors. There are many references that describe the basic
algorithm <span id="id50">[<a class="reference internal" href="../../misc/bibliography.html#id110" title="W.R. Gilks, S. Richardson, and D.J. Spiegelhalter. Markov chain Monte Carlo in practice. Chapman &amp; Hall, 1998.">GRS98</a>]</span> and this is an active research area.
MCMC algorithms may require hundreds of thousands of steps to converge,
depending on dimensionality, response nonlinearity, and the desired set
of posterior statistics. Since each iteration involves an evaluation of
the model to obtain <span class="math notranslate nohighlight">\(q(\boldsymbol{\theta})\)</span>, surrogate models of
expensive simulations are often employed to make the MCMC process
tractable.</p>
<p>Dakota offers five approaches for Bayesian calibration: QUESO, DREAM,
GPMSA, MUQ, and WASABI. They are specified with the
<code class="docutils literal notranslate"><span class="pre">bayes_calibration</span></code> keyword in combination with the <code class="docutils literal notranslate"><span class="pre">queso</span></code>,
<code class="docutils literal notranslate"><span class="pre">dream</span></code>, <code class="docutils literal notranslate"><span class="pre">gpmsa</span></code>, <code class="docutils literal notranslate"><span class="pre">muq</span></code>, or <code class="docutils literal notranslate"><span class="pre">wasabi</span></code> selections, respectively.
The QUESO and GPMSA methods use components from the QUESO library
(Quantification of Uncertainty for Estimation, Simulation, and
Optimization) developed at The University of Texas at Austin. It
implements the Delayed Rejection and Adaptive
Metropolis <span id="id51">[<a class="reference internal" href="../../misc/bibliography.html#id136" title="Heikki Haario, Marko Laine, Antonietta Mira, and Eero Saksman. DRAM: efficient adaptive MCMC. Statistics and Computing, 16:339-354, 2006. URL: http://dx.doi.org/10.1007/s11222-006-9438-0.">HLMS06</a>]</span> (DRAM) algorithm, among others.
Algorithm variants selectively combine the delayed rejection and
adaptive elements. The QUESO/GPMSA capability is based on the GPMSA
Matlab toolbox developed at Los Alamos National Laboratory and uses
tightly integrated Gaussian process models during calibration. The
Dakota implementation of QUES0/GPMSA is in a prototype stage. DREAM uses
an implementation of DiffeRential Evolution Adaptive Metropolis
developed by John Burkardt. The DREAM approach runs concurrent chains
for global exploration, and automatically tunes the proposal covariance
during the process by a self-adaptive randomized subspace
sampling <span id="id52">[<a class="reference internal" href="../../misc/bibliography.html#id293" title="J. A. Vrugt, C. J. F. ter Braak, C. G. H. Diks, B. A. Robinson, J. M. Hyman, and D. Higdon. Accelerating Markov chain Monte Carlo simulation by self-adaptive differential evolution with randomized subspace sampling. International Journal of Nonlinear Scientific Numerical Simulation, 2009.">VtBD+09</a>]</span>. MUQ uses components from the MIT
Uncertainty Quantification library and also implements the Delayed
Rejection and Adaptive Metropolis <span id="id53">[<a class="reference internal" href="../../misc/bibliography.html#id136" title="Heikki Haario, Marko Laine, Antonietta Mira, and Eero Saksman. DRAM: efficient adaptive MCMC. Statistics and Computing, 16:339-354, 2006. URL: http://dx.doi.org/10.1007/s11222-006-9438-0.">HLMS06</a>]</span> (DRAM)
algorithms, among others. The prototype WASABI method is an MCMC-free
Bayesian calibration approach. QUESO/DRAM and variants are the most
well-developed within Dakota.</p>
<section id="queso">
<span id="uq-bayesian-queso"></span><h3>QUESO<a class="headerlink" href="#queso" title="Link to this heading"></a></h3>
<p>The QUESO library includes several sampling algorithm variants. One can
use a standard Metropolis-Hastings algorithm (<code class="docutils literal notranslate"><span class="pre">metropolis_hastings</span></code>),
adaptive Metropolis (<code class="docutils literal notranslate"><span class="pre">adaptive_metropolis</span></code>) for adapting the proposal
covariance during the sampling, delayed rejection
(<code class="docutils literal notranslate"><span class="pre">delayed_rejection</span></code>) for backtracking from sample rejections, the
full DRAM (<code class="docutils literal notranslate"><span class="pre">dram</span></code>) which involves both delayed rejection and adaptive
Metropolis, or a multi-level algorithm (<code class="docutils literal notranslate"><span class="pre">multilevel</span></code>). This last
option is not yet production-ready in Dakota.</p>
<p>With any choice of sampling algorithm, one may manually set the burn in
period for the MCMC chain with <code class="docutils literal notranslate"><span class="pre">burn_in_samples</span></code>. If a
<code class="docutils literal notranslate"><span class="pre">sub_sampling_period</span></code> is specified, the MCMC chain is further filtered
such that only the sample at the beginning of each period is in the
final MCMC chain. The <code class="docutils literal notranslate"><span class="pre">sub_sampling_period</span></code> should therefore be
greater than or equal to the correlation length of the samples.</p>
<p>With the QUESO method, one may run the MCMC sampling on the simulation
model directly. However, if the model is expensive, use of a surrogate
(emulator) model is recommended. Options include a Gaussian process, a
polynomial chaos expansion, or a stochastic collocation expansion.</p>
<p>The proposal covariance refers to the covariance structure of a
multivariate normal distribution, which governs sample generation in the
chain. One may specify <code class="docutils literal notranslate"><span class="pre">proposal_covariance</span></code>, followed by <code class="docutils literal notranslate"><span class="pre">prior</span></code>
(the default), <code class="docutils literal notranslate"><span class="pre">values</span></code>, <code class="docutils literal notranslate"><span class="pre">filename</span></code>, or <code class="docutils literal notranslate"><span class="pre">derivatives</span></code>. With the
<code class="docutils literal notranslate"><span class="pre">prior</span></code> setting, the proposal covariance will be set to the variance
of the prior distributions of the parameters being calibrated. When
specifying the proposal covariance with input file values or from a
separate file, the user may specify only the diagonals of the covariance
matrix or the full covariance matrix.</p>
<p>The derivatives option will use derivatives from the simulation or
emulator model to form or approximate the Hessian of the misfit function
(the negative log likelihood). Especially when derivative information is
available inexpensively (e.g. from an emulator), the derivative-based
proposal covariance forms a more accurate proposal distribution,
resulting in lower rejection rates and faster chain mixing. When using
an emulator, the derivative-based proposal covariance should be updated
periodically using the <code class="docutils literal notranslate"><span class="pre">posterior_adaptive</span></code> specification. This will
add simulation truth evaluations in areas of high-likelihood to the
emulator training data, thus refining the Hessian. For more detail about
derivative-based formulations involving the misfit Hessian, refer to
<a class="reference internal" href="../theory/bayesian.html#uq-bayes-prop"><span class="std std-ref">Proposal Densities</span></a>.</p>
<p>An additional control for QUESO is to perform a logit transformation
(<code class="docutils literal notranslate"><span class="pre">logit_transform</span></code>) which performs an internal variable transformation
from bounded domains to unbounded domains.</p>
<p>This option can be helpful
when regions of high posterior density exist in the corners of a
multi-dimensional bounded domain. In these cases, it may be difficult to
generate feasible samples from the proposal density, and transformation
to unbounded domains may greatly reduce sample rejection rates.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">pre_solve</span></code> option will perform a deterministic gradient-based
optimization before the MCMC sampling to get a good starting point for
the chain. This pre-solve seeks to maximize the log-posterior (the
log-likelihood minus the log-prior) to identify the maximum a posteriori
probability point, also called the MAP point. The Markov Chain will then
start at the MAP point, which can circumvent a lot of initial searching
for high posterior probability points. The pre-solve option can be used
with an emulator or with no emulator.</p>
<p>Credible and prediction intervals will be calculated if
<code class="docutils literal notranslate"><span class="pre">probability_levels</span></code> is specified. Credible intervals propagate
uncertainties in parameter density information to the quantity of
interest and quantify how well the model fits the provided data, while
prediction intervals propagate both parameter and experimental
measurement uncertainties and contain the next experimental or simulated
observation with the specified probability. Further details can be found
in <span id="id54">[<a class="reference internal" href="../../misc/bibliography.html#id268" title="R.C. Smith. Uncertainty Quantification: Theory, Implementation, and Applications. Computational Science and Engineering. SIAM, 2013.">Smi13</a>]</span>. If <code class="docutils literal notranslate"><span class="pre">probability_levels</span></code> is
specified, credible intervals will always be calculated. Prediction
intervals will only be calculated if <code class="docutils literal notranslate"><span class="pre">experiment_variance_type</span></code> is
also specified in the <code class="docutils literal notranslate"><span class="pre">responses</span></code> block. By specifying
<code class="docutils literal notranslate"><span class="pre">posterior_stats</span></code>, information-theoretic metrics may be calculated
using the posterior distribution of parameters. If the <code class="docutils literal notranslate"><span class="pre">kl_divergence</span></code>
option is selected, the Kullback-Leibler Divergence will be calculated
between the posterior and the prior distributions such that</p>
<div class="math notranslate nohighlight">
\[D_{KL} = \int {f_{\boldsymbol{\Theta |D}}}\left( \boldsymbol{\theta |d} \right)
\log \frac{ {f_{\boldsymbol{\Theta |D}}}\left( \boldsymbol{\theta |d} \right) }
{{f_{\boldsymbol{\Theta}}}\left( \boldsymbol{\theta}  \right)}
d\boldsymbol{\theta}.\]</div>
<p>This quantity represents the amount of information gained about the
parameters during the Bayesian update. Further details regarding the
calculation and use of <span class="math notranslate nohighlight">\(D_{KL}\)</span> can be found
in <a class="reference internal" href="../theory/bayesian.html#uq-info-theory"><span class="std std-ref">Information Theoretic Tools</span></a>.</p>
</section>
<section id="dream">
<h3>DREAM<a class="headerlink" href="#dream" title="Link to this heading"></a></h3>
<p>For the DREAM method, one can define the number of chains (minimum 3)
used with the
<code class="docutils literal notranslate"><span class="pre">chains</span></code> specification. The total number of generations per chain in
DREAM is the number of samples divided by the number of chains. The
number of chains randomly selected to be used in the crossover each time
a crossover occurs is <code class="docutils literal notranslate"><span class="pre">crossover_chain_pairs</span></code>. There is an extra
adaptation during burn-in, in which DREAM estimates a distribution of
crossover probabilities that favors large jumps over smaller ones in
each of the chains. Normalization is required to ensure that all of the
input dimensions contribute equally. In this process, a discrete number
of candidate points for each crossover value is generated, which can be
specified with <code class="docutils literal notranslate"><span class="pre">num_cr</span></code>. The <code class="docutils literal notranslate"><span class="pre">gr_threshold</span></code> control is the
convergence tolerance for the Gelman-Rubin statistic, which governs the
convergence of the multiple chain process. The integer <code class="docutils literal notranslate"><span class="pre">jump_step</span></code>
forces a long jump every <code class="docutils literal notranslate"><span class="pre">jump_step</span></code> generations. For more details
about these parameters, refer to <span id="id55">[<a class="reference internal" href="../../misc/bibliography.html#id293" title="J. A. Vrugt, C. J. F. ter Braak, C. G. H. Diks, B. A. Robinson, J. M. Hyman, and D. Higdon. Accelerating Markov chain Monte Carlo simulation by self-adaptive differential evolution with randomized subspace sampling. International Journal of Nonlinear Scientific Numerical Simulation, 2009.">VtBD+09</a>]</span>. Credible and
prediction intervals can be calculated by specifying
<code class="docutils literal notranslate"><span class="pre">probability_levels</span></code>, and statistics regarding the posterior may be
calculated by specifying <code class="docutils literal notranslate"><span class="pre">posterior_stats</span></code>, as described in
<a class="reference internal" href="#uq-bayesian-queso"><span class="std std-ref">QUESO</span></a>.</p>
</section>
<section id="gpmsa">
<h3>GPMSA<a class="headerlink" href="#gpmsa" title="Link to this heading"></a></h3>
<p>Core to GPMSA is the construction of a Gaussian process emulator from
simulation runs collected at various settings of input parameters. The
emulator is a statistical model of the system response, and it is used
to incorporate the observational data to improve system predictions and
constrain or calibrate the unknown parameters. The GPMSA code draws
heavily on the theory developed in the seminal Bayesian calibration
paper by Kennedy and O’Hagan <span id="id56">[<a class="reference internal" href="../../misc/bibliography.html#id168" title="M. C. Kennedy and A. O'Hagan. Bayesian calibration of computer models. Journal of the Royal Statistical Society, 63:425–464, 2001.">KOHagan01</a>]</span>. The particular
approach developed by the Los Alamos group, and implemented in QUESO and
therefore Dakota, is provided in <span id="id57">[<a class="reference internal" href="../../misc/bibliography.html#id151" title="D. Higdon, J. Gattiker, B. Williams, and M. Rightley. Computer model calibration using high-dimensional output. Journal of the American Statistical Association, 103(482):570–583, 2008.">HGWR08</a>]</span>. It includes
an embedded discrepancy model and the ability to estimate various
hyper-parameters of the Gaussian process, observation error model, and
discrepancy model. Dakota’s <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-gpmsa.html"><span class="pre">gpmsa</span></a></code> capability is an experimental
prototype with a number of limitations.</p>
</section>
<section id="muq">
<h3>MUQ<a class="headerlink" href="#muq" title="Link to this heading"></a></h3>
<p>MUQ is the MIT Uncertainty Quantification library. See
<a class="reference external" href="https://bitbucket.org/mituq/muq2/src/master/">https://bitbucket.org/mituq/muq2/src/master/</a> and
<a class="reference external" href="https://mituq.bitbucket.io/index.html">https://mituq.bitbucket.io/index.html</a> for additional documentation.
Dakota currently exposes six MCMC approaches from MUQ:</p>
<ul class="simple">
<li><p>Adaptive Metroplis (<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-muq-adaptive_metropolis.html"><span class="pre">adaptive_metropolis</span></a></code>)</p></li>
<li><p>Delayed rejection (<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-muq-delayed_rejection.html"><span class="pre">delayed_rejection</span></a></code>)</p></li>
<li><p>Dimension-independent, likelihood informed (<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-muq-dili.html"><span class="pre">dili</span></a></code>)</p></li>
<li><p>Delayed rejection, adaptive Metropolis (<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-muq-dram.html"><span class="pre">dram</span></a></code>)</p></li>
<li><p>Metropolis-adjusted Langevin algorithm (<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-muq-mala.html"><span class="pre">mala</span></a></code>)</p></li>
<li><p>Metropolis-Hastings (<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-muq-metropolis_hastings.html"><span class="pre">metropolis_hastings</span></a></code>)</p></li>
</ul>
<p>MUQ is an experimental Dakota capability, and as such, it is not turned on by default,
and must be explicitly enabled when compiling Dakota.</p>
</section>
<section id="wasabi">
<h3>WASABI<a class="headerlink" href="#wasabi" title="Link to this heading"></a></h3>
<p>WASABI differs from the other Bayesian approaches in that it is not an
MCMC-based approach. Instead, it is based on the idea of “consistent
Bayes” which is outlined in  <span id="id58">[<a class="reference internal" href="../../misc/bibliography.html#id328" title="T. Butler, J. D. Jakeman, and T. M. Wildey. A consistent bayesian formulation for stochastic inverse problems based on push-forward measures. arXiv, math.NA:1704.00680, 2017. URL: http://arxiv.org/abs/1704.00680.">BJW17</a>]</span>. This
approach to stochastic inference uses measure-theoretic principles to
construct a probability measure or density on model parameters that is
consistent with the model and the data. The idea is that the probability
measure on the parameters, when “pushed-foward” through the
computational model, will give results that match the probability
measure on the observational data.</p>
<p>We use a similar notation as with the Bayesian methods, but the
interpretation is different here. The goal is to identify the posterior
density on the parameters, <span class="math notranslate nohighlight">\(\pi_{post}({\theta})\)</span>, which is equal
to the prior density on the parameters times a ratio. The numerator of
the ratio, <span class="math notranslate nohighlight">\(\pi_{D}^{obs}\)</span>, describes the relative likelihood that
the output of the model corresponds to the observed data <span class="math notranslate nohighlight">\({D}\)</span>:
this is the density of the data evaluated at the model output.
<span class="math notranslate nohighlight">\(q(\boldsymbol{\theta})\)</span> refers to the model output.
<span class="math notranslate nohighlight">\(\pi_{D}^{q_{prior}}\)</span> refers to the push-forward of the prior
through the model and represents a forward propagation of uncertainty.</p>
<div class="math notranslate nohighlight">
\[\pi_{post}(\boldsymbol{\theta})=\pi_{prior}(\boldsymbol{\theta})\frac{\pi_{D}^{obs}(q(\boldsymbol{\theta}))}{\pi_{D}^{q_{prior}}(q(\boldsymbol{\theta}))}.
\label{eq:consistentBayesEq}\]</div>
<p><a class="reference internal" href="../theory/bayesian.html#uq-bayes-basic"><span class="std std-ref">The Fundamentals section of the main Bayesian Methods theory page</span></a>
has more detail about the assumptions and mathematical foundations for this method. Note a major
difference in interpretation of the posterior results with respect to a
standard Bayesian approach: In a standard Bayesian approach, the
posterior reflects an updated state of information about the prior
distribution on parameter values induced by the observational data. In
consistent Bayes, the posterior reflects a stochastic mapping of
parameter values such that the posterior parameters, when pushed-forward
through the model, give results that are consistent with the density of
the observational data. Dakota’s <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-wasabi.html"><span class="pre">wasabi</span></a></code>
keyword is a prototype capability.</p>
</section>
<section id="feature-comparison">
<h3>Feature Comparison<a class="headerlink" href="#feature-comparison" title="Link to this heading"></a></h3>
<p><a class="reference internal" href="#tab-bayes-comparison"><span class="std std-numref">Table 9</span></a> compares the options available with the
QUESO, DREAM, GPMSA, MUQ, and WASABI implementations in Dakota.</p>
<table class="docutils align-default" id="tab-bayes-comparison">
<caption><span class="caption-number">Table 9 </span><span class="caption-text">Capabilities of Bayesian methods in Dakota</span><a class="headerlink" href="#tab-bayes-comparison" title="Link to this table"></a></caption>
<thead>
<tr class="row-odd"><th class="head"><p>Capability</p></th>
<th class="head"><p>QUESO</p></th>
<th class="head"><p>MUQ</p></th>
<th class="head"><p>GPMSA</p></th>
<th class="head"><p>DREAM</p></th>
<th class="head"><p>WASABI</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Prior
Distributions</p></td>
<td><p>Any continuous variable type</p></td>
<td><p>Any
continuous
variable type</p></td>
<td><p>Any
continuous
variable type</p></td>
<td><p>Uniform only</p></td>
<td><p>Uniform
only</p></td>
</tr>
<tr class="row-odd"><td><p>Inference Type</p></td>
<td><p>MCMC with
DR, AM,
DRAM, or
MH</p></td>
<td><p>MCMC with
DR, AM,
DRAM, or
MH</p></td>
<td><p>MCMC with
DR, AM,
DRAM, or
MH</p></td>
<td><p>MCMC with
Differential
Evolution Adaptive
Metropolis</p></td>
<td><p>MCMC-
free
interval
analysis</p></td>
</tr>
<tr class="row-even"><td><p>Can use PCE/SC
Emulator</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>Can use GP Emulator</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes (required)</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even"><td><p>Likelihood-based
adaptive emulator
update</p></td>
<td><p>Yes</p></td>
<td><p>No</p></td>
<td><p>No</p></td>
<td><p>No</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd"><td><p>Initialize with
MAP pre-solve</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>No</p></td>
<td><p>No</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>Proposal covariance
options</p></td>
<td><p>prior, user,
derivative-based</p></td>
<td><p>n/a</p></td>
<td><p>prior, user</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
</tr>
<tr class="row-odd"><td><p>Can calibrate error
covariance
multipliers</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes (internal)</p></td>
<td><p>Yes</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>Supports
standardized space</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>Logit transform</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>No</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>Posterior export</p></td>
<td><p>samples</p></td>
<td><p>samples</p></td>
<td><p>samples</p></td>
<td><p>samples</p></td>
<td><p>samples,
density</p></td>
</tr>
</tbody>
</table>
</section>
<section id="bayesian-calibration-example">
<span id="uq-bayesian-ex"></span><h3>Bayesian Calibration Example<a class="headerlink" href="#bayesian-calibration-example" title="Link to this heading"></a></h3>
<p>To run a QUESO-based Bayesian calibration in Dakota, create a Dakota
input file such as the one shown in <a class="reference internal" href="#uq-figure18"><span class="std std-numref">Listing 50</span></a>.
Here, the QUESO DRAM (delayed
rejection adaptive metropolis) solver is selected. The number of samples
= 1000 indicates how many points to generate in the acceptance
chain <a class="footnote-reference brackets" href="#id69" id="id59" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>. This example uses the <code class="docutils literal notranslate"><span class="pre">mod_cantilever</span></code> algebraic model, so
an emulator is not warranted. The proposal covariance used has diagonal
element values of 1.e6 and 0.1. Two credible and prediction intervals
will be calculated for each model output: a 5/95 interval and a 10/90
interval. The calibration terms in the responses section refers to the
number of outputs that will be used in the calibration process: in this
case, it is just two. The calibration data file has the observational
data: in this case, it is a freeform file (e.g. no header or annotation)
with ten experiments. For each experiment, there are two experiment
values, one for stress and one for displacement, followed by two
variance values for the error associated with that experiment for each
quantity of interest.</p>
<div class="literal-block-wrapper docutils container" id="uq-figure18">
<div class="code-block-caption"><span class="caption-number">Listing 50 </span><span class="caption-text">Dakota input file for Bayesian calibration</span><a class="headerlink" href="#uq-figure18" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span><span class="k">method</span>
  bayes_calibration queso
    chain_samples = 10000 seed = 348
    dram  # | delayed_rejection | adaptive_metropolis | metropolis_hastings
    proposal_covariance
      values 1.0e6 1.0e-1
        diagonal
    logit_transform         # default is off
    probability_levels 0.05 0.1
                       0.05 0.1
    posterior_stats kl_divergence

<span class="k">variables</span>
  uniform_uncertain 2
    upper_bounds  1.e8 10.0
    lower_bounds 1.e6 0.1
    initial_point 2.85e7 2.5
    descriptors &#39;E&#39; &#39;w&#39;
  continuous_state 4
    initial_state 3 40000 500 1000
    descriptors &#39;t&#39; &#39;R&#39; &#39;X&#39; &#39;Y&#39;

<span class="k">interface</span>
  analysis_drivers = &#39;mod_cantilever&#39;
    direct

<span class="k">responses</span>
  calibration_terms = 2
  calibration_data_file = &#39;dakota_cantilever_queso.withsigma.dat&#39;
    freeform
    num_experiments = 10
    variance_type = &#39;scalar&#39; # read 2 scalar sigmas in each row
  descriptors = &#39;stress&#39; &#39;displacement&#39;
  no_gradients
  no_hessians
</pre></div>
</div>
</div>
<p>When the input file shown in <a class="reference internal" href="#uq-figure18"><span class="std std-numref">Listing 50</span></a> is run,
Dakota will run the MCMC algorithm and generate a posterior sample of
<span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> in accordance with Bayes
Theorem <a class="reference internal" href="#equation-eq-bayesthm">(29)</a> and the likelihood
function <a class="reference internal" href="#equation-eq-likelihood">(31)</a>. Dakota’s final output
summary reports an evaluation count summary and the best sample point
visited during the MCMC process as measured by maximum posterior
probability (an estimate of the MAP point). The final output also
summarizes the moments of the posterior samples from the chain (e.g.
mean of the chain, standard deviation of the chain samples, etc.), as
well as the credible and prediction intervals for each model output.</p>
<p>Auxilliary output is also generated to a directory called
<code class="docutils literal notranslate"><span class="pre">QuesoDiagnostics/</span></code> in the directory from which Dakota is run. The
file <code class="docutils literal notranslate"><span class="pre">display_sub0.txt</span></code> contains diagnostic information regarding
the MCMC process. The Matlab files contained in the
<code class="docutils literal notranslate"><span class="pre">QuesoDiagnostics/</span></code> directory contain the chain files. The files to
load in Matlab are <code class="docutils literal notranslate"><span class="pre">raw_chain.m</span></code> or <code class="docutils literal notranslate"><span class="pre">filtered_chain.m</span></code>, containing
the full chain or the filtered chain values of the
parameters <a class="footnote-reference brackets" href="#id70" id="id60" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a>. In addition, the accepted chain values that Dakota
generates are written to a file in the run directory called (by default)
<code class="docutils literal notranslate"><span class="pre">dakota_mcmc_tabular.dat</span></code>. The first columns of this file are the posterior values of the input
variables. If <code class="docutils literal notranslate"><span class="pre">burn_in</span></code> or <code class="docutils literal notranslate"><span class="pre">sub_sampling_period</span></code> are specified, the
filtered acceptance chain is instead written to the file <code class="docutils literal notranslate"><span class="pre">dakota_mcmc_tabular.dat</span></code>. This file
contains the posterior values of the filtered MCMC chain, as well as the
values of state variables and the resulting model responses. Finally, if
one wants to see the likelihood of each point, specifying verbose output
in the method section will result in the likelihoods being printed.</p>
</section>
<section id="chain-diagnostics">
<h3>Chain Diagnostics<a class="headerlink" href="#chain-diagnostics" title="Link to this heading"></a></h3>
<p>The convergence of the chain produced by MCMC may require many thousands
of steps, if not millions, as discussed earlier in this section.
Assessing the convergence of MCMC chains is an active area of research,
and the implementation of metrics for chain convergence is undergoing
active development in Dakota, and can be triggered during a Bayesian
calibration study through the use of the keyword <code class="docutils literal notranslate"><span class="pre">chain_diagnostics</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As of Dakota 6.10, <code class="docutils literal notranslate"><span class="pre">confidence_intervals</span></code> is the only diagnostic
implemented.</p>
</div>
<p>Suppose <span class="math notranslate nohighlight">\(g\)</span> is a function that represents some characteristic
(e.g. moment) of an underlying distribution, such as the mean or
variance. Then under the standard assumptions of an MCMC chain, the true
value can be approximated by taking the ensemble mean over the MCMC
chain. The confidence interval for the true moment calculated using the
asymptotically valid interval estimator is given
by <span id="id61">[<a class="reference internal" href="../../misc/bibliography.html#id93" title="J. M. Flegal and G. L. Jones. Batch means and spectral variance estimators in Markov chain Monte Carlo. The Annals of Statistics, 38(2):1034–1070, 2010.">FJ10</a>]</span></p>
<div class="math notranslate nohighlight">
\[\bar{g}_{n} \pm t_{*} \frac{\hat{\sigma}_{n}}{\sqrt{n}},\]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{g}_{n}\)</span> is the estimated moment (i.e. mean or
variance), <span class="math notranslate nohighlight">\(t_{*}\)</span> is the Student’s <span class="math notranslate nohighlight">\(t\)</span>-value for the 95th
quantile, <span class="math notranslate nohighlight">\(n\)</span> is the MCMC chain length, and
<span class="math notranslate nohighlight">\(\hat{\sigma}_{n}\)</span> is an estimate of the standard error whose
square is obtained using batch means estimation. To obtain the estimate
<span class="math notranslate nohighlight">\(\hat{\sigma}_{n}\)</span>, the Markov chain produced during calibration
is broken up into “batches,” the sample moment is calculated for each
batch, and <span class="math notranslate nohighlight">\(\hat{\sigma}_{n}\)</span> is subsequently obtained as an
unbiased estimate of the standard deviation in the moment calculations
over the batches. The confidence intervals produced are 95% confidence
intervals, and they are calculated for the mean and variance (first and
second moments) for each parameter and each response. Further details
regarding the default settings for these calculations can be found in
<a class="reference internal" href="../theory/bayesian.html#uq-chain-diagnostics"><span class="std std-ref">Chain Diagnostics</span></a>.</p>
<p>Confidence intervals may be used as a chain diagnostic by setting
fixed-width stopping rules <span id="id62">[<a class="reference internal" href="../../misc/bibliography.html#id250" title="N. L. Robertson, M. Khalil, and B. M. Adams. Comparing MCMC diagnostics and stopping rules. In A. Cangi and M. L. Parks, editors, Center for Computing Research Summer Proceedings 2018, 132–144. Sandia National Laboratories, 2018. Technical Report SAND2019-5093R.">RKA18</a>]</span>. For example, if
the interval width is below some threshold value, that may indicate that
enough samples have been drawn. Common choices for the threshold value
include:</p>
<ul class="simple">
<li><p>Fixed width: <span class="math notranslate nohighlight">\(\epsilon\)</span></p></li>
<li><p>Relative magnitude: <span class="math notranslate nohighlight">\(\epsilon \| \bar{g}_{n} \|\)</span></p></li>
<li><p>Relative standard deviation: <span class="math notranslate nohighlight">\(\epsilon \| \hat{\sigma}_{n} \|\)</span></p></li>
</ul>
<p>If the chosen threshold is exceeded, <code class="docutils literal notranslate"><span class="pre">samples</span></code> may need to be
increased, say by 10%, and the diagnostics reevaluated for signs of
chain convergence. Furthermore, if <code class="docutils literal notranslate"><span class="pre">output</span></code> is set to <code class="docutils literal notranslate"><span class="pre">debug</span></code>, the
sample moment for each batch (for each parameter and response) is output
to the screen. The user can then analyze the convergence of these batch
means in order to deduce whether the MCMC chain has converged.</p>
</section>
<section id="calibrating-the-observation-error-model">
<h3>Calibrating the Observation Error Model<a class="headerlink" href="#calibrating-the-observation-error-model" title="Link to this heading"></a></h3>
<p>As discussed in <a class="reference internal" href="../inputfile/inputstodakota.html#input-calib-data"><span class="std std-ref">Calibration data import</span></a>,
Dakota accepts user information on the covariance <span class="math notranslate nohighlight">\(\Sigma_d\)</span> among
observation errors and includes this in the likelihood formulation:</p>
<div class="math notranslate nohighlight">
\[\log{\mathcal{L}(\boldsymbol{{\theta};d})} \propto % =-0.5 {R}^{T} {\Sigma_d}^{-1} {R}
-\frac{1}{2} \boldsymbol{r}^T \boldsymbol{\Sigma_d}^{-1} \boldsymbol{r}.\]</div>
<p>In some cases, it can be helpful to fine tune the assumptions in this
covariance during the calibration process. Dakota supports calibrating
one or more multipliers on the blocks of the error covariance. So if
<span class="math notranslate nohighlight">\(\Sigma_d\)</span> is block diagonal such that <span class="math notranslate nohighlight">\(\Sigma_d =
\mbox{diag}({\Sigma_d}_1, ..., {\Sigma_d}_N)\)</span>, we instead formulate as
<span class="math notranslate nohighlight">\(\Sigma_d = \mbox{diag}(m_1{\Sigma_d}_1, ..., m_P{\Sigma_d}_P)\)</span>
and calibrate the multipliers <span class="math notranslate nohighlight">\(m_i\)</span> as hyper-parameters in the
Bayesian inference process.</p>
<p>The supported modes for calibrating observation error multipliers are
shown in <a class="reference internal" href="#uq-obs-err-mult"><span class="std std-numref">Table 10</span></a>: <code class="docutils literal notranslate"><span class="pre">one</span></code>,
<code class="docutils literal notranslate"><span class="pre">per_experiment</span></code>, <code class="docutils literal notranslate"><span class="pre">per_response</span></code>, and <code class="docutils literal notranslate"><span class="pre">both</span></code>. Here, the two major
blocks denote two experiments, while the inner blocks denote five response
groups (two scalar, three field). The priors on the hyper-parameters
<span class="math notranslate nohighlight">\(m_i\)</span> are taken to be inverse gamma distributions, with mean and
mode approximately 1.0 and standard deviation approximately 0.1.</p>
<table class="docutils align-default" id="uq-obs-err-mult">
<caption><span class="caption-number">Table 10 </span><span class="caption-text">Calibrating observational error covariance multipliers: (a)
one multiplier on whole user-provided covariance structure, (b)
multiplier per-experiment, (c) multiplier per-response, and (d)
both.</span><a class="headerlink" href="#uq-obs-err-mult" title="Link to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><img alt="../../_images/CalibrateOne.png" src="../../_images/CalibrateOne.png" />
<ol class="loweralpha simple">
<li></li>
</ol>
</td>
<td><img alt="../../_images/CalibratePerExperiment.png" src="../../_images/CalibratePerExperiment.png" />
<ol class="loweralpha simple" start="2">
<li></li>
</ol>
</td>
</tr>
<tr class="row-even"><td><img alt="../../_images/CalibratePerResponse.png" src="../../_images/CalibratePerResponse.png" />
<ol class="loweralpha simple" start="3">
<li></li>
</ol>
</td>
<td><img alt="../../_images/CalibrateBoth.png" src="../../_images/CalibrateBoth.png" />
<ol class="loweralpha simple" start="4">
<li></li>
</ol>
</td>
</tr>
</tbody>
</table>
</section>
<section id="scaling-and-weighting-of-residuals">
<h3>Scaling and Weighting of Residuals<a class="headerlink" href="#scaling-and-weighting-of-residuals" title="Link to this heading"></a></h3>
<p>Dakota’s scaling options, described in
<a class="reference internal" href="optimization.html#opt-additional-scaling"><span class="std std-ref">Optimization with User-specified or Automatic Scaling</span></a>,
can be used on Bayesian calibration problems, using the
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms-primary_scales.html"><span class="pre">primary_scales</span></a></code> keyword, to scale the residuals between
the data points and the model predictions, if desired.  Additionally,
Bayesian calibration residuals-squared can be weighted via the
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms-weights.html"><span class="pre">weights</span></a></code> specification. Neither set of weights nor
scales are adjusted during calibration. When response scaling is active,
it is applied after error variance weighting and before <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms-weights.html"><span class="pre">weights</span></a></code>
application. The <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms.html"><span class="pre">calibration_terms</span></a></code> documentation
has more detail about weighting and scaling of the residual terms.</p>
</section>
<section id="model-evidence">
<h3>Model Evidence<a class="headerlink" href="#model-evidence" title="Link to this heading"></a></h3>
<p>In some situations, there are multiple models that may represent a
phenomenon and the user is left with the task to determine which is most
appropriate given the available data. In this case, Bayesian model
selection may help. Suppose that the user has a set of models,
<span class="math notranslate nohighlight">\(\mathcal{M}\)</span>=<span class="math notranslate nohighlight">\(M_1,M_2...M_m\)</span> from which to choose. In
the Bayesian setting, the parameters of each of these models may be
updated according to Bayes’ rule:</p>
<div class="math notranslate nohighlight">
\[\pi_{post}(\boldsymbol{\theta_i}|D,M_i)=\pi_{prior}(\boldsymbol{\theta_i}|M_i)\frac{\pi(D|\boldsymbol{\theta_i},M_i)}{\pi(D|M_i)}\]</div>
<p>where the dependence on the model has been made explicit. The
denominator is used as the likelihood of a specific model of interest in
a version of Bayes’ rule which calculates the posterior model
plausibility as:</p>
<div class="math notranslate nohighlight" id="equation-eq-model-plausibility">
<span class="eqno">(32)<a class="headerlink" href="#equation-eq-model-plausibility" title="Link to this equation"></a></span>\[\pi_{post}(M_i|D)=\pi_{prior}(M_i)\frac{\pi(D|M_i)}{\pi(D)}\]</div>
<p>In this equation, the posterior model probability given the data is also
referred to as model plausibility. The prior model plausibility,
<span class="math notranslate nohighlight">\(\pi(M_i)\)</span>, is usually taken to be uniform, meaning equally likely
for all models, but it does not have to be. <span class="math notranslate nohighlight">\(\pi(D)\)</span> is a
normalizing factor such that the sum of all model plausibilities is 1.
In this context, model selection involves choosing the model with the
highest posterior model plausibility. Model evidence is defined as the
likelihood in <a class="reference internal" href="#equation-eq-model-plausibility">(32)</a>, denoted
by <span class="math notranslate nohighlight">\(\pi(D|M_i)\)</span>. Model evidence is determined by averaging the
likelihood of its model parameters over all possible values of the model
parameters, according to their prior distributions. It is also called
the marginal likelihood of the model. Model evidence is defined as:</p>
<div class="math notranslate nohighlight" id="equation-eq-uq-model-evidence">
<span class="eqno">(33)<a class="headerlink" href="#equation-eq-uq-model-evidence" title="Link to this equation"></a></span>\[\pi(D|M_i)=\int \pi(D|\boldsymbol{\theta_i},M_i)\pi_{prior}(\boldsymbol{\theta_i}|M_i)d \boldsymbol{\theta_i}\]</div>
<p>There are many ways to calculate model evidence. There are currently two
methods implemented in Dakota. The user first specifies
<code class="docutils literal notranslate"><span class="pre">model_evidence</span></code>, then either <code class="docutils literal notranslate"><span class="pre">mc_approx</span></code> and/or <code class="docutils literal notranslate"><span class="pre">laplace_approx</span></code>
depending on the method(s) used to calculate model evidence.</p>
<ol class="arabic">
<li><p>Monte Carlo approximation. This involves sampling from the prior
distribution of the parameters, calculating the corresponding
likelihood values at those samples, and estimating the integral given
in Eq. <a class="reference internal" href="#equation-eq-uq-model-evidence">(33)</a> by brute
force. The number of samples used in the sampling of the integral
is determined by <code class="docutils literal notranslate"><span class="pre">evidence_samples</span></code>. Although this method is easy,
it is not efficient because each sample of the prior density requires
an evaluation of the simulation model to compute the corresponding
likelihood.  Additionally, many prior samples will have very low
(near zero) likelihood, so millions of samples may be required for
accurate computation of the integral.</p></li>
<li><p>Laplace approximation. This approach is based on the Laplace
approximation, as outlined in <span id="id63">[<a class="reference internal" href="../../misc/bibliography.html#id330" title="Larry Wasserman. Bayesian model selection and model averaging. Journal of mathematical psychology, 44(1):92–107, 2000.">Was00</a>]</span>. It has
the assumption that the posterior distribution is nearly Gaussian,
which is not always a safe assumption. Then, with maximum a
posteriori (MAP) point <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}\)</span>, the Laplace
approximation of model evidence is:</p>
<div class="math notranslate nohighlight">
\[\int \pi(D|\boldsymbol{\theta_i},M_i)\pi_{prior}(\boldsymbol{\theta_i}|M_i)d \boldsymbol{\theta_i} \approx \pi(D|\hat{\boldsymbol{\theta}},M_i)\pi(\hat{\boldsymbol{\theta}}|M_i)(2\pi)^{N_i/2}{\|\det(H(\hat{\boldsymbol{\theta}}))\|}^{-1/2}\]</div>
<p>where <span class="math notranslate nohighlight">\(N_i\)</span> is the number of unknown parameters in the i-th
model and <span class="math notranslate nohighlight">\(H\)</span> is the negative Hessian of the log-posterior
evaluated at the MAP point <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}\)</span>.
Therefore, this implementation only requires the evaluation of the
model likelihood and the Hessian of the log-posterior density at the
MAP point.</p>
</li>
</ol>
</section>
<section id="model-discrepancy">
<h3>Model Discrepancy<a class="headerlink" href="#model-discrepancy" title="Link to this heading"></a></h3>
<p>Whether in a Bayesian setting or otherwise, the goal of model
calibration is to minimize the difference between the observational data
<span class="math notranslate nohighlight">\(d_i\)</span> and the corresponding model response
<span class="math notranslate nohighlight">\(q_i(\boldsymbol{\theta})\)</span>. In the presence of scenario or
configuration variables <span class="math notranslate nohighlight">\(x\)</span>, Eq. <a class="reference internal" href="#equation-eq-model">(30)</a> can be
modified,</p>
<div class="math notranslate nohighlight">
\[d_i(x) = q_i\left(\boldsymbol{\theta}, x\right) + \epsilon_i,\]</div>
<p>with the ensuing equations of the likelihood and Bayes’ Theorem updated
likewise. The configuration variables represent experimental settings,
such as temperature or pressure, that may vary between experiments.</p>
<p>However, it is often the case that the agreement between the data and
the model after calibration is not sufficiently close. This is generally
attributed to model form or structural error, and can be corrected to
some extent with the use of model discrepancy. The Kennedy and
O’Hagan <span id="id64">[<a class="reference internal" href="../../misc/bibliography.html#id168" title="M. C. Kennedy and A. O'Hagan. Bayesian calibration of computer models. Journal of the Royal Statistical Society, 63:425–464, 2001.">KOHagan01</a>]</span> formulation takes the form</p>
<div class="math notranslate nohighlight">
\[d_i(x) = q_i\left(\boldsymbol{\theta}, x\right) + \delta_i(x) + \epsilon_i,\]</div>
<p>where <span class="math notranslate nohighlight">\(\delta_i(x)\)</span> represents the model discrepancy. For scalar
responses, the model discrepancy is <em>only</em> a function of the
configuration variables. Furthermore, one discrepancy model is
calculated for <em>each</em> observable <span class="math notranslate nohighlight">\(d_i\)</span>, <span class="math notranslate nohighlight">\(i = 1, \ldots, n\)</span>,
yielding <span class="math notranslate nohighlight">\(\delta_1, \ldots, \delta_n\)</span>. For field responses, a
single, global <span class="math notranslate nohighlight">\(\delta\)</span> is a function of the configuration
variables as well as the independent field coordinates, which are
usually points in time or space. The construction of the model
discrepancy in cases with mixed scalar and field responses has not been
tested.</p>
<p>The current implementation of the model discrepancy capability in Dakota
serves as a post-processing mechanism after the completion of a Bayesian
update. If <code class="docutils literal notranslate"><span class="pre">model_discrepancy</span></code> is specified in the input file, Dakota
will perform the Bayesian update as detailed in the section above, and
then begin the process of approximating <span class="math notranslate nohighlight">\(\delta\)</span>. For each scalar
observable <span class="math notranslate nohighlight">\(d_i\)</span> and for each configuration <span class="math notranslate nohighlight">\(x_j\)</span>,</p>
<div class="math notranslate nohighlight">
\[\delta_i \left( x_j \right) = d_i \left( x_j \right) -
q_i \left(\boldsymbol{\theta}^*, x_j \right),\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^*\)</span> is the average of the calibrated
posterior distribution of the model parameters. The <span class="math notranslate nohighlight">\(i^{th}\)</span>
discrepancy function will be built over the computed
<span class="math notranslate nohighlight">\(\delta_i \left( x_j \right)\)</span>, <span class="math notranslate nohighlight">\(j = 1, \ldots,
m\)</span>. For field observable <span class="math notranslate nohighlight">\(d\)</span>, the discrepancy is calculated for
each independent field coordinate <span class="math notranslate nohighlight">\(t_{i}\)</span> and for each
configuration <span class="math notranslate nohighlight">\(x_{j}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\delta(t_{i}, x_{j}) = d(t_{i}, x_{j}) - q(\boldsymbol{\theta}^{*}, t_{i},
  x_{j}).\]</div>
<p>The global discrepancy function is then built over the computed
<span class="math notranslate nohighlight">\(\delta(t_{i},
x_{j})\)</span>, <span class="math notranslate nohighlight">\(i = 1, \ldots, n\)</span>, <span class="math notranslate nohighlight">\(j = 1, \ldots, m\)</span>. For
simplicity in future notation, we let
<span class="math notranslate nohighlight">\(\delta_{i}(x_i) = \delta(t_i, x_i)\)</span>.</p>
<p>The field discrepancy function is built using a Gaussian process
regression model with a quadratic trend function. If instead the
responses are scalars, more options for the regression model are
available. Within the Dakota input file, the user may specify the
<code class="docutils literal notranslate"><span class="pre">discrepancy_type</span></code> to be either a Gaussian process or polynomial
regression model with the <code class="docutils literal notranslate"><span class="pre">gaussian_process</span></code> or <code class="docutils literal notranslate"><span class="pre">polynomial</span></code>
commands, respectively. Additionally, the order of the trend function
may be selected using the <code class="docutils literal notranslate"><span class="pre">correction_order</span></code> command and choosing one
of <code class="docutils literal notranslate"><span class="pre">constant</span></code>, <code class="docutils literal notranslate"><span class="pre">linear</span></code>, or <code class="docutils literal notranslate"><span class="pre">quadratic</span></code>. Any specifications using
these keywords will apply to all <span class="math notranslate nohighlight">\(\delta_i\)</span>. By default, Dakota
will build a Gaussian process discrepancy model with a quadratic trend
function. Information regarding how polynomial and Gaussian process
models are built can be found in
<a class="reference internal" href="../inputfile/model.html#models-surf-polynomial"><span class="std std-ref">Linear, Quadratic, and Cubic Polynomial Models</span></a> and <a class="reference internal" href="../inputfile/model.html#models-surf-kriging"><span class="std std-ref">Kriging/Gaussian-Process Spatial Interpolation Models</span></a>, respectively.</p>
<p>The user may specify new “prediction” configurations at which the
corrected model should be calculated. For each response and for each new
configuration,
<span class="math notranslate nohighlight">\(q_i(\boldsymbol{\theta}, x_{k,new}) + \delta_i(x_{k,new})\)</span> will
be computed. The prediction configurations can be specified in one of
three ways. If <code class="docutils literal notranslate"><span class="pre">num_prediction_configs</span></code> is included, Dakota will
uniformly distribute the indicated number of prediction configurations
throughout the domain of the configuration variable that is given in the
<code class="docutils literal notranslate"><span class="pre">variables</span></code> block of the input file. Alternatively, the user may
explicitly list desired prediction configuration locations within the
input file following the <code class="docutils literal notranslate"><span class="pre">prediction_configs</span></code> keyword, or in an
external file to be read in with the <code class="docutils literal notranslate"><span class="pre">import_prediction_configs</span></code>
option. If none of these three options is selected, Dakota will
automatically calculate corrected model predictions at ten
configurations in the scalar response case, with the predictions spread
uniformly in the configuration variable domain. In the case of field
responses, corrected model predictions are calculated for each value of
the input configuration variable(s).</p>
<p>Calculations corresponding to each prediction configuration and to each
observable will be output to tabular files. The responses from the
discrepancy model itself is output to <code class="docutils literal notranslate"><span class="pre">dakota_discrepancy_tabular.dat</span></code>.
Those from the corrected model
are output to <code class="docutils literal notranslate"><span class="pre">dakota_corrected_tabular.dat</span></code>.
The user may specify the output file names for the
discrepancy and corrected model tabular files using the
<code class="docutils literal notranslate"><span class="pre">export_discrepancy_file</span></code> and <code class="docutils literal notranslate"><span class="pre">export_corrected_model_file</span></code>
keywords, respectively.</p>
<p>Variance information corresponding to each specified configuration
location and for each observable is also computed. In a prediction
setting for scalar responses, the variance calculated from the
discrepancy model is additively combined with the variance information
provided with the experimental data, such that</p>
<div class="math notranslate nohighlight" id="equation-eq-discrep-var">
<span class="eqno">(34)<a class="headerlink" href="#equation-eq-discrep-var" title="Link to this equation"></a></span>\[\Sigma_{total,i}(x) = \Sigma_{\delta, i}(x) + \sigma^{2}_{exp,i} I\]</div>
<p>for each observable <span class="math notranslate nohighlight">\(i\)</span>. Further details of how the variance
<span class="math notranslate nohighlight">\(\Sigma_{\delta,i}(x)\)</span> is computed for Gaussian process and
polynomial regression models can be found in <a class="reference internal" href="../theory/bayesian.html#uq-model-disc"><span class="std std-ref">Model Discrepancy</span></a>.
The experimental variance provided
for parameter calibration may vary for the same observable from
experiment to experiment, thus <span class="math notranslate nohighlight">\(\sigma^{2}_{exp,i}\)</span> is taken to be
the maximum variance given for each observable. That is,</p>
<div class="math notranslate nohighlight">
\[\sigma^2_{exp,i} = \max_{j} \sigma^2_{i}(x_j),\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma^2_{i}(x_j)\)</span> is the variance provided for the
<span class="math notranslate nohighlight">\(i^{th}\)</span> observable <span class="math notranslate nohighlight">\(d_i\)</span>, computed or measured with the
configuration variable <span class="math notranslate nohighlight">\(x_j\)</span>.</p>
<p>When each corrected model value
<span class="math notranslate nohighlight">\(q_i(\boldsymbol{\theta}^{*}, x_{k, new}) +
\delta_i(x_{k,new})\)</span> is considered, the variance calculated
via <a class="reference internal" href="#equation-eq-discrep-var">(34)</a> provides a prediction
interval, similar to those described in
<a class="reference internal" href="#uq-bayesian-queso"><span class="std std-ref">QUESO</span></a>. Including
<span class="math notranslate nohighlight">\(\sigma^{2}_{exp,i}\)</span> in the variance calculation accounts for the
uncertainty in the model predictions that arise due to uncertainties in
the calibration data. These prediction variances are output to the file
<code class="docutils literal notranslate"><span class="pre">dakota_discrepancy_variance_tabular.dat</span></code> by default.
The name of this file can be modified using the
<code class="docutils literal notranslate"><span class="pre">export_corrected_variance_file</span></code> keyword in the input script. If the
response is a field, the variance information written to this file is
the variance of the Gaussian process alone. Future work includes
calculation of combined experimental variance and discrepancy model
variance for field responses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Additional details and an illustrative example of these calculations are
given in <a class="reference internal" href="../theory/bayesian.html#uq-model-disc-scalar-example"><span class="std std-ref">Scalar Responses Example</span></a> and <a class="reference internal" href="../theory/bayesian.html#uq-model-disc-field-example"><span class="std std-ref">Field Responses Example</span></a>.</p>
</div>
</section>
<section id="bayesian-experimental-design">
<span id="sec-bayes-expdesign"></span><h3>Bayesian Experimental Design<a class="headerlink" href="#bayesian-experimental-design" title="Link to this heading"></a></h3>
<p>The goal of experimental design is to add observational data to the
Bayesian update that informs model parameters and reduces their
uncertainties. In Bayesian approaches, data from physical experiments is
typically used to calibrate a model. However, another common practice is
to use responses or output from a high-fidelity model as “truth data” in
place of experimental data in a low-fidelity model calibration. This can
be done in with a single Bayesian calibration, or it can be done
iteratively with the use of experimental design, where an initial set of
high-fidelity runs is augmented sequentially to find the next “best”
high-fidelity design point at which to run the high-fidelity model to
add to the calibration data. The low-fidelity posterior parameter
distribution is then updated again using Bayesian calibration. The
mutual information is used as the selection criterion to guide the
process of high-fidelity data acquisition.</p>
<p>In Dakota, design conditions, such as temperature or spatial location,
can be specified using so-called configuration variables. The design
selection algorithm implemented in Dakota uses a user-specified
high-fidelity code to produce the “experimental” or observational data
that is used in the calibration of the desired low-fidelity model. The
high-fidelity model is dependent only upon the design or configuration
variables while the low-fidelity model depends on both the design
variables and uncertain model parameters.</p>
<p>An example Dakota input file that implements this Bayesian experimental
design algorithm is shown in
<a class="reference internal" href="#figure-uq-expdesign1"><span class="std std-numref">Listing 51</span></a>.
Note that there are three <code class="docutils literal notranslate"><span class="pre">model</span></code> blocks, one describing the model
hierarchy and one each for the high-fidelity and low-fidelity models.
There are two <code class="docutils literal notranslate"><span class="pre">variables</span></code>, <code class="docutils literal notranslate"><span class="pre">interface</span></code>, and <code class="docutils literal notranslate"><span class="pre">responses</span></code> blocks
such that each model has its own specifications. The low-fidelity
<code class="docutils literal notranslate"><span class="pre">variables</span></code> block contains information about both the design
variables, which are specified with <code class="docutils literal notranslate"><span class="pre">continuous_state</span></code>, and the
parameters to be updated via Bayes’
Theorem <a class="reference internal" href="#equation-eq-bayesthm">(29)</a>, which are specified using one
of the aleatory uncertain variable types discussed in
Section <a class="reference internal" href="../inputfile/variables.html#variables-uncertain"><span class="std std-ref">Uncertain Variables</span></a>. In
the high-fidelity <code class="docutils literal notranslate"><span class="pre">variables</span></code> block, only the <code class="docutils literal notranslate"><span class="pre">continuous_state</span></code>
parameters are included. The specifications of the design variables
should be consistent in both blocks. Each <code class="docutils literal notranslate"><span class="pre">interface</span></code> block should
point to the appropriate high- or low-fidelity code, and the
<code class="docutils literal notranslate"><span class="pre">responses</span></code> blocks should contain consistent details about the
responses from each code. For example, both of the models should return
the same number of <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms.html"><span class="pre">calibration_terms</span></a></code>.</p>
<div class="literal-block-wrapper docutils container" id="figure-uq-expdesign1">
<div class="code-block-caption"><span class="caption-number">Listing 51 </span><span class="caption-text">Dakota input file for Bayesian Experimental Design.</span><a class="headerlink" href="#figure-uq-expdesign1" title="Link to this code"></a></div>
<div class="highlight-dakota notranslate"><div class="highlight"><pre><span></span><span class="k">environment</span>
  tabular_data

<span class="k">method</span>,
       bayes_calibration queso
          dram
    seed = 34785
          chain_samples = 500
          experimental_design
          initial_samples = 2
    num_candidates = 2
    import_candidate_points_file = &#39;dakota_bayes_expdesign.cand.dat&#39;
    freeform
    #ksg2
    max_hifi_evaluations = 1
          model_pointer = &#39;HIERARCH&#39;

<span class="k">model</span>,
  id_model = &#39;HIERARCH&#39;
  variables_pointer = &#39;ALL_VARS&#39;
  surrogate ensemble
    ordered_model_fidelities = &#39;LF&#39; &#39;HF&#39;

<span class="k">model</span>,
        id_model = &#39;LF&#39;
        single
          interface_pointer = &#39;lofi_IF&#39;
        variables_pointer = &#39;ALL_VARS&#39;
        responses_pointer = &#39;lofi_resp&#39;

<span class="k">model</span>,
        id_model = &#39;HF&#39;
        single
          interface_pointer = &#39;hifi_IF&#39;
        variables_pointer = &#39;CONFIG_VARS&#39;
        responses_pointer = &#39;hifi_resp&#39;

<span class="k">variables</span>,
  id_variables = &#39;ALL_VARS&#39;
        continuous_state = 1
    upper_bounds = 70
          lower_bounds = 10
        uniform_uncertain = 3
    upper_bounds   0.06   0     260
    lower_bounds   0  -8  0

<span class="k">variables</span>,
  id_variables = &#39;CONFIG_VARS&#39;
  active state
  continuous_state = 1
          upper_bounds = 70
          lower_bounds = 10

<span class="k">interface</span>,
        id_interface = &#39;hifi_IF&#39;
        analysis_drivers = &#39;expdesign_high&#39;
          fork

<span class="k">interface</span>,
        id_interface = &#39;lofi_IF&#39;
        analysis_drivers = &#39;expdesign_low&#39;
          fork

<span class="k">responses</span>,
  id_responses = &#39;lofi_resp&#39;
        calibration_terms = 1
  no_gradients
  no_hessians

<span class="k">responses</span>,
  id_responses = &#39;hifi_resp&#39;
  calibration_terms = 1
  calibration_data_file = &#39;dakota_bayes_expdesign.dat&#39;
    freeform
    num_config_variables = 1
    num_experiments = 2
    experiment_variance_type = &#39;none&#39;
  no_gradients
  no_hessians
</pre></div>
</div>
</div>
<p>The mutual information experimental design algorithm is selected by
specifying <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration.html"><span class="pre">bayes_calibration</span></a></code>, <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-queso.html"><span class="pre">queso</span></a></code>, and
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-experimental_design.html"><span class="pre">experimental_design</span></a></code> within the
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method.html"><span class="pre">method</span></a></code> block of the input file, and the first <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/model.html"><span class="pre">model</span></a></code>
block should contain the <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/model-surrogate-hierarchical.html"><span class="pre">hierarchical</span></a></code>
specification of the <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/model-surrogate.html"><span class="pre">surrogate</span></a></code> keyword. The algorithm starts by
performing a Bayesian calibration using a number of data points,
specified in Dakota by <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-experimental_design-initial_samples.html"><span class="pre">initial_samples</span></a></code>.
These initial data points can be pulled from external data using the
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms-calibration_data_file.html"><span class="pre">calibration_data_file</span></a></code>
keyword in the high-fidelity <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses.html"><span class="pre">responses</span></a></code> block. In this case,
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms-calibration_data_file-num_config_variables.html"><span class="pre">num_config_variables</span></a></code>
should be specified and set to the number of
configuration variables captured in the <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/variables.html"><span class="pre">variables</span></a></code> blocks.
Furthermore, for use in Bayesian experimental design,
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms-calibration_data_file.html"><span class="pre">calibration_data_file</span></a></code>
should contain the configuration variables and
the corresponding high-fidelity model responses. Scalar variance
information may be included for the calibration data through the use of
the <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms-calibration_data_file-experiment_variance_type.html"><span class="pre">experiment_variance_type</span></a></code>
or <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms-simulation_variance.html"><span class="pre">simulation_variance</span></a></code> command
within the high-fidelity <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses.html"><span class="pre">responses</span></a></code> block. The former is applied to
any user-provided data, such as through the
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms-calibration_data_file.html"><span class="pre">calibration_data_file</span></a></code> keyword, while
the latter applies only to those high-fidelity model responses produced by
the high-fidelity code run by Dakota. If the number of points taken from
this file is less than <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-experimental_design-initial_samples.html"><span class="pre">initial_samples</span></a></code>, or if no such file is
provided, Latin Hypercube Sampling is used to draw samples of the design
space, and the high-fidelity model is run at these points to supplement
the user-specified data. After this initial calibration, a set of design
conditions (i.e. configuration variables) of size <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-experimental_design-num_candidates.html"><span class="pre">num_candidates</span></a></code> is
proposed. Users may specify these candidate points through the
<code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-experimental_design-import_candidate_points_file.html"><span class="pre">import_candidate_points_file</span></a></code> command. Again, if the number of points
in this file is less than <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-experimental_design-num_candidates.html"><span class="pre">num_candidates</span></a></code>, or if no such file is
provided, Latin Hypercube Sampling is used to draw samples of the design
space.</p>
<p>From these candidate designs, that which maximizes the mutual
information with respect to the low-fidelity model parameters is deemed
“optimal.” The mutual information is approximated using the low-fidelity
model and a <span class="math notranslate nohighlight">\(k\)</span>-nearest neighbor algorithm, as detailed
in <span id="id65">[<a class="reference internal" href="../../misc/bibliography.html#id188" title="Allison Lewis, Ralph Smith, Brian Williams, and Victor Figueroa. An information theoretic approach to use high-fidelity codes to calibrate low-fidelity codes. Journal of Computational Physics, 324:24 - 43, 2016.">LSWF16</a>]</span>. This optimal design is used in the
high-fidelity model to create a new observation, which is appended to
the initial data. This updated data is used to recalculate the Bayesian
posterior, and the process repeats until one of three stopping criteria
are met. Multiple optimal designs may be selected concurrently by
specifying <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-experimental_design-batch_size.html"><span class="pre">batch_size</span></a></code> in the input script.
These designs are selected using the greedy algorithm described in detail
in <a class="reference internal" href="../theory/bayesian.html#uq-bayes-experimental-design"><span class="std std-ref">Experimental Design</span></a>. In this case, the high-fidelity model is
run at all batch-selected optimal designs before the Bayesian posterior
is recalculated with the updated data for an ensuing iteration of the
experimental design algorithm.</p>
<p>There are two algorithms that may be used to calculate the mutual
information, both of which are derived in <span id="id66">[<a class="reference internal" href="../../misc/bibliography.html#id186" title="Alexander Kraskov, Harald Stögbauer, and Peter Grassberger. Estimating mutual information. Physical review E, 69(6):066138, 2004.">KStogbauerG04</a>]</span>. The
first algorithm discussed therein is used as the default algorithm
within Dakota; the second may be selected by including the keyword
<code class="docutils literal notranslate"><span class="pre">ksg2</span></code> in the Dakota input script. Furthermore, the user may choose to
include, during the computation of the mutual information, a stochastic
error term on the low-fidelity model responses. This is done by
specifying <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses-calibration_terms-simulation_variance.html"><span class="pre">simulation_variance</span></a></code> in the <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/responses.html"><span class="pre">responses</span></a></code> block
corresponding to the low-fidelity model. See <a class="reference internal" href="../theory/bayesian.html#uq-bayes-experimental-design"><span class="std std-ref">Experimental Design</span></a> for more
information regarding the implementation of the mutual information calculations.</p>
<p>There are three criteria by which this algorithm is considered complete.
The user may specify <code class="docutils literal notranslate"><a class="reference external" href="../../usingdakota/reference/method-bayes_calibration-experimental_design-max_hifi_evaluations.html"><span class="pre">max_hifi_evaluations</span></a></code>, which limits the number of
high-fidelity model simulations Dakota will run. Note that this does not
include any simulations needed to perform the initial Bayesian calibration
of the low-fidelity model parameters. Alternatively, if the change in the
mutual information from one iteration to the next is sufficiently small or
if all candidate points have been exhausted, the algorithm will terminate.</p>
<p>Progress of the algorithm will be reported to the screen with the rest
of the Dakota output. Furthermore, a summary of the algorithm’s results,
including, for each iteration, the optimal design, the mutual
information, and the corresponding high-fidelity model response, can be
found in the file <code class="docutils literal notranslate"><span class="pre">experimental_design_output.txt</span></code>.</p>
<section id="one-at-a-time-implementation">
<h4>One-at-a-time Implementation<a class="headerlink" href="#one-at-a-time-implementation" title="Link to this heading"></a></h4>
<p>There may be some applications for which the high-fidelity model must be
run independently of Dakota. This algorithm may still be implemented in
this case, however, it requires some extra work by the user to ensure
that the high-fidelity model information is properly communicated to
Dakota, as a “dummy” high-fidelity model code must be supplied to
Dakota. The data to be used in the initial Bayesian calibration should
be gathered from the high-fidelity model or physical experiment and
imported via the <code class="docutils literal notranslate"><span class="pre">calibration_data_file</span></code> in the high-fidelity
<code class="docutils literal notranslate"><span class="pre">responses</span></code> block, and extra care should be taken to ensure that
<code class="docutils literal notranslate"><span class="pre">initial_samples</span></code> matches the number of experiments in this file. It
is also best, for this use-case, to use
<code class="docutils literal notranslate"><span class="pre">import_candidate_points_file</span></code>, with <code class="docutils literal notranslate"><span class="pre">num_candidates</span></code> exactly
matching the number of candidate points in the file.</p>
<p>By setting <code class="docutils literal notranslate"><span class="pre">max_hifi_evaluations</span></code> to zero, Dakota will run the initial
calibration of the low-fidelity model, select the optimal design (or
multiple optimal designs when <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> is greater than 1) from
those provided in <code class="docutils literal notranslate"><span class="pre">import_candidate_points_file</span></code>, and exit <em>without</em>
running the “dummy” high-fidelity model code. The selected design(s)
will be output to the screen, as well as to <code class="docutils literal notranslate"><span class="pre">experimental_design_output.txt</span></code>,
as detailed above. The
high-fidelity model may then be run offline with the newly selected
design point(s).</p>
<p>The user must update <code class="docutils literal notranslate"><span class="pre">calibration_data_file</span></code> with the new
high-fidelity data when it becomes available, as well as remove the
previously selected design point(s) from
<code class="docutils literal notranslate"><span class="pre">import_candidate_points_file</span></code>. Within the Dakota input file,
<code class="docutils literal notranslate"><span class="pre">initial_samples</span></code>, <code class="docutils literal notranslate"><span class="pre">num_experiments</span></code>, and <code class="docutils literal notranslate"><span class="pre">num_candidates</span></code> should
be correspondingly updated. Dakota may then be run again to yield the
next optimal experimental design(s). It should be noted that the
stopping criteria will not be automatically evaluated by Dakota when
one-at-a-time implementation is used. The user must determine when the
algorithm should be terminated.</p>
</section>
</section>
</section>
<section id="uncertainty-quantification-usage-guidelines">
<span id="usage-uq"></span><h2>Uncertainty Quantification Usage Guidelines<a class="headerlink" href="#uncertainty-quantification-usage-guidelines" title="Link to this heading"></a></h2>
<p>The choice of uncertainty quantification method depends on how the input
uncertainty is characterized, the computational budget, and the desired
output accuracy. The recommendations for UQ methods are summarized in
<a class="reference internal" href="#usage-guideuq"><span class="std std-numref">Table 11</span></a> and are discussed in the remainder of the
section.</p>
<table class="docutils align-default" id="usage-guideuq">
<caption><span class="caption-number">Table 11 </span><span class="caption-text">Guidelines for UQ method selection.</span><a class="headerlink" href="#usage-guideuq" title="Link to this table"></a></caption>
<tbody>
<tr class="row-odd"><td><p><strong>Method</strong></p></td>
<td><p><strong>Desired Problem</strong></p></td>
<td><p><strong>Applicable
Methods</strong></p></td>
</tr>
<tr class="row-even"><td><p><strong>Classification</strong></p></td>
<td><p><strong>Characteristics</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Sampling</p></td>
<td><p>nonsmooth, multimodal
response functions;</p></td>
<td><p>sampling (Monte Carlo
or LHS)</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>response evaluations
are relatively
inexpensive</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Local</p></td>
<td><p>smooth, unimodal
response functions;</p></td>
<td><p>local_reliability
(MV,
AMV/AMV<span class="math notranslate nohighlight">\(^2\)</span>,</p></td>
</tr>
<tr class="row-even"><td><p>reliability</p></td>
<td><p>larger sets of random
variables;</p></td>
<td><p>AMV
+/AMV<span class="math notranslate nohighlight">\(^2\)</span>+,
TANA, FORM/SORM)</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>estimation of tail
probabilities</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Global</p></td>
<td><p>smooth or limited
nonsmooth response;</p></td>
<td><p>global_reliability</p></td>
</tr>
<tr class="row-odd"><td><p>reliability</p></td>
<td><p>multimodal response;
low dimensional;</p></td>
<td></td>
</tr>
<tr class="row-even"><td></td>
<td><p>estimation of tail
probabilities</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Adaptive</p></td>
<td><p>smooth or limited
nonsmooth response;</p></td>
<td><p>importance_sampling,</p></td>
</tr>
<tr class="row-even"><td><p>Sampling</p></td>
<td><p>multimodal response;
low dimensional;</p></td>
<td><p>gpais,
adaptive_sampling,</p></td>
</tr>
<tr class="row-odd"><td></td>
<td><p>estimation of tail
probabilities</p></td>
<td><p>pof_darts</p></td>
</tr>
<tr class="row-even"><td><p>Stochastic</p></td>
<td><p>smooth or limited
nonsmooth response;</p></td>
<td><p>polynomial_chaos,</p></td>
</tr>
<tr class="row-odd"><td><p>expansions</p></td>
<td><p>multimodal response;
low dimensional;</p></td>
<td><p>stoch_collocation</p></td>
</tr>
<tr class="row-even"><td></td>
<td><p>estimation of moments
or moment-based
metrics</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Epistemic</p></td>
<td><p>uncertainties are
poorly characterized</p></td>
<td><p>interval:
local_interval_est,</p></td>
</tr>
<tr class="row-even"><td></td>
<td></td>
<td><p>global_interval_est,
sampling;</p></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td><p>BPA: local_evidence,
global_evidence</p></td>
</tr>
<tr class="row-even"><td><p>Mixed UQ</p></td>
<td><p>some uncertainties
are poorly
characterized</p></td>
<td><p>nested UQ (IVP, SOP,
DSTE) with epistemic</p></td>
</tr>
<tr class="row-odd"><td></td>
<td></td>
<td><p>outer loop and
aleatory inner loop,
sampling</p></td>
</tr>
</tbody>
</table>
<div class="line-block">
<div class="line"><strong>Sampling Methods</strong></div>
<div class="line">Sampling-based methods are the most robust uncertainty techniques
available, are applicable to almost all simulations, and possess
rigorous error bounds; consequently, they should be used whenever the
function is relatively inexpensive to compute and adequate sampling
can be performed. In the case of terascale computational simulations,
however, the number of function evaluations required by traditional
techniques such as Monte Carlo and Latin hypercube sampling (LHS)
quickly becomes prohibitive, especially if tail statistics are needed.</div>
</div>
<p>Alternatively, one can apply the traditional sampling techniques to a
surrogate function approximating the expensive computational simulation
(see <a class="reference internal" href="../advanced/advancedmodelrecursions.html#adv-models-sbuq"><span class="std std-ref">Surrogate-Based Uncertainty Quantification</span></a>). However, if this
approach is selected, the user should be aware that it is very difficult
to assess the accuracy of the results obtained. Unlike the case of
surrogate-based local minimization (see
<a class="reference internal" href="../advanced/advancedmethods.html#adv-meth-sbm-sblm"><span class="std std-ref">Surrogate-Based Local Minimization</span></a>), there is no
simple pointwise calculation to verify the accuracy of the approximate
results. This is due to the functional nature of uncertainty
quantification, i.e. the accuracy of the surrogate over the entire
parameter space needs to be considered, not just around a candidate
optimum as in the case of surrogate-based local. This issue especially
manifests itself when trying to estimate low probability events such as
the catastrophic failure of a system.</p>
<div class="line-block">
<div class="line"><strong>Reliability Methods</strong></div>
<div class="line">Local reliability methods (e.g., MV, AMV/AMV<span class="math notranslate nohighlight">\(^2\)</span>,
AMV+/AMV<span class="math notranslate nohighlight">\(^2\)</span>+, TANA, and FORM/SORM) are more computationally
efficient in general than the sampling methods and are effective when
applied to reasonably well-behaved response functions; i.e., functions
that are smooth, unimodal, and only mildly nonlinear. They can be used
to provide qualitative sensitivity information concerning which
uncertain variables are important (with relatively few function
evaluations), or compute full cumulative or complementary cumulative
response functions (with additional computational effort). Since they
rely on gradient calculations to compute local optima (most probable
points of failure), they scale well for increasing numbers of random
variables, but issues with nonsmooth, discontinuous, and multimodal
response functions are relevant concerns. In addition, even if there
is a single MPP and it is calculated accurately, first-order and
second-order integrations may fail to accurately capture the shape of
the failure domain. In these cases, adaptive importance sampling
around the MPP can be helpful. Overall, local reliability methods
should be used with some care and their accuracy should be verified
whenever possible.</div>
</div>
<p>An effective alternative to local reliability analysis when confronted
with nonsmooth, multimodal, and/or highly nonlinear response functions
is efficient global reliability analysis (EGRA). This technique employs
Gaussian process global surrogate models to accurately resolve the
failure domain and then employs multimodal adaptive importance sampling
to resolve the probabilities. For relatively low dimensional problems
(i.e, on the order of 10 variables), this method displays the efficiency
of local reliability analysis with the accuracy of exhaustive sampling.
While extremely promising, this method is still relatively new and is
the subject of ongoing refinements as we deploy it to additional
applications.</p>
<div class="line-block">
<div class="line"><strong>Adaptive Sampling Methods</strong></div>
<div class="line">There are now a number of methods in Dakota which are tailored to
estimating tail probabilities. These methods include both standard
importance sampling and Gaussian Process Adaptive Importance Sampling,
as well as adaptive sampling and the POF-darts method. These methods
are suitable for smooth or limited non-smooth responses, and work well
in low dimensions. GPAIS and POF-darts utilize a Gaussian process
surrogate model.</div>
</div>
<div class="line-block">
<div class="line"><strong>Stochastic Expansions Methods</strong></div>
<div class="line">The next class of UQ methods available in Dakota is comprised of
stochastic expansion methods (polynomial chaos and stochastic
collocation), which are general purpose techniques provided that the
response functions possess finite second order moments. Further, these
methods capture the underlying functional relationship between a key
response metric and its random variables, rather than just
approximating statistics such as mean and standard deviation. This
class of methods parallels traditional variational methods in
mechanics; in that vein, efforts are underway to compute rigorous
error bounds of the approximations produced by the methods. Another
strength of these methods is their potential use in a multiphysics
environment as a means to propagate the uncertainty through a series
of simulations while retaining as much information as possible at each
stage of the analysis. The current challenge in the development of
these methods, as for other global surrogate-based methods, is
effective scaling for large numbers of random variables. Recent
advances in adaptive collocation and sparsity detection methods
address some of the scaling issues for stochastic expansions.</div>
</div>
<div class="line-block">
<div class="line"><strong>Epistemic Uncertainty Quantification Methods</strong></div>
<div class="line">The final class of UQ methods available in Dakota are focused on
epistemic uncertainties, or uncertainties resulting from a lack of
knowledge. In these problems, the assignment of input probability
distributions when data is sparse can be somewhat suspect. One
approach to handling epistemic uncertainties is interval analysis
(<code class="docutils literal notranslate"><span class="pre">local_interval_est</span></code> and <code class="docutils literal notranslate"><span class="pre">global_interval_est</span></code>), where a set of
intervals on inputs, one interval for each input variable, is mapped
to a set of intervals on outputs. To perform this process efficiently,
optimization methods can be used. Another related technique is
Dempster-Shafer theory of evidence (Dakota methods <code class="docutils literal notranslate"><span class="pre">local_evidence</span></code>
and <code class="docutils literal notranslate"><span class="pre">global_evidence</span></code>), where multiple intervals per input variable
(which can be overlapping, contiguous, or disjoint) are propagated,
again potentially using optimization methods. The choice between local
or global optimization methods for interval computation is governed by
the same issues described in <a class="reference internal" href="optimization.html#opt-usage"><span class="std std-ref">Optimization Usage Guidelines</span></a>.</div>
</div>
<div class="line-block">
<div class="line"><strong>Mixed Aleatoric and Epistemic Methods</strong></div>
<div class="line">For problems with a mixture of epistemic and aleatoric uncertainties,
it is desirable to segregate the two uncertainty types within a nested
analysis, allowing stronger probabilistic inferences for the portion
of the problem where they are appropriate. In this nested approach, an
outer epistemic level selects realizations of epistemic parameters
(augmented variables) and/or realizations of random variable
distribution parameters (inserted variables). These realizations
define the objective probabilistic analysis to be performed on the
inner aleatoric level. In the case where the outer loop involves
propagation of subjective probability, the nested approach is known as
second-order probability and the study generates a family of CDF/CCDF
respresentations known as a “horse tail” plot. In the case where the
outer loop is an interval propagation approach (<code class="docutils literal notranslate"><span class="pre">local_interval_est</span></code>
or <code class="docutils literal notranslate"><span class="pre">global_interval_est</span></code>), the nested approach is known as
interval-valued probability (see also
<a class="reference internal" href="../inputfile/model.html#models-nested"><span class="std std-ref">Nested Models</span></a>) . In the case where the
outer loop is an evidence-based approach (<code class="docutils literal notranslate"><span class="pre">local_evidence</span></code> or
<code class="docutils literal notranslate"><span class="pre">global_evidence</span></code>), the approach generates epistemic belief and
plausibility bounds on aleatory statistics.</div>
</div>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id67" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id26">1</a><span class="fn-bracket">]</span></span>
<p>Orthogonal polynomial selections also exist for discrete probability
distributions, but are not yet supported in Dakota.</p>
</aside>
<aside class="footnote brackets" id="id68" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id27">2</a><span class="fn-bracket">]</span></span>
<p>Identical support range; weight differs by at most a constant factor.</p>
</aside>
<aside class="footnote brackets" id="id69" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id59">3</a><span class="fn-bracket">]</span></span>
<p>If delayed rejection is active, the number of simulation evaluations
will typically be higher due to backtracking.</p>
</aside>
<aside class="footnote brackets" id="id70" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id60">4</a><span class="fn-bracket">]</span></span>
<p>The full chain will be output in cases of adaptive posterior
refinement or proposal updating, since these use cases access the
entire acceptance chain to identify refinement data or restarting
points, respectively.</p>
</aside>
</aside>
</section>
<section id="video-resources">
<h2>Video Resources<a class="headerlink" href="#video-resources" title="Link to this heading"></a></h2>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Title</p></th>
<th class="head"><p>Link</p></th>
<th class="head"><p>Resources</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Uncertainty Quantification</p></td>
<td><p><a class="reference external" href="http://digitalops.sandia.gov/Mediasite/Play/8105e6e9c2cb45089cf24cd4585fc8cb1d"><img alt="Uncertainty Quantification" src="../../_images/UQTrainingTeaser.png" /></a></p></td>
<td><p><a class="reference external" href="https://dakota.sandia.gov/sites/default/files/training/DakotaTraining_UncertaintyQuantification.pdf">Slides</a> /
<a class="reference external" href="https://dakota.sandia.gov/sites/default/files/training/uncertainty_analysis-220216.zip">Exercises</a></p></td>
</tr>
<tr class="row-odd"><td><p>Sampling</p></td>
<td><p><a class="reference external" href="https://www.youtube.com/watch?v=dnqoUCw6wSo"><img alt="Sampling" src="../../_images/SamplingScreencastTeaser.png" /></a></p></td>
<td></td>
</tr>
</tbody>
</table>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="designofexperiments.html" class="btn btn-neutral float-left" title="Design of Experiments" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="optimization.html" class="btn btn-neutral float-right" title="Optimization" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <!--
  <div role="contentinfo">
    <p>&#169; Copyright 2024, Sandia National Laboratories.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
  
  --> 

</footer>
        </div>
      </div>
	  
	  <div style="background-color: #0f0f0f;color:#fafafa;padding:20px">
	    <div>
		  <h2><em>Exceptional service in the national interest</em></h2>
		</div>
		<p>© 2023 National Technology and Engineering Solutions of Sandia, LLC. | <a href="https://www.sandia.gov/contact_us/index.html">Questions &amp; Comments</a> | <a href="https://www.sandia.gov/general/privacy-security/index.html">Privacy &amp; Security</a></p>
		<p><a href="http://energy.gov" rel="noopener noreferrer" target="_blank"><img alt="U.S. Department of Energy" longdesc="https://energy.gov" src="https://www.sandia.gov/_common/images/doe_logo_white.png" style="height:37px; width:140px"></a> <a href="http://nnsa.energy.gov/" rel="noopener noreferrer" target="_blank"> <img alt="National Nuclear Security Administration" longdesc="http://nnsa.gov" src="https://www.sandia.gov/_common/images/nnsa_logo_white.png" style="height:37px; width:116px"></a></p>
		<p><a href="https://www.sandia.gov">Sandia National Laboratories</a> is a multimission laboratory managed and operated by National Technology and Engineering Solutions of Sandia, LLC., a wholly owned subsidiary of Honeywell International, Inc., for the U.S. Department of Energy’s National Nuclear Security Administration under contract DE-NA-0003525.</p>
	  </div>	  	  
	  
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>